{
  "audit_metadata": {
    "repository_path": ".",
    "adr_path": "docs/architecture/ADRs",
    "analysis_timestamp": "2025-08-06T01:52:48.885276+00:00",
    "execution_time_seconds": 2249.3236112594604,
    "total_adrs_analyzed": 21
  },
  "overall_compliance_score": 44.34761904761905,
  "discovered_adrs": [
    {
      "adr_id": "ADR-011_HistoricalCodeAnalysis",
      "title": "ADR-011: Historical Code Analysis for ADR Compliance Auditing",
      "file_path": "docs/architecture/ADRs/ADR-011_HistoricalCodeAnalysis.md",
      "requirements": [
        "This decision establishes a systematic, automated approach to ADR compliance auditing that scales with the growing complexity of the ViolentUTF API architecture. The Historical Code Analysis Tool addresses critical audit team needs while maintaining security, performance, and operational requirements.",
        "2. **Configurable Detection**: YAML-based patterns adapt to evolving ADR requirements"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-007_AsyncTaskProcessing",
      "title": "ADR-007: Asynchronous Task Processing with HTTP Polling and Webhooks",
      "file_path": "docs/architecture/ADRs/ADR-007_AsyncTaskProcessing.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-004_Versioning",
      "title": "ADR-004: URI Path Versioning Strategy",
      "file_path": "docs/architecture/ADRs/ADR-004_Versioning.md",
      "requirements": [
        "Non-breaking, backward-compatible changes (e.g., adding a new optional field to a response or adding a completely new endpoint) will **not** require a new version. The current major version will simply be updated."
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-F1-3_EndpointIntegrationArchitecture",
      "title": "ADR-F1.3: Extensible Plugin Architecture for Target AI Integration",
      "file_path": "docs/architecture/ADRs/ADR-F1-3_EndpointIntegrationArchitecture.md",
      "requirements": [
        "1.  **Standard Interface**: A standardized **`ProviderPlugin` abstract interface** will be defined in the core application. This interface will specify a set of methods that every plugin must implement (e.g., `send_chat_completion`, `list_available_models`)."
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-003_RBAC+ABAC",
      "title": "ADR-003: Hybrid Authorization Model using RBAC and ABAC",
      "file_path": "docs/architecture/ADRs/ADR-003_RBAC+ABAC.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-F2-1_VulnerabilityTaxonomies",
      "title": "ADR-F2.1: Database-Driven Vulnerability Taxonomy Model",
      "file_path": "docs/architecture/ADRs/ADR-F2-1_VulnerabilityTaxonomies.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-009_ErrorandResponses",
      "title": "ADR-009: Standardized Error Handling with RFC 7807",
      "file_path": "docs/architecture/ADRs/ADR-009_ErrorandResponses.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-006_DataSerializationFormat",
      "title": "ADR-006: JSON as the Exclusive Data Serialization Format",
      "file_path": "docs/architecture/ADRs/ADR-006_DataSerializationFormat.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-010_SoftwareDependencies",
      "title": "ADR-010: Automated Dependency Management and SCA Policy",
      "file_path": "docs/architecture/ADRs/ADR-010_SoftwareDependencies.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-F1-1_TemplatingEngine",
      "title": "ADR-F1.1: Sandboxed Templating Engine for Attack Payloads",
      "file_path": "docs/architecture/ADRs/ADR-F1-1_TemplatingEngine.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-005_RateLimiting",
      "title": "ADR-005: Multi-Layered Rate Limiting and Resource Consumption Policy",
      "file_path": "docs/architecture/ADRs/ADR-005_RateLimiting.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-007_Auth_Failover",
      "title": "ADR-007: Authentication Failover Mechanisms",
      "file_path": "docs/architecture/ADRs/ADR-007_Auth_Failover.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-008_LoggingandAuditing",
      "title": "ADR-008: Structured JSON Logging for Multi-Tenant Auditing and Observability",
      "file_path": "docs/architecture/ADRs/ADR-008_LoggingandAuditing.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-F3-1_ScoringArchitecture",
      "title": "ADR-F3.1: Hybrid Scoring Architecture for Model Risk Analysis",
      "file_path": "docs/architecture/ADRs/ADR-F3-1_ScoringArchitecture.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-001_RESTstyle",
      "title": "ADR-001: Adopt REST for Standalone API Endpoints",
      "file_path": "docs/architecture/ADRs/ADR-001_RESTstyle.md",
      "requirements": [
        "The ViolentUTF API will adopt and enhance a **RESTful architectural style** for all public-facing endpoints. This decision reaffirms the existing approach but adapts it to meet the new requirements of a standalone, GSA-compliant service."
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-F1-2_ServersideOrchestration",
      "title": "ADR-F1.2: Server-Side Orchestration for Multi-Turn Attacks",
      "file_path": "docs/architecture/ADRs/ADR-F1-2_ServersideOrchestration.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-F4-1_UntrustedModelInteractions",
      "title": "ADR-F4.1: Container-based Sandboxing for Untrusted Model Execution",
      "file_path": "docs/architecture/ADRs/ADR-F4-1_UntrustedModelInteractions.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-002_Authentication",
      "title": "ADR-002: Phased Authentication Strategy using JWT and API Keys",
      "file_path": "docs/architecture/ADRs/ADR-002_Authentication.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-F2-2_DataStorage",
      "title": "ADR-F2.2: Polyglot Persistence Strategy for Session Evidence",
      "file_path": "docs/architecture/ADRs/ADR-F2-2_DataStorage.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-F4-2_SecretManagement",
      "title": "ADR-F4.2: Centralized Secrets Management for Target System Credentials",
      "file_path": "docs/architecture/ADRs/ADR-F4-2_SecretManagement.md",
      "requirements": [
        "3.  **Just-in-Time (JIT) Retrieval**: Application services (e.g., background workers) will retrieve secrets from the manager on a just-in-time basis immediately before they are needed. Secrets will only be held in memory for the minimal time required and will never be written to disk."
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-F3-2_ReportGeneration",
      "title": "ADR-F3.2: Server-Side Engine for Automated Report Generation",
      "file_path": "docs/architecture/ADRs/ADR-F3-2_ReportGeneration.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    }
  ],
  "adr_compliance": {
    "ADR-011_HistoricalCodeAnalysis": {
      "adr_id": "ADR-011_HistoricalCodeAnalysis",
      "compliance_score": 89.2,
      "violations": [
        {
          "file_path": "tools/pre_audit/historical_analyzer.py",
          "line_number": 1254,
          "description": "Missing --min-risk parameter validation range enforcement - ADR specifies reasonable bounds checking but implementation allows any float value",
          "risk_level": "medium",
          "remediation_suggestion": "Add validation: if args.min_risk < 0.0 or args.min_risk > 100.0: logger.error('min-risk must be between 0.0 and 100.0'); sys.exit(1)",
          "confidence": 0.85
        },
        {
          "file_path": "tools/pre_audit/historical_analyzer.py",
          "line_number": 1125,
          "description": "Report path enhancement may fail silently - ADR requires comprehensive error handling but implementation has generic exception catch",
          "risk_level": "low",
          "remediation_suggestion": "Replace generic except Exception with specific exceptions for better error reporting and debugging",
          "confidence": 0.72
        },
        {
          "file_path": "config/violation_patterns.yml",
          "line_number": 418,
          "description": "Configuration file truncated at line 418 - ADR specifies comprehensive coverage of 20+ ADRs but implementation appears incomplete",
          "risk_level": "medium",
          "remediation_suggestion": "Verify complete configuration file covers all implemented ADRs including ADR-011 itself and other recent ADRs",
          "confidence": 0.78
        },
        {
          "file_path": "tools/pre_audit/historical_analyzer.py",
          "line_number": 665,
          "description": "Default configuration path uses hardcoded relative path which may not work in all deployment scenarios",
          "risk_level": "low",
          "remediation_suggestion": "Use absolute path resolution or environment-variable-based path discovery for better deployment flexibility",
          "confidence": 0.68
        },
        {
          "file_path": "tools/pre_audit/historical_analyzer.py",
          "line_number": 796,
          "description": "Analysis duration calculation lacks bounds checking - potential division by zero handled but with magic number 0.001",
          "risk_level": "low",
          "remediation_suggestion": "Use more robust duration calculation with proper constants and explain why 0.001 is chosen",
          "confidence": 0.65
        }
      ],
      "compliant_areas": [
        "Core Architecture Components: All 5 components (Git History Parser, ADR Pattern Matcher, Multi-Factor Risk Scorer, Report Generator, Security Layer) properly implemented",
        "PyDriller Integration: Correct usage of PyDriller for Git history traversal with proper commit filtering and merge commit exclusion",
        "Multi-Factor Risk Scoring: Sophisticated risk algorithm implemented with frequency, recency, severity, and complexity factors as specified",
        "Security-First Design: Comprehensive input validation, path traversal protection, and resource limits properly implemented",
        "Configuration System: YAML-based violation patterns with 20+ ADR mappings correctly structured",
        "Performance Optimization: Caching, parallel processing, and efficient algorithms implemented with 100+ commits/second capability",
        "Report Generation: Comprehensive Markdown reports with descriptive naming and executive summaries",
        "CLI Interface: Complete argument parsing with help documentation and usage examples",
        "Temporal Risk Weighting: Recent violations weighted higher with logarithmic normalization for extreme values",
        "Pattern-Driven Detection: Configurable violation patterns mapped to specific ADRs with confidence scoring",
        "Resource Protection: File size limits, memory leak prevention, and timeout protection implemented",
        "Error Handling: Structured error reporting with appropriate logging levels and graceful degradation",
        "Complexity Analysis: Lizard integration for cyclomatic complexity analysis with security validation",
        "Git Repository Validation: Proper Git repository structure validation with security checks",
        "File Pattern Matching: Sophisticated glob pattern matching with exclude patterns support"
      ],
      "recommendations": [
        "Add comprehensive unit test suite as mentioned in ADR-011 future enhancements section",
        "Implement web-based dashboard for trend visualization as outlined in medium-term goals",
        "Add machine learning enhancement for pattern recognition as specified in long-term plans",
        "Create integration with CI/CD pipelines as recommended in operational integration section",
        "Develop automated remediation suggestion engine mentioned in long-term enhancements",
        "Add multi-repository analysis capabilities for microservices architecture support",
        "Implement real-time violation detection and alerting system",
        "Create comprehensive documentation for pattern configuration and customization"
      ],
      "analysis_timestamp": "2025-08-06T01:15:19.563964+00:00",
      "files_analyzed": [
        "docs/architecture/ADRs/ADR-011_HistoricalCodeAnalysis.md",
        "tools/pre_audit/historical_analyzer.py",
        "config/violation_patterns.yml",
        "tools/pre_audit/git_pattern_matcher.py",
        "tools/pre_audit/statistical_analysis/statistical_hotspot_orchestrator.py",
        "tools/pre_audit/reporting/base.py",
        "test_reports/adr_audit_report_20250805_182328.json",
        "docs/reports/ADRaudit-claudecode/reports/ADRaudit_GENERALSECURITYViolations_21commits_130files_20250805.md"
      ],
      "analysis_summary": "ADR-011 HistoricalCodeAnalysis shows excellent compliance at 89.2%. The implementation successfully delivers all core architectural components with sophisticated multi-factor risk scoring, comprehensive security measures, and performance optimization. The tool processes 100+ commits per second and generates detailed reports with actionable recommendations. Minor improvements needed in parameter validation bounds and error handling specificity. The actual implementation demonstrates working capability through successful analysis of 93 commits, identifying 21 violations across 130 files with proper risk scoring and report generation. The ADR's goals of systematic ADR compliance auditing through Git history forensics have been successfully achieved."
    },
    "ADR-007_AsyncTaskProcessing": {
      "adr_id": "ADR-007_AsyncTaskProcessing",
      "compliance_score": 15.0,
      "violations": [
        {
          "file_path": "app/api/routes.py",
          "line_number": 1,
          "description": "CRITICAL: No async task endpoints implemented. ADR requires /api/v1/scans and /api/v1/tasks endpoints for HTTP Polling pattern but these are completely missing from the API router configuration.",
          "risk_level": "critical",
          "remediation_suggestion": "Create scans.py and tasks.py endpoint files and register them in routes.py with proper 202 Accepted responses",
          "confidence": 0.95
        },
        {
          "file_path": "requirements.txt",
          "line_number": 28,
          "description": "CRITICAL: Redis dependency exists but no Celery task queue system implemented. ADR mandates Celery for backend task processing but it's entirely absent from dependencies and implementation.",
          "risk_level": "critical",
          "remediation_suggestion": "Add celery>=5.3.0 to requirements.txt and implement celery worker configuration",
          "confidence": 0.98
        },
        {
          "file_path": "app/models/__init__.py",
          "line_number": 20,
          "description": "CRITICAL: No Task model exists for tracking async jobs. ADR requires task records in database with PENDING/RUNNING/SUCCESS states but no such model is implemented.",
          "risk_level": "critical",
          "remediation_suggestion": "Create Task model with fields: id, status, task_type, result_url, webhook_url, created_at, updated_at",
          "confidence": 0.95
        },
        {
          "file_path": "app/core/config.py",
          "line_number": 64,
          "description": "HIGH: Redis configured but no task queue or worker configuration. ADR requires message broker setup for Celery but implementation is missing.",
          "risk_level": "high",
          "remediation_suggestion": "Add CELERY_BROKER_URL, CELERY_RESULT_BACKEND, and worker configuration settings",
          "confidence": 0.9
        },
        {
          "file_path": "app/main.py",
          "line_number": 238,
          "description": "HIGH: No Celery worker process or task queue initialization in application startup. ADR requires dedicated worker processes but they're not configured.",
          "risk_level": "high",
          "remediation_suggestion": "Add Celery app initialization and worker startup configuration in lifespan handler",
          "confidence": 0.88
        },
        {
          "file_path": "app/api/endpoints/",
          "line_number": 1,
          "description": "CRITICAL: No scan initiation endpoints exist. ADR specifically requires POST /api/v1/scans to initiate long-running tasks like PyRIT orchestrator or Garak scans.",
          "risk_level": "critical",
          "remediation_suggestion": "Create scans.py with endpoints for initiating PyRIT orchestrator and Garak security scans",
          "confidence": 0.95
        },
        {
          "file_path": "app/api/endpoints/",
          "line_number": 1,
          "description": "CRITICAL: No task status polling endpoints. ADR mandates GET /api/v1/tasks/{task_id} for HTTP polling pattern but this endpoint doesn't exist.",
          "risk_level": "critical",
          "remediation_suggestion": "Create tasks.py with status checking endpoint returning task status, progress, and result URLs",
          "confidence": 0.95
        },
        {
          "file_path": "app/schemas/__init__.py",
          "line_number": 1,
          "description": "HIGH: No task-related schemas defined. ADR requires schemas for task creation, status responses, and webhook payloads.",
          "risk_level": "high",
          "remediation_suggestion": "Create TaskCreate, TaskStatus, TaskResponse, and WebhookPayload schemas with proper validation",
          "confidence": 0.85
        },
        {
          "file_path": "app/services/",
          "line_number": 1,
          "description": "CRITICAL: No task service layer for managing async operations. ADR requires service layer to handle task creation, status tracking, and webhook delivery.",
          "risk_level": "critical",
          "remediation_suggestion": "Create TaskService class with methods for create_task, get_task_status, update_task_status, and send_webhook",
          "confidence": 0.9
        }
      ],
      "compliant_areas": [
        "Redis caching infrastructure partially supports message broker requirements",
        "FastAPI framework supports async operations and 202 status codes",
        "Database infrastructure can support task tracking models"
      ],
      "recommendations": [
        "IMMEDIATE: Add Celery to dependencies and configure task queue infrastructure",
        "IMMEDIATE: Create Task database model with proper status tracking and relationships",
        "HIGH PRIORITY: Implement POST /api/v1/scans endpoint with 202 Accepted response pattern",
        "HIGH PRIORITY: Implement GET /api/v1/tasks/{task_id} endpoint for HTTP polling",
        "HIGH PRIORITY: Create worker processes for PyRIT orchestrator and Garak scan execution",
        "MEDIUM PRIORITY: Add webhook support with signature verification for advanced clients",
        "MEDIUM PRIORITY: Implement result storage and retrieval endpoints",
        "LOW PRIORITY: Add task result cleanup and archival processes"
      ],
      "analysis_timestamp": "2025-08-06T01:16:37.558295+00:00",
      "files_analyzed": [
        "docs/architecture/ADRs/ADR-007_AsyncTaskProcessing.md",
        "app/main.py",
        "app/api/routes.py",
        "app/api/endpoints/__init__.py",
        "app/api/endpoints/upload.py",
        "app/models/__init__.py",
        "app/core/config.py",
        "requirements.txt",
        "pyproject.toml"
      ],
      "analysis_summary": "CRITICAL NON-COMPLIANCE: The codebase has ZERO implementation of ADR-007 requirements. No async task processing, no Celery workers, no task endpoints, no task models, and no webhook support. This represents a complete gap between architectural intent and implementation. The API currently only supports synchronous operations, which directly violates the ADR's core requirement for handling long-running PyRIT and Garak tasks. Immediate architectural changes required."
    },
    "ADR-004_Versioning": {
      "adr_id": "ADR-004_Versioning",
      "compliance_score": 72.5,
      "violations": [
        {
          "file_path": "app/api/routes.py",
          "line_number": 21,
          "description": "API router structure does not implement versioned prefixes using APIRouter instances for different versions. All endpoints are included under a single router without version-specific organization.",
          "risk_level": "high",
          "remediation_suggestion": "Implement version-specific APIRouter instances (e.g., v1_router, v2_router) and structure routing to support concurrent API versions as specified in ADR-004",
          "confidence": 0.95
        },
        {
          "file_path": "app/main.py",
          "line_number": 216,
          "description": "Application router mounting uses a single API_V1_STR prefix without provisions for multiple concurrent versions. No backend architecture for handling version-specific controllers exists.",
          "risk_level": "high",
          "remediation_suggestion": "Modify the application startup to support multiple versioned routers and implement shared business logic services called by version-specific controllers",
          "confidence": 0.9
        },
        {
          "file_path": "app/core/config.py",
          "line_number": 31,
          "description": "Configuration hardcodes API_V1_STR without provisions for API_V2_STR or dynamic version configuration. No support for managing multiple concurrent API versions.",
          "risk_level": "medium",
          "remediation_suggestion": "Add configuration support for multiple API versions (API_V1_STR, API_V2_STR) and implement version-specific settings management",
          "confidence": 0.85
        },
        {
          "file_path": "app/api/endpoints/auth.py",
          "line_number": 26,
          "description": "No implementation of deprecation headers (Deprecation, Warning) in API responses as required by ADR-004 deprecation policy.",
          "risk_level": "medium",
          "remediation_suggestion": "Implement middleware or response handling to add Deprecation and Warning headers for deprecated API versions",
          "confidence": 0.8
        },
        {
          "file_path": "app/main.py",
          "line_number": 146,
          "description": "OpenAPI documentation generation does not support version-specific documentation paths. No provisions for /api/v1/docs, /api/v2/docs separation.",
          "risk_level": "medium",
          "remediation_suggestion": "Implement version-specific OpenAPI documentation generation with separate docs endpoints for each API version",
          "confidence": 0.85
        }
      ],
      "compliant_areas": [
        "URI path versioning format follows /api/v{major_version} pattern as specified",
        "OpenAPI 3.x specification compatibility maintained in main.py",
        "FastAPI framework properly supports version-specific routing capabilities",
        "Security middleware and authentication work consistently with versioned endpoints",
        "Configuration system provides foundation for version management"
      ],
      "recommendations": [
        "Implement version-specific APIRouter structure in app/api/routes.py to support concurrent API versions",
        "Add deprecation middleware to automatically inject Deprecation and Warning headers for deprecated versions",
        "Extend configuration system to support multiple API version settings (API_V1_STR, API_V2_STR, etc.)",
        "Create shared business logic services that can be consumed by version-specific controllers",
        "Implement CI/CD pipeline support for managing and deploying multiple API versions concurrently",
        "Add comprehensive testing for version-specific functionality and backward compatibility",
        "Implement version-specific OpenAPI documentation generation and serving",
        "Create migration guides and tools for clients transitioning between API versions"
      ],
      "analysis_timestamp": "2025-08-06T01:17:54.113415+00:00",
      "files_analyzed": [
        "app/main.py",
        "app/api/routes.py",
        "app/api/base.py",
        "app/core/config.py",
        "app/api/endpoints/auth.py",
        "app/api/endpoints/users.py",
        "app/middleware/permissions.py",
        "app/middleware/authentication.py",
        "tests/integration/test_startup.py",
        "tests/security/test_request_signing.py"
      ],
      "analysis_summary": "The ViolentUTF API partially implements URI path versioning with /api/v1 prefix but lacks the comprehensive versioning architecture required by ADR-004. Critical missing elements include concurrent version support, deprecation headers, version-specific documentation, and backend architecture for managing multiple versions. The current implementation provides a foundation but requires significant enhancements to fully comply with the ADR requirements for production-ready API versioning."
    },
    "ADR-F1-3_EndpointIntegrationArchitecture": {
      "adr_id": "ADR-F1-3_EndpointIntegrationArchitecture",
      "compliance_score": 15.0,
      "violations": [
        {
          "file_path": "app/main.py",
          "line_number": 1,
          "description": "Missing ProviderPlugin abstract interface implementation. The main application does not define or import the required ProviderPlugin abstract base class as specified in lines 85-116 of the ADR.",
          "risk_level": "critical",
          "remediation_suggestion": "Create app/providers/base.py with the ProviderPlugin abstract interface including send_chat_completion, list_available_models, and validate_credentials methods",
          "confidence": 0.98
        },
        {
          "file_path": "app/",
          "line_number": 1,
          "description": "Missing plugin discovery mechanism. The ADR specifies that plugins should be discovered by scanning a violentutf_api/plugins/ directory at startup (line 120-121), but no such directory or discovery mechanism exists.",
          "risk_level": "critical",
          "remediation_suggestion": "Create app/providers/plugins/ directory structure and implement plugin discovery in app/core/startup.py to automatically register plugin modules",
          "confidence": 0.99
        },
        {
          "file_path": "app/models/",
          "line_number": 1,
          "description": "Missing Generator database model. The ADR specifies a Generator database schema with name, plugin_name, model_id, and credentials_id fields (lines 122-130), but no such model exists in app/models/",
          "risk_level": "critical",
          "remediation_suggestion": "Create app/models/generator.py with Generator model including name, plugin_name, model_id, and credentials_id fields as specified in the ADR",
          "confidence": 0.97
        },
        {
          "file_path": "app/core/external_services.py",
          "line_number": 38,
          "description": "Generic external services implementation does not follow the specific ProviderPlugin pattern. While AI_MODEL service type exists, it lacks the standardized send_chat_completion, list_available_models, and validate_credentials interface methods required by the ADR.",
          "risk_level": "high",
          "remediation_suggestion": "Refactor external_services.py to implement provider-specific plugins that inherit from ProviderPlugin interface or create separate plugin system alongside existing external services",
          "confidence": 0.85
        },
        {
          "file_path": "app/core/startup.py",
          "line_number": 13,
          "description": "Startup handler does not implement plugin registration. The ADR requires dynamic loading and registration of plugins at application startup, but on_startup() only initializes cache and auth services.",
          "risk_level": "high",
          "remediation_suggestion": "Add plugin discovery and registration logic to on_startup() function to scan plugins directory and register ProviderPlugin implementations",
          "confidence": 0.92
        },
        {
          "file_path": "app/",
          "line_number": 1,
          "description": "Missing provider-specific plugin implementations. The ADR explicitly mentions OpenAI, Anthropic, and Ollama as examples, but no concrete plugin implementations exist for any AI providers.",
          "risk_level": "critical",
          "remediation_suggestion": "Create concrete plugin implementations such as app/providers/plugins/openai_plugin.py, app/providers/plugins/anthropic_plugin.py that implement the ProviderPlugin interface",
          "confidence": 0.96
        },
        {
          "file_path": "app/repositories/",
          "line_number": 1,
          "description": "Missing Generator repository for managing generator configurations. The ADR implies CRUD operations for Generator entities, but no repository exists for managing generators.",
          "risk_level": "medium",
          "remediation_suggestion": "Create app/repositories/generator.py with GeneratorRepository class to handle CRUD operations for Generator entities",
          "confidence": 0.88
        },
        {
          "file_path": "app/api/endpoints/",
          "line_number": 1,
          "description": "Missing Generator management endpoints. The ADR describes generators as user-configurable endpoints, but no API endpoints exist for managing generator configurations.",
          "risk_level": "medium",
          "remediation_suggestion": "Create app/api/endpoints/generators.py with endpoints for creating, reading, updating, and deleting generator configurations",
          "confidence": 0.9
        },
        {
          "file_path": "app/db/base.py",
          "line_number": 11,
          "description": "Database schema missing Generator table registration. The base.py file imports models for Alembic discovery but does not include any Generator model import.",
          "risk_level": "medium",
          "remediation_suggestion": "Add 'from app.models.generator import Generator' import to base.py after creating the Generator model",
          "confidence": 0.94
        }
      ],
      "compliant_areas": [
        "External services framework provides circuit breaker and retry mechanisms suitable for external API calls",
        "Configuration management system supports dynamic service registration patterns",
        "Modular architecture in app/ directory structure supports plugin-based extension"
      ],
      "recommendations": [
        "Implement the complete ProviderPlugin architecture as specified in the ADR before adding specific provider integrations",
        "Create a plugin registry system to manage provider plugin lifecycle and configuration",
        "Implement generator configuration management with proper CRUD operations and API endpoints",
        "Add comprehensive error handling for plugin failures to prevent cascading system failures as mentioned in ADR rationale",
        "Consider migrating existing external_services.py AI_MODEL functionality to the new plugin system for consistency"
      ],
      "analysis_timestamp": "2025-08-06T01:19:00.249389+00:00",
      "files_analyzed": [
        "app/main.py",
        "app/core/config.py",
        "app/core/startup.py",
        "app/core/external_services.py",
        "app/models/__init__.py",
        "app/db/base.py",
        "app/api/endpoints/",
        "app/services/"
      ],
      "analysis_summary": "The codebase shows a 15% compliance with ADR-F1-3_EndpointIntegrationArchitecture. While a solid foundation exists with external services framework and modular architecture, the core Plugin System architecture is completely missing. Critical violations include the absence of the ProviderPlugin abstract interface, plugin discovery mechanism, Generator database model, and concrete provider implementations. The existing external_services.py provides some relevant functionality but does not follow the specific architectural pattern mandated by the ADR. Immediate implementation of the plugin architecture is required to achieve ADR compliance."
    },
    "ADR-003_RBAC+ABAC": {
      "adr_id": "ADR-003_RBAC+ABAC",
      "compliance_score": 45.0,
      "violations": [
        {
          "file_path": "app/middleware/authentication.py",
          "line_number": 114,
          "description": "JWT payload missing 'organization_id' claim required by ADR-003. Only 'sub' and 'roles' claims are extracted, but ABAC layer requires organization_id for multi-tenant data isolation.",
          "risk_level": "critical",
          "remediation_suggestion": "Add organization_id extraction from JWT payload: request.state.organization_id = payload.get('organization_id')",
          "confidence": 0.95
        },
        {
          "file_path": "app/repositories/base.py",
          "line_number": 97,
          "description": "Base repository missing ABAC enforcement - queries do not filter by organization_id. ADR-003 requires all data access queries to filter by organization_id from user's token.",
          "risk_level": "critical",
          "remediation_suggestion": "Add organization_id filtering to all data access methods in BaseRepository and override in specific repositories",
          "confidence": 0.9
        },
        {
          "file_path": "app/api/endpoints/users.py",
          "line_number": 304,
          "description": "User endpoint missing ABAC organization_id filtering. Current user lookup does not enforce organization boundary as required by ADR-003.",
          "risk_level": "high",
          "remediation_suggestion": "Add organization_id filtering to user repository calls and ensure queries include AND organization_id = :org_id clause",
          "confidence": 0.88
        },
        {
          "file_path": "app/api/endpoints/api_keys.py",
          "line_number": 324,
          "description": "API Key listing missing organization_id filtering. Users can potentially access API keys from other organizations violating ABAC requirements.",
          "risk_level": "high",
          "remediation_suggestion": "Add organization_id filtering to API key repository queries to ensure tenant data isolation",
          "confidence": 0.85
        },
        {
          "file_path": "app/core/permissions.py",
          "line_number": 232,
          "description": "Permission checking system lacks organization context. RBAC service calls don't consider organization_id for permission checks, violating hybrid RBAC+ABAC model.",
          "risk_level": "high",
          "remediation_suggestion": "Modify permission checking to include organization context and validate user permissions within their organization scope",
          "confidence": 0.82
        },
        {
          "file_path": "app/models/user.py",
          "line_number": 95,
          "description": "User model defines roles as simple array but lacks organization-scoped roles. ADR-003 requires roles to be organization-aware for proper RBAC implementation.",
          "risk_level": "medium",
          "remediation_suggestion": "Consider implementing organization-scoped roles or ensure role validation considers organization context",
          "confidence": 0.78
        },
        {
          "file_path": "app/services/rbac_service.py",
          "line_number": 324,
          "description": "RBAC service get_user_roles method missing organization filtering. Roles should be scoped to user's organization per ADR-003 requirements.",
          "risk_level": "high",
          "remediation_suggestion": "Add organization_id parameter to role queries and ensure role assignments are organization-scoped",
          "confidence": 0.85
        }
      ],
      "compliant_areas": [
        "JWT-based authentication system is correctly implemented with token validation",
        "Role-based permission system with proper role definitions (viewer, tester, admin)",
        "RBAC service with comprehensive role management functionality",
        "Security validation mixins prevent injection attacks",
        "Proper audit logging infrastructure in place",
        "BaseModelMixin includes organization_id field for ABAC support"
      ],
      "recommendations": [
        "Implement organization_id extraction from JWT tokens in authentication middleware",
        "Add ABAC filtering to all repository data access methods using organization_id",
        "Update all API endpoints to enforce organization boundary checks",
        "Modify RBAC service to consider organization context in permission checks",
        "Add integration tests to verify both RBAC and ABAC enforcement",
        "Implement organization-scoped role assignments",
        "Add comprehensive logging for authorization decisions",
        "Create organization isolation validation utilities"
      ],
      "analysis_timestamp": "2025-08-06T01:20:29.274006+00:00",
      "files_analyzed": [
        "docs/architecture/ADRs/ADR-003_RBAC+ABAC.md",
        "app/core/auth.py",
        "app/core/permissions.py",
        "app/services/rbac_service.py",
        "app/models/user.py",
        "app/models/role.py",
        "app/models/mixins.py",
        "app/repositories/base.py",
        "app/api/endpoints/users.py",
        "app/api/endpoints/api_keys.py",
        "app/middleware/authentication.py"
      ],
      "analysis_summary": "The codebase shows a partially implemented RBAC+ABAC hybrid authorization model. While RBAC components are well-structured with proper role definitions and permissions, the critical ABAC layer for multi-tenant data isolation is incomplete. The organization_id field exists in models but is not properly extracted from JWT tokens or enforced in data access queries, creating significant security gaps for multi-tenant access control."
    },
    "ADR-F2-1_VulnerabilityTaxonomies": {
      "adr_id": "ADR-F2-1_VulnerabilityTaxonomies",
      "compliance_score": 0.0,
      "violations": [
        {
          "file_path": "app/db/base.py",
          "line_number": 9,
          "description": "Missing import for vulnerability_taxonomies model - ADR requires database tables for vulnerability classification but no models exist",
          "risk_level": "critical",
          "remediation_suggestion": "Create VulnerabilityTaxonomy and TaxonomyMapping models as specified in ADR schema",
          "confidence": 0.99
        },
        {
          "file_path": "app/models/__init__.py",
          "line_number": 12,
          "description": "No vulnerability taxonomy models exported - ADR requires VulnerabilityTaxonomy model but it's missing from __all__",
          "risk_level": "critical",
          "remediation_suggestion": "Create VulnerabilityTaxonomy and TaxonomyMapping models and add them to __all__",
          "confidence": 0.99
        },
        {
          "file_path": "alembic/versions/0d9d1d5fbe10_initial_database_models_with_.py",
          "line_number": 194,
          "description": "Missing database tables for vulnerability taxonomy - ADR specifies vulnerability_taxonomies and taxonomy_mappings tables but they were never created",
          "risk_level": "critical",
          "remediation_suggestion": "Create new Alembic migration to add vulnerability_taxonomies and taxonomy_mappings tables with specified schema",
          "confidence": 0.99
        },
        {
          "file_path": "app/api/routes.py",
          "line_number": 120,
          "description": "Missing API endpoints for vulnerability taxonomy management - ADR requires ability to manage vulnerability classifications via API",
          "risk_level": "high",
          "remediation_suggestion": "Create vulnerability taxonomy API endpoints for CRUD operations on taxonomies and mappings",
          "confidence": 0.95
        },
        {
          "file_path": "app/schemas/__init__.py",
          "line_number": 1,
          "description": "No Pydantic schemas for vulnerability taxonomies - ADR requires data validation for vulnerability classification",
          "risk_level": "high",
          "remediation_suggestion": "Create VulnerabilityTaxonomySchema and TaxonomyMappingSchema for API validation",
          "confidence": 0.95
        },
        {
          "file_path": "app/repositories/__init__.py",
          "line_number": 1,
          "description": "Missing repository classes for vulnerability taxonomy data access - ADR requires database-driven taxonomy but no data access layer exists",
          "risk_level": "high",
          "remediation_suggestion": "Create VulnerabilityTaxonomyRepository and TaxonomyMappingRepository for data access",
          "confidence": 0.95
        }
      ],
      "compliant_areas": [
        "Database infrastructure (SQLAlchemy 2.0, Alembic migrations) is properly configured",
        "BaseModelMixin provides audit trails suitable for tracking taxonomy changes",
        "API architecture supports adding new endpoints for taxonomy management",
        "Security validation mixins exist to prevent injection attacks on taxonomy data"
      ],
      "recommendations": [
        "Immediately create VulnerabilityTaxonomy model with fields: id, name, description, remediation_advice, parent_id, default_severity",
        "Create TaxonomyMapping model with fields: id, taxonomy_id, framework_name, framework_id, framework_url",
        "Generate Alembic migration to create the required database tables with proper indexes",
        "Implement API endpoints for CRUD operations on vulnerability taxonomies",
        "Create data seeding script to populate initial OWASP LLM Top 10 classifications",
        "Add repository and service layers for taxonomy data management",
        "Implement hierarchical queries for parent-child taxonomy relationships",
        "Create Pydantic schemas for request/response validation",
        "Add comprehensive tests for the taxonomy system",
        "Document the taxonomy management API endpoints"
      ],
      "analysis_timestamp": "2025-08-06T01:21:36.301007+00:00",
      "files_analyzed": [
        "docs/architecture/ADRs/ADR-F2-1_VulnerabilityTaxonomies.md",
        "app/models/__init__.py",
        "app/db/base.py",
        "alembic/versions/0d9d1d5fbe10_initial_database_models_with_.py",
        "app/core/config.py",
        "app/db/base_class.py",
        "app/models/mixins.py",
        "app/main.py",
        "app/api/routes.py",
        "pyproject.toml"
      ],
      "analysis_summary": "Complete non-compliance with ADR-F2-1. The vulnerability taxonomy system mandated by the ADR is entirely missing from the codebase. No database models, tables, API endpoints, or data access layers exist for vulnerability classification. This represents a critical architectural gap that prevents the AI red-teaming platform from properly categorizing and reporting security findings according to industry standards like OWASP LLM Top 10 or MITRE ATLAS."
    },
    "ADR-009_ErrorandResponses": {
      "adr_id": "ADR-009_ErrorandResponses",
      "compliance_score": 15.2,
      "violations": [
        {
          "file_path": "app/core/errors.py",
          "line_number": 15,
          "description": "ErrorDetail model uses custom format instead of RFC 7807 structure. Missing required fields: 'type', 'title', 'status', 'detail', 'instance'. Using non-standard fields: 'error', 'message', 'request_id', 'path', 'timestamp'",
          "risk_level": "critical",
          "remediation_suggestion": "Replace ErrorDetail with RFC 7807 compliant model containing 'type', 'title', 'status', 'detail', 'instance' fields, plus custom 'correlation_id' and 'error_code' extensions",
          "confidence": 0.98
        },
        {
          "file_path": "app/core/errors.py",
          "line_number": 153,
          "description": "Error responses not using 'application/problem+json' content type as required by RFC 7807",
          "risk_level": "critical",
          "remediation_suggestion": "Add Content-Type header 'application/problem+json' to all JSONResponse error returns",
          "confidence": 0.99
        },
        {
          "file_path": "app/core/errors.py",
          "line_number": 121,
          "description": "Missing Error Dictionary implementation. No centralized mapping of error codes to RFC 7807 type URIs as specified in ADR",
          "risk_level": "high",
          "remediation_suggestion": "Create error_dictionary.py with mappings like {'VUTF-1001': {'status': 400, 'title': 'Validation Error', 'type': '/errors/validation-error'}}",
          "confidence": 0.95
        },
        {
          "file_path": "app/core/errors.py",
          "line_number": 132,
          "description": "Using 'request_id' instead of 'correlation_id' as specified in ADR-009. Also missing 'error_code' field",
          "risk_level": "medium",
          "remediation_suggestion": "Change field name from 'request_id' to 'correlation_id' and add 'error_code' field to match ADR specification",
          "confidence": 0.97
        },
        {
          "file_path": "app/schemas/base.py",
          "line_number": 182,
          "description": "APIErrorResponse schema exists but implements RFC 7807 structure, however it's not being used in actual error handlers",
          "risk_level": "medium",
          "remediation_suggestion": "Update error handlers in app/core/errors.py to use APIErrorResponse schema instead of ErrorDetail",
          "confidence": 0.85
        },
        {
          "file_path": "app/main.py",
          "line_number": 49,
          "description": "Rate limit handler returns non-RFC 7807 compliant error format with 'detail' and 'type' fields but missing required 'title', 'status', 'instance'",
          "risk_level": "medium",
          "remediation_suggestion": "Update rate_limit_handler to return RFC 7807 compliant response using centralized error handling",
          "confidence": 0.9
        },
        {
          "file_path": "app/middleware/request_signing.py",
          "line_number": 95,
          "description": "Multiple middleware files returning ad-hoc error responses instead of using centralized RFC 7807 handler",
          "risk_level": "medium",
          "remediation_suggestion": "Replace direct JSONResponse usage with centralized error handling that enforces RFC 7807 format",
          "confidence": 0.88
        }
      ],
      "compliant_areas": [
        "Centralized exception handling mechanism exists via setup_error_handlers()",
        "Global exception handler implemented for unexpected errors",
        "Development mode check prevents information leakage in production",
        "Structured logging implemented for error tracking"
      ],
      "recommendations": [
        "Implement RFC 7807 compliant error response model replacing ErrorDetail",
        "Create centralized Error Dictionary mapping error codes to RFC 7807 types",
        "Add 'application/problem+json' Content-Type to all error responses",
        "Replace 'request_id' with 'correlation_id' throughout error handling",
        "Update all middleware to use centralized error handling instead of direct JSONResponse",
        "Add comprehensive test suite to verify RFC 7807 compliance",
        "Document error codes and type URIs as specified in ADR requirements"
      ],
      "analysis_timestamp": "2025-08-06T01:22:49.936482+00:00",
      "files_analyzed": [
        "docs/architecture/ADRs/ADR-009_ErrorandResponses.md",
        "app/core/errors.py",
        "app/main.py",
        "app/schemas/base.py",
        "app/api/endpoints/auth.py",
        "app/api/endpoints/sessions.py",
        "app/middleware/logging.py",
        "app/middleware/request_signing.py",
        "app/core/config.py",
        "pyproject.toml"
      ],
      "analysis_summary": "The codebase has a foundation for error handling but lacks critical RFC 7807 compliance. While centralized exception handlers exist, they implement a custom error format instead of RFC 7807. The required Error Dictionary, correlation_id field, error_code extensions, and application/problem+json content type are all missing. Multiple middleware files bypass centralized handling with ad-hoc responses."
    },
    "ADR-006_DataSerializationFormat": {
      "adr_id": "ADR-006_DataSerializationFormat",
      "compliance_score": 82.5,
      "violations": [
        {
          "file_path": "app/api/endpoints/audit_logs.py",
          "line_number": 620,
          "description": "Export endpoint supports CSV format (text/csv) in addition to JSON, violating the ADR requirement for JSON-only data serialization",
          "risk_level": "medium",
          "remediation_suggestion": "Remove CSV export functionality and provide JSON-only exports, or document this as an approved exception for data export requirements",
          "confidence": 0.95
        },
        {
          "file_path": "app/api/endpoints/oauth.py",
          "line_number": 220,
          "description": "OAuth authorization endpoint uses HTMLResponse for user authorization flow, violating JSON-only requirement",
          "risk_level": "high",
          "remediation_suggestion": "Refactor OAuth authorization flow to use JSON-based API responses with separate frontend handling, or document as approved exception for OAuth2 specification compliance",
          "confidence": 0.9
        },
        {
          "file_path": "app/api/endpoints/oauth.py",
          "line_number": 235,
          "description": "OAuth authorization page returns HTML content directly from API endpoint",
          "risk_level": "high",
          "remediation_suggestion": "Separate HTML OAuth pages from API endpoints and serve via static content or dedicated frontend service",
          "confidence": 0.9
        },
        {
          "file_path": "app/middleware/input_sanitization.py",
          "line_number": 46,
          "description": "Input sanitization middleware explicitly handles text/plain content type, indicating API accepts non-JSON request bodies",
          "risk_level": "medium",
          "remediation_suggestion": "Remove text/plain content type support and restrict to application/json only",
          "confidence": 0.8
        }
      ],
      "compliant_areas": [
        "All Pydantic models are properly configured for JSON serialization with BaseModel inheritance",
        "FastAPI application uses JSON as default response format through Pydantic response_model declarations",
        "Authentication endpoints return JSON responses with proper LoginResponse and UserResponse schemas",
        "CRUD endpoints consistently use JSON for both request and response bodies",
        "Error responses follow RFC 7807 JSON format via APIErrorResponse schema",
        "Request/response middleware assumes application/json as default content type",
        "OpenAPI specification generated by FastAPI defines application/json as the media type"
      ],
      "recommendations": [
        "Remove CSV export functionality from audit logs endpoint to maintain JSON-only compliance",
        "Refactor OAuth2 authorization flow to use JSON APIs with separate frontend for HTML forms",
        "Update input sanitization middleware to reject non-JSON content types",
        "Add explicit content-type validation middleware to enforce application/json requirement",
        "Document any approved exceptions to the JSON-only requirement with business justification"
      ],
      "analysis_timestamp": "2025-08-06T01:23:59.709547+00:00",
      "files_analyzed": [
        "docs/architecture/ADRs/ADR-006_DataSerializationFormat.md",
        "app/main.py",
        "app/schemas/base.py",
        "app/schemas/user.py",
        "app/api/endpoints/auth.py",
        "app/api/endpoints/oauth.py",
        "app/api/endpoints/audit_logs.py",
        "app/api/endpoints/upload.py",
        "app/api/routes.py",
        "app/core/config.py",
        "app/middleware/input_sanitization.py"
      ],
      "analysis_summary": "The API demonstrates strong compliance with JSON-only serialization through consistent use of Pydantic models and FastAPI's built-in JSON handling. However, there are notable violations in the OAuth authorization flow (HTML responses) and audit log exports (CSV format). The middleware also accepts text/plain content, which contradicts the exclusive JSON requirement. Overall compliance is good but requires addressing specific non-JSON response scenarios."
    },
    "ADR-010_SoftwareDependencies": {
      "adr_id": "ADR-010_SoftwareDependencies",
      "compliance_score": 68.5,
      "violations": [
        {
          "file_path": ".github/workflows/pr-validation.yml",
          "line_number": 62,
          "description": "pip-audit is not implemented as a blocking CI/CD step in PR validation workflow. ADR mandates pip-audit as mandatory blocking quality gate, but workflow uses 'safety check' instead on line 62",
          "risk_level": "critical",
          "remediation_suggestion": "Add pip-audit as blocking step with '--fail-on-high --fail-on-critical' flags before the existing safety check",
          "confidence": 0.95
        },
        {
          "file_path": ".github/workflows/ci.yml",
          "line_number": 1,
          "description": "Main CI pipeline lacks pip-audit integration completely. ADR requires pip-audit scanning on every code change, but CI workflow has no dependency vulnerability scanning",
          "risk_level": "high",
          "remediation_suggestion": "Add pip-audit scanning step to quick-quality job with failure conditions for CRITICAL/HIGH vulnerabilities",
          "confidence": 0.92
        },
        {
          "file_path": "security/pip-audit-report.json",
          "line_number": 1,
          "description": "Current pip-audit scan shows 10 vulnerable dependencies (aiohttp, mcp, pillow, protobuf, requests, starlette, torch, tornado, transformers, urllib3) with 12 total vulnerabilities, violating ADR blocking policy",
          "risk_level": "high",
          "remediation_suggestion": "Upgrade or replace vulnerable dependencies immediately as per ADR-010 SLO requirements",
          "confidence": 0.98
        },
        {
          "file_path": "docs/architecture/ADRs/ADR-010_SoftwareDependencies.md",
          "line_number": 77,
          "description": "No formal Vulnerability Management Policy implementation with defined SLOs. ADR specifies CRITICAL (7 days), HIGH (30 days), MEDIUM (90 days) remediation timelines but no enforcement mechanism exists",
          "risk_level": "medium",
          "remediation_suggestion": "Implement automated vulnerability SLO tracking system with alerts and escalation procedures",
          "confidence": 0.85
        },
        {
          "file_path": "docs/architecture/ADRs/ADR-010_SoftwareDependencies.md",
          "line_number": 85,
          "description": "No License Compliance Policy implementation. ADR defines approved (MIT, Apache-2.0), restricted (LGPL), and prohibited (GPL) licenses but no automated checking exists",
          "risk_level": "medium",
          "remediation_suggestion": "Integrate license scanning tools like pip-licenses with CI/CD pipeline to enforce license policy",
          "confidence": 0.88
        },
        {
          "file_path": ".github/workflows/pr-validation.yml",
          "line_number": 62,
          "description": "Safety tool used as primary dependency scanner, but ADR specifically mandates pip-audit. While both are valid SCA tools, this deviates from ADR specifications",
          "risk_level": "medium",
          "remediation_suggestion": "Replace safety with pip-audit as primary scanner, or supplement safety with pip-audit to ensure ADR compliance",
          "confidence": 0.78
        },
        {
          "file_path": ".pre-commit-config.yaml",
          "line_number": 74,
          "description": "No pip-audit integration in pre-commit hooks. While bandit is present, ADR specifically requires pip-audit for dependency vulnerability scanning in development workflow",
          "risk_level": "low",
          "remediation_suggestion": "Add pip-audit hook to pre-commit configuration to catch vulnerabilities during development",
          "confidence": 0.72
        }
      ],
      "compliant_areas": [
        "Dependabot is properly configured with weekly schedules and appropriate groupings for security-tools, development-tools, and api-frameworks",
        "Security scanning tools (bandit, safety, detect-secrets) are integrated in development workflow and scripts",
        "pip-audit tool is installed and available in requirements-dev.txt (version 2.6.0+)",
        "Comprehensive pre-commit hooks with security scanning using bandit and detect-secrets",
        "Semgrep static analysis tool is available in requirements-dev.txt for enhanced security scanning",
        "Development security scripts (check_security.sh, security-scan.sh) implement pip-audit scanning",
        "Security reports directory structure with automated report generation"
      ],
      "recommendations": [
        "Immediately add pip-audit as blocking step in PR validation workflow with '--fail-on-critical --fail-on-high' flags",
        "Integrate pip-audit into main CI pipeline (ci.yml) with appropriate exit codes",
        "Implement formal Vulnerability Management Policy with automated SLO tracking and alerting system",
        "Add license compliance scanning to CI/CD pipeline using tools like pip-licenses",
        "Address the 12 existing vulnerabilities in dependencies according to ADR remediation timelines",
        "Create automated vulnerability dashboard showing compliance with ADR-010 SLO requirements",
        "Integrate semgrep (already available) into CI pipeline for comprehensive static analysis as specified in ADR",
        "Establish formal process for handling vulnerability exceptions with documented compensating controls"
      ],
      "analysis_timestamp": "2025-08-06T01:25:22.312318+00:00",
      "files_analyzed": [
        "docs/architecture/ADRs/ADR-010_SoftwareDependencies.md",
        ".github/dependabot.yml",
        ".github/workflows/security.yml",
        ".github/workflows/ci.yml",
        ".github/workflows/pr-validation.yml",
        ".pre-commit-config.yaml",
        "pyproject.toml",
        "requirements.txt",
        "requirements-dev.txt",
        "security/pip-audit-report.json",
        "scripts/security-scan.sh",
        "check_security.sh"
      ],
      "analysis_summary": "ADR-010 shows moderate compliance (68.5%) with solid tooling foundation but critical enforcement gaps. While Dependabot, security tools, and development workflows are well-implemented, the core requirement for pip-audit as a blocking CI/CD mechanism is missing. The existence of 12 vulnerabilities across 10 dependencies directly violates the ADR's blocking policy. Key missing elements include formal vulnerability management SLOs, license compliance automation, and CI/CD enforcement. The infrastructure exists but requires immediate implementation of blocking mechanisms to achieve full ADR compliance."
    },
    "ADR-F1-1_TemplatingEngine": {
      "adr_id": "ADR-F1-1_TemplatingEngine",
      "compliance_score": 15.0,
      "violations": [
        {
          "file_path": "app/services/",
          "line_number": null,
          "description": "Missing core templating service implementation - no service class found that implements Jinja2 sandboxed templating for attack payloads as specified in ADR",
          "risk_level": "critical",
          "remediation_suggestion": "Create app/services/templating_service.py implementing SandboxedEnvironment with custom filters (base64encode, leetspeak, urlencode, json_escape) and resource limits",
          "confidence": 0.99
        },
        {
          "file_path": "app/api/endpoints/",
          "line_number": null,
          "description": "Missing templating API endpoint - no REST endpoint found for template rendering functionality required by ADR",
          "risk_level": "critical",
          "remediation_suggestion": "Create app/api/endpoints/templating.py with POST /template/render endpoint accepting template and data parameters",
          "confidence": 0.99
        },
        {
          "file_path": "app/schemas/",
          "line_number": null,
          "description": "Missing templating schema models - no Pydantic models found for template request/response validation",
          "risk_level": "high",
          "remediation_suggestion": "Create app/schemas/templating.py with TemplateRequest, TemplateResponse, and TemplateError models",
          "confidence": 0.95
        },
        {
          "file_path": "requirements.txt",
          "line_number": 56,
          "description": "Jinja2 dependency present but no custom filters implementation found - ADR requires base64encode, leetspeak, urlencode, json_escape, reverse filters",
          "risk_level": "high",
          "remediation_suggestion": "Implement custom filter functions in templating service and register them with SandboxedEnvironment",
          "confidence": 0.9
        },
        {
          "file_path": "app/core/",
          "line_number": null,
          "description": "Missing resource limiting implementation - ADR requires CPU time and memory limits for template execution",
          "risk_level": "high",
          "remediation_suggestion": "Implement resource limiting wrapper using multiprocessing or threading with timeout controls in templating service",
          "confidence": 0.85
        },
        {
          "file_path": "tests/",
          "line_number": null,
          "description": "Missing security tests for templating engine - no tests found validating sandbox escape prevention or SSTI protection",
          "risk_level": "high",
          "remediation_suggestion": "Create tests/unit/services/test_templating_security.py with SSTI injection attempt tests and sandbox validation",
          "confidence": 0.9
        },
        {
          "file_path": "app/models/",
          "line_number": null,
          "description": "Missing database models for template storage - no models found for storing user templates or template execution history",
          "risk_level": "medium",
          "remediation_suggestion": "Consider creating Template and TemplateExecution models if persistent storage is required",
          "confidence": 0.75
        }
      ],
      "compliant_areas": [
        "Jinja2 dependency correctly specified in requirements.txt with version constraints",
        "SandboxedEnvironment properly implemented in reporting system (tools/pre_audit/reporting/exporters/html_generator.py) showing understanding of security requirements",
        "Security-focused configuration in app/core/config.py with proper validation patterns",
        "Comprehensive sanitization utilities in app/utils/sanitization.py showing security awareness"
      ],
      "recommendations": [
        "Implement core templating service using existing security patterns from reporting system",
        "Create comprehensive test suite covering SSTI attacks and sandbox escape attempts",
        "Add resource limiting using timeout decorators and process isolation",
        "Implement audit logging for all template executions to track usage patterns",
        "Add rate limiting specifically for template rendering endpoints",
        "Create detailed documentation and examples for custom filter usage",
        "Consider implementing template validation before execution",
        "Add metrics collection for template execution performance monitoring"
      ],
      "analysis_timestamp": "2025-08-06T01:35:39.886369+00:00",
      "files_analyzed": [
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/docs/architecture/ADRs/ADR-F1-1_TemplatingEngine.md",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/requirements.txt",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/security.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/utils/sanitization.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/config.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/tools/pre_audit/reporting/exporters/html_generator.py"
      ],
      "analysis_summary": "ADR-F1-1 TemplatingEngine has a compliance score of 15% due to complete absence of the core templating functionality. While the project shows excellent security practices in the reporting system with proper Jinja2 SandboxedEnvironment implementation, the main templating service for attack payload generation is entirely missing. The ADR requires a templating engine with custom filters for red-teaming purposes, but no implementation exists in the application layer. Critical violations include missing service layer, API endpoints, schemas, and security tests. The project does demonstrate understanding of secure templating practices through the reporting system implementation."
    },
    "ADR-005_RateLimiting": {
      "adr_id": "ADR-005_RateLimiting",
      "compliance_score": 72.5,
      "violations": [
        {
          "file_path": "app/middleware/rate_limiting.py",
          "line_number": 154,
          "description": "Rate limiting middleware bypasses actual enforcement with comment 'Skip actual rate limiting in test/development mode'. This violates ADR-005's requirement for consistent multi-layered protection.",
          "risk_level": "high",
          "remediation_suggestion": "Implement proper rate limiting logic using Redis backend as specified in ADR-005, replacing the test/development bypass",
          "confidence": 0.95
        },
        {
          "file_path": "app/core/rate_limiting.py",
          "line_number": 105,
          "description": "Token Bucket algorithm not properly implemented - using SlowAPI's default implementation instead of the specified Token Bucket algorithm from ADR-005.",
          "risk_level": "medium",
          "remediation_suggestion": "Implement proper Token Bucket algorithm as specified in ADR-005 decision section",
          "confidence": 0.9
        },
        {
          "file_path": "app/core/rate_limiting.py",
          "line_number": 195,
          "description": "Function add_rate_limit_headers() is empty implementation with comment 'Headers are automatically added by SlowAPI'. Missing validation that required headers (X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset) are actually present.",
          "risk_level": "medium",
          "remediation_suggestion": "Implement verification that all required rate limit headers per ADR-005 are included in responses",
          "confidence": 0.88
        },
        {
          "file_path": "app/core/config.py",
          "line_number": 64,
          "description": "Redis URL is optional with default None, but ADR-005 explicitly requires Redis for state management in distributed deployments. Missing enforcement of Redis requirement for production.",
          "risk_level": "high",
          "remediation_suggestion": "Enforce Redis URL as required setting when ENVIRONMENT=production and RATE_LIMIT_ENABLED=True",
          "confidence": 0.92
        },
        {
          "file_path": "app/middleware/rate_limiting.py",
          "line_number": 87,
          "description": "Rate limit headers are added with placeholder values (X-RateLimit-Remaining=0, X-RateLimit-Limit=varies) instead of actual rate limit state, violating ADR-005 transparency requirements.",
          "risk_level": "medium",
          "remediation_suggestion": "Integrate with actual rate limiter state to provide accurate remaining count and reset time",
          "confidence": 0.85
        },
        {
          "file_path": "app/api/endpoints/auth.py",
          "line_number": 20,
          "description": "Rate limiting import present but no evidence of @rate_limit decorator usage on authentication endpoints, violating ADR-005 Layer 3 requirement for authentication endpoint protection.",
          "risk_level": "high",
          "remediation_suggestion": "Apply @rate_limit('auth_login') decorator to login endpoints and other auth endpoints as specified in ADR-005",
          "confidence": 0.87
        }
      ],
      "compliant_areas": [
        "Multi-layered rate limiting configuration correctly defined in RATE_LIMITS dictionary with different limits for different endpoint types",
        "Organization-based rate limiting key generation properly implemented using organization_id from JWT tokens",
        "Rate limiting middleware properly integrated into FastAPI application stack at correct position",
        "SlowAPI integration with Redis backend configuration present (storage_uri parameter)",
        "Custom rate limit exception handling with 429 status code properly implemented",
        "Rate limiting can be disabled via RATE_LIMIT_ENABLED configuration for testing",
        "Proper fallback mechanisms implemented (organization_id -> user_id -> api_key -> IP address)"
      ],
      "recommendations": [
        "Implement actual Token Bucket algorithm instead of relying solely on SlowAPI's default behavior",
        "Add production environment validation to enforce Redis URL requirement when rate limiting is enabled",
        "Replace development/test bypasses in middleware with proper implementation",
        "Add comprehensive rate limit header validation and injection",
        "Apply rate limiting decorators to all authentication endpoints as specified in ADR-005",
        "Implement proper integration with SlowAPI internals to get accurate remaining counts and reset times",
        "Add monitoring and alerting for rate limit violations per endpoint type",
        "Consider implementing circuit breaker pattern for backend services when rate limits are exceeded"
      ],
      "analysis_timestamp": "2025-08-06T01:37:44.681421+00:00",
      "files_analyzed": [
        "docs/architecture/ADRs/ADR-005_RateLimiting.md",
        "app/core/rate_limiting.py",
        "app/middleware/rate_limiting.py",
        "app/main.py",
        "app/core/config.py",
        "app/api/endpoints/auth.py",
        "tests/unit/core/test_core_rate_limiting.py",
        "tests/security/test_rate_limiting.py"
      ],
      "analysis_summary": "The implementation shows good architectural foundation with proper multi-layered configuration and SlowAPI integration, but has critical gaps in actual enforcement mechanisms, missing Token Bucket implementation, and incomplete header handling. The middleware bypasses actual rate limiting in non-production environments, and authentication endpoints lack proper decorator application. Redis integration is present but not enforced for production deployments as required by ADR-005."
    },
    "ADR-007_Auth_Failover": {
      "adr_id": "ADR-007_Auth_Failover",
      "compliance_score": 92.5,
      "violations": [
        {
          "file_path": "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/auth_failover.py",
          "line_number": 12,
          "description": "Missing import for connection pooling implementation - ADR specifies consistent hashing for distributed caching but no connection pooling strategy is implemented",
          "risk_level": "medium",
          "remediation_suggestion": "Add Redis connection pooling configuration with consistent hashing for distributed cache scenarios as specified in ADR Implementation Components section 1",
          "confidence": 0.85
        },
        {
          "file_path": "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/services/health_service.py",
          "line_number": 232,
          "description": "Circuit breaker health check implementation references non-existent function get_all_circuit_stats() - should be get_all_circuit_breaker_stats() from utils module",
          "risk_level": "high",
          "remediation_suggestion": "Fix import path to use correct function from app.utils.circuit_breaker module: 'from app.utils.circuit_breaker import get_all_circuit_breaker_stats'",
          "confidence": 0.95
        },
        {
          "file_path": "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/cache.py",
          "line_number": 304,
          "description": "Redis pipeline implementation lacks proper error handling for partial failures during batch operations, violating write-through caching consistency requirement",
          "risk_level": "medium",
          "remediation_suggestion": "Add transaction rollback logic for failed pipeline operations to maintain cache consistency as required by ADR section 1",
          "confidence": 0.8
        },
        {
          "file_path": "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/middleware/authentication.py",
          "line_number": 94,
          "description": "Authentication middleware lacks integration with fallback auth provider - no failover mechanism implemented when primary JWT validation fails",
          "risk_level": "high",
          "remediation_suggestion": "Integrate FallbackAuthProvider.authenticate_fallback() as secondary authentication method when JWT validation fails to implement ADR requirement 3",
          "confidence": 0.9
        }
      ],
      "compliant_areas": [
        "Cache-Based Session Management: Redis primary with fallback to in-memory cache implemented (app/core/cache.py)",
        "Circuit Breaker Pattern: Comprehensive implementation with proper state transitions, failure thresholds, and recovery timeout (app/utils/circuit_breaker.py, app/core/circuit_breaker.py)",
        "Fallback Authentication Methods: Emergency token system and API key fallback implemented (app/core/auth_failover.py)",
        "Health Monitoring: Comprehensive health checks for database, cache, auth services, and circuit breakers (app/services/health_service.py)",
        "Graceful Degradation: Cache fallback to in-memory storage when Redis unavailable, service degradation detection implemented",
        "Exponential Backoff: Connection retry logic with exponential delay implemented in cache manager",
        "Write-through Caching: Implemented for user credentials, API keys, and permissions with TTL support",
        "Automatic Failover: Circuit breaker decorator properly protects authentication endpoints"
      ],
      "recommendations": [
        "Implement connection pooling with consistent hashing for distributed Redis caching as specified in ADR Architecture section",
        "Fix circuit breaker stats import in health service to ensure monitoring works correctly",
        "Integrate fallback authentication provider into JWT middleware for seamless failover",
        "Add monitoring alerts for authentication service degradation events",
        "Implement read-only access mode during write operation failures as specified in ADR graceful degradation requirements",
        "Add metrics collection for authentication fallback usage patterns",
        "Consider implementing Redis Sentinel for high availability as referenced in ADR"
      ],
      "analysis_timestamp": "2025-08-06T01:38:50.292687+00:00",
      "files_analyzed": [
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/auth_failover.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/utils/circuit_breaker.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/cache.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/services/health_service.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/middleware/authentication.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/circuit_breaker.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/config.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/main.py"
      ],
      "analysis_summary": "The implementation demonstrates strong compliance with ADR-007 Auth Failover requirements, achieving a 92.5% compliance score. All major architectural components are implemented: cache-based session management with Redis primary and fallback, comprehensive circuit breaker pattern, fallback authentication methods, health monitoring, and graceful degradation. Key strengths include proper emergency token management, write-through caching, and circuit breaker protection. Main gaps are in middleware integration of failover mechanisms and some technical debt in import references. The architecture closely follows the specified multi-layered failover strategy with room for minor improvements in integration and monitoring."
    },
    "ADR-008_LoggingandAuditing": {
      "adr_id": "ADR-008_LoggingandAuditing",
      "compliance_score": 72.0,
      "violations": [
        {
          "file_path": "app/middleware/authentication.py",
          "line_number": 114,
          "description": "Authentication middleware sets user_id in request.state but does not bind organization_id and user_id to logging context for multi-tenant auditing as required by ADR-008",
          "risk_level": "high",
          "remediation_suggestion": "Add log_request_context call in authentication middleware to bind user_id and organization_id from token payload to all subsequent logs",
          "confidence": 0.95
        },
        {
          "file_path": "app/core/logging.py",
          "line_number": 15,
          "description": "Missing service_name field in log schema - ADR-008 requires 'service_name' field but only 'service' is added via add_app_context processor",
          "risk_level": "medium",
          "remediation_suggestion": "Rename 'service' field to 'service_name' in add_app_context function to match ADR-008 schema requirement",
          "confidence": 0.9
        },
        {
          "file_path": "app/middleware/logging.py",
          "line_number": 30,
          "description": "HTTP logging middleware doesn't populate auth_context with organization_id and user_id as required by ADR-008 multi-tenant logging schema",
          "risk_level": "high",
          "remediation_suggestion": "Extract user_id and organization_id from request.state and include in log entries as auth_context object",
          "confidence": 0.92
        },
        {
          "file_path": "app/db/init_mfa_policies.py",
          "line_number": 86,
          "description": "Using unstructured print() statements instead of structured JSON logging as mandated by ADR-008",
          "risk_level": "medium",
          "remediation_suggestion": "Replace print() calls with structured logger.info() calls to maintain consistent JSON logging format",
          "confidence": 0.98
        },
        {
          "file_path": "app/middleware/logging.py",
          "line_number": 34,
          "description": "Missing required http_context fields - ADR-008 requires source_ip, method, path, status_code but only partial implementation exists",
          "risk_level": "medium",
          "remediation_suggestion": "Add complete http_context object with source_ip from request headers and status_code from response",
          "confidence": 0.88
        }
      ],
      "compliant_areas": [
        "Structured JSON logging with structlog",
        "Data sanitization for sensitive fields (passwords, tokens, etc.)",
        "Correlation ID implementation via RequestIDMiddleware",
        "ISO 8601 timestamps with UTC timezone",
        "Proper log level usage (INFO, WARNING, ERROR, CRITICAL)",
        "Logging to stdout for containerization",
        "Comprehensive database audit logging",
        "Error handling and exception logging"
      ],
      "recommendations": [
        "Implement organization_id extraction from JWT tokens and bind to logging context",
        "Update authentication middleware to call log_request_context with user identity",
        "Standardize service_name field across all log entries to match ADR schema",
        "Replace all print() statements with structured logger calls",
        "Add complete http_context object to HTTP request logs",
        "Consider implementing async log sampling for DEBUG level as mentioned in ADR-008",
        "Add user_agent extraction to http_context in request logs"
      ],
      "analysis_timestamp": "2025-08-06T01:39:57.708810+00:00",
      "files_analyzed": [
        "app/core/logging.py",
        "app/main.py",
        "app/middleware/logging.py",
        "app/middleware/request_id.py",
        "app/middleware/audit.py",
        "app/middleware/authentication.py",
        "app/models/audit_log.py",
        "app/core/config.py",
        "app/db/init_mfa_policies.py"
      ],
      "analysis_summary": "The codebase demonstrates strong structured logging foundation with structlog but lacks full ADR-008 compliance in multi-tenant context binding. While correlation IDs and data redaction are properly implemented, the authentication middleware fails to bind organization_id and user_id to the logging context, breaking the audit trail requirement. Several non-structured print() statements also violate the JSON-only logging mandate."
    },
    "ADR-F3-1_ScoringArchitecture": {
      "adr_id": "ADR-F3-1_ScoringArchitecture",
      "compliance_score": 12.5,
      "violations": [
        {
          "file_path": "app/",
          "line_number": 0,
          "description": "Missing ScorerPlugin abstract base class - The ADR specifies a 'ScorerPlugin' interface with SCORER_TYPE, SCORER_NAME, and score() method, but no such implementation exists in the codebase",
          "risk_level": "critical",
          "remediation_suggestion": "Implement app/core/scoring/plugin.py with the ScorerPlugin ABC as specified in ADR lines 108-124",
          "confidence": 0.95
        },
        {
          "file_path": "app/models/session.py",
          "line_number": 1,
          "description": "Missing evidence document storage model - The ADR requires storing prompt/response pairs as 'evidence documents' with triage and deep analysis scores, but Session model only handles user authentication sessions",
          "risk_level": "critical",
          "remediation_suggestion": "Create app/models/evidence.py with fields for prompt_text, response_text, triage_scores, deep_analysis_scores, and session_id foreign key",
          "confidence": 0.98
        },
        {
          "file_path": "app/models/session.py",
          "line_number": 93,
          "description": "Missing session_summary table with analysis_status - ADR specifies session_summary needs analysis_status column to track scoring completion, but current session model lacks this field",
          "risk_level": "high",
          "remediation_suggestion": "Add analysis_status field to Session model or create separate SessionSummary model as specified in ADR line 146",
          "confidence": 0.9
        },
        {
          "file_path": "app/",
          "line_number": 0,
          "description": "Missing async task processing infrastructure - ADR requires task queue system (ADR-007) for background scoring workers, but no Celery/Redis task queue implementation found",
          "risk_level": "critical",
          "remediation_suggestion": "Implement Celery task queue with Redis broker as specified in ADR-007, create app/workers/scoring_worker.py for deep analysis processing",
          "confidence": 0.95
        },
        {
          "file_path": "app/",
          "line_number": 0,
          "description": "Missing real-time triage scoring integration - No evidence of lightweight real-time scorers being applied during test execution as required by Phase 1 of the hybrid architecture",
          "risk_level": "high",
          "remediation_suggestion": "Implement real-time scoring integration in orchestration endpoints to apply lightweight scorers immediately after receiving model responses",
          "confidence": 0.92
        },
        {
          "file_path": "app/",
          "line_number": 0,
          "description": "Missing deep analysis batch processing - No implementation of Phase 2 asynchronous batch job processing for expensive computational scoring after test completion",
          "risk_level": "high",
          "remediation_suggestion": "Create deep analysis worker process to handle batch scoring jobs triggered after test completion using the task queue system",
          "confidence": 0.93
        },
        {
          "file_path": "app/api/endpoints/",
          "line_number": 0,
          "description": "Missing orchestration endpoints - ADR refers to orchestration workers receiving responses from target AI models, but no AI model interaction endpoints found",
          "risk_level": "medium",
          "remediation_suggestion": "Implement endpoints for AI model orchestration that integrate with the scoring architecture as specified in ADR execution flow",
          "confidence": 0.85
        },
        {
          "file_path": "app/",
          "line_number": 0,
          "description": "Missing document database integration - ADR specifies evidence documents stored in document database, but only PostgreSQL/SQLAlchemy relational DB found",
          "risk_level": "medium",
          "remediation_suggestion": "Integrate document database (MongoDB, CouchDB) for flexible evidence storage or extend current models to handle nested scoring data",
          "confidence": 0.88
        }
      ],
      "compliant_areas": [
        "Basic session management infrastructure exists",
        "FastAPI framework properly configured for async operations",
        "Database models use proper validation and security patterns"
      ],
      "recommendations": [
        "Implement the ScorerPlugin abstract base class and plugin registration system as the foundation",
        "Create Evidence model for storing prompt/response pairs with scoring metadata",
        "Set up Celery task queue with Redis broker for async processing as specified in ADR-007",
        "Implement two-phase scoring workflow: real-time triage + batch deep analysis",
        "Add session analysis status tracking to monitor scoring completion",
        "Create orchestration endpoints that integrate with the scoring pipeline",
        "Establish plugin discovery and configuration system for extensible scorers",
        "Implement proper error handling and monitoring for the distributed scoring system"
      ],
      "analysis_timestamp": "2025-08-06T01:41:39.794748+00:00",
      "files_analyzed": [
        "docs/architecture/ADRs/ADR-F3-1_ScoringArchitecture.md",
        "docs/architecture/ADRs/ADR-007_AsyncTaskProcessing.md",
        "app/main.py",
        "app/api/routes.py",
        "app/repositories/session.py",
        "app/models/session.py",
        "app/schemas/session.py",
        "app/api/endpoints/sessions.py",
        "pyproject.toml"
      ],
      "analysis_summary": "The codebase shows a severe lack of compliance with ADR-F3-1. While basic FastAPI infrastructure exists, none of the core scoring architecture components are implemented. Missing critical elements include: ScorerPlugin interface, evidence storage models, async task processing, hybrid scoring workflow, and AI model orchestration endpoints. The current implementation focuses only on user session management rather than the AI security testing platform specified in the ADR."
    },
    "ADR-001_RESTstyle": {
      "adr_id": "ADR-001_RESTstyle",
      "compliance_score": 78.5,
      "violations": [
        {
          "file_path": "app/main.py",
          "line_number": 146,
          "description": "OpenAPI documentation URL does not follow versioned URI path pattern '/api/v1/openapi.json' - uses f'{app_settings.API_V1_STR}/openapi.json' which may not align with clear URI versioning strategy",
          "risk_level": "medium",
          "remediation_suggestion": "Ensure API_V1_STR consistently resolves to '/api/v1' and validate URI path versioning strategy aligns with ADR requirement for clear URI path versioning (e.g., '/api/v1/...')",
          "confidence": 0.75
        },
        {
          "file_path": "app/core/config.py",
          "line_number": 31,
          "description": "API versioning is defined as field but not explicitly validated for REST-compliant URI pattern format. ADR requires clear URI path versioning strategy",
          "risk_level": "low",
          "remediation_suggestion": "Add validation to ensure API_V1_STR follows REST-compliant versioning pattern '/api/v{version}' and add field validator to enforce proper URI structure",
          "confidence": 0.85
        },
        {
          "file_path": "app/api/base.py",
          "line_number": 77,
          "description": "Pagination implementation may not fully mitigate REST's over-fetching weakness as specified in ADR. While pagination exists, comprehensive field selection capabilities for addressing over-fetching are not evident in base CRUD operations",
          "risk_level": "medium",
          "remediation_suggestion": "Enhance field selection implementation in BaseCRUDRouter to fully address REST over-fetching concerns. Implement comprehensive field selection parameters in all list endpoints as specified in ADR rationale point 4",
          "confidence": 0.8
        },
        {
          "file_path": "app/utils/field_selection.py",
          "line_number": 1,
          "description": "Field selection utility exists but integration with main CRUD endpoints is not evident in the analyzed base router implementation",
          "risk_level": "medium",
          "remediation_suggestion": "Ensure field_selection utility is properly integrated into all REST endpoints to implement comprehensive field selection capabilities as required by ADR for mitigating over-fetching",
          "confidence": 0.7
        },
        {
          "file_path": "app/api/endpoints/users.py",
          "line_number": 35,
          "description": "Custom CRUD router implementation bypasses some base functionality, potentially inconsistent with standardized REST patterns across the API surface",
          "risk_level": "low",
          "remediation_suggestion": "Review user endpoint implementation to ensure it maintains consistent REST patterns and doesn't create 'endpoint sprawl' mentioned as a concern in ADR consequences",
          "confidence": 0.65
        }
      ],
      "compliant_areas": [
        "FastAPI framework usage provides strong RESTful foundation and OpenAPI documentation support",
        "Standard HTTP methods (GET, POST, PUT, PATCH, DELETE) properly implemented in BaseCRUDRouter",
        "JSON data serialization consistently used throughout API via Pydantic models",
        "URI path versioning implemented with /api/v1 prefix as required by ADR",
        "Authentication middleware properly implements JWT/API key authentication in application middleware as required for standalone operation",
        "Authorization middleware with RBAC patterns implemented for resource-level permission checking",
        "Rate limiting middleware properly implemented to handle policies in application code",
        "Comprehensive security headers and middleware stack implemented for standalone operation",
        "Stateless design maintained - no server-side session state between requests",
        "Pagination and filtering capabilities implemented in base CRUD operations",
        "Consistent error responses and status codes following HTTP standards",
        "Request validation and sanitization implemented throughout the stack"
      ],
      "recommendations": [
        "Validate and document API versioning strategy to ensure it fully aligns with REST best practices and ADR requirements",
        "Complete integration of field selection utility across all endpoints to fully address REST over-fetching concerns",
        "Review and standardize all endpoint implementations to prevent endpoint sprawl and ensure consistency",
        "Add comprehensive API documentation that demonstrates adherence to REST principles and ADR decisions",
        "Implement API testing suite that validates REST compliance including proper use of HTTP methods, status codes, and resource representations"
      ],
      "analysis_timestamp": "2025-08-06T01:43:00.182155+00:00",
      "files_analyzed": [
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/main.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/api/routes.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/api/base.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/config.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/api/endpoints/users.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/middleware/authentication.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/pyproject.toml"
      ],
      "analysis_summary": "The ViolentUTF API demonstrates strong compliance with ADR-001_RESTstyle requirements. The implementation successfully adopts FastAPI for RESTful architecture, implements proper JSON serialization, URI versioning, and comprehensive middleware for standalone operation. Key strengths include proper HTTP method usage, authentication/authorization middleware, rate limiting, and security headers. The main areas for improvement involve ensuring complete field selection integration to address REST over-fetching concerns and validating consistent application of REST patterns across all endpoints to prevent endpoint sprawl as mentioned in ADR consequences."
    },
    "ADR-F1-2_ServersideOrchestration": {
      "adr_id": "ADR-F1-2_ServersideOrchestration",
      "compliance_score": 15.2,
      "violations": [
        {
          "file_path": "app/api/routes.py",
          "line_number": 21,
          "description": "Critical violation: No orchestrator API endpoints implemented. ADR mandates POST /api/v1/orchestrators/execute endpoint that accepts YAML/JSON workflow definitions and returns 202 Accepted with task_id. Current routes.py only includes basic CRUD endpoints (auth, users, sessions, etc.) but no orchestrator endpoints.",
          "risk_level": "critical",
          "remediation_suggestion": "Add orchestrator router import and include POST /api/v1/orchestrators/execute endpoint that integrates with ADR-007 async task processing",
          "confidence": 0.98
        },
        {
          "file_path": "app/models/__init__.py",
          "line_number": 1,
          "description": "Critical violation: No database models for orchestration state management. ADR requires storing orchestration definitions, running state, conversation transcripts, and state transitions. Current models only include user management (user, api_key, session, audit_log, etc.) but no orchestration-related models.",
          "risk_level": "critical",
          "remediation_suggestion": "Create OrchestrationJob, OrchestrationState, OrchestrationTransition, and ConversationTurn models with proper relationships and status tracking",
          "confidence": 0.97
        },
        {
          "file_path": "requirements.txt",
          "line_number": 28,
          "description": "Critical violation: Missing task queue infrastructure. ADR-007 specifies Celery workers for background orchestration execution, but requirements.txt has Redis but no Celery. Background workers are essential for state machine execution.",
          "risk_level": "critical",
          "remediation_suggestion": "Add celery>=5.3.0 and flower>=2.0.0 dependencies for task queue management and monitoring",
          "confidence": 0.95
        },
        {
          "file_path": "app/core/config.py",
          "line_number": 64,
          "description": "High violation: No task queue configuration settings. ADR requires configuration for task queue brokers, worker scaling, and orchestration timeouts. Current config has Redis URL but no Celery or task-specific settings.",
          "risk_level": "high",
          "remediation_suggestion": "Add CELERY_BROKER_URL, CELERY_RESULT_BACKEND, ORCHESTRATION_TIMEOUT, and WORKER_CONCURRENCY configuration fields",
          "confidence": 0.92
        },
        {
          "file_path": "app/main.py",
          "line_number": 216,
          "description": "High violation: No orchestration engine initialization. ADR requires state machine execution engine startup during application lifespan. Current main.py initializes database and cache but no orchestration workers or state machine components.",
          "risk_level": "high",
          "remediation_suggestion": "Add orchestration engine initialization in the lifespan context manager with proper worker startup and shutdown",
          "confidence": 0.9
        },
        {
          "file_path": "app/services",
          "line_number": 1,
          "description": "High violation: Missing orchestration service layer. ADR specifies complex state machine logic, prompt rendering via ADR-F1.1, and transition evaluation. No orchestration service exists in services directory.",
          "risk_level": "high",
          "remediation_suggestion": "Create orchestration_service.py with StateMachineEngine, WorkflowParser, and TransitionEvaluator classes",
          "confidence": 0.93
        },
        {
          "file_path": "requirements.txt",
          "line_number": 56,
          "description": "Medium violation: Template engine dependency exists but orchestration-specific validation missing. ADR requires YAML/JSON schema validation for workflow definitions. Jinja2 is present for ADR-F1.1 but no orchestration schema validation.",
          "risk_level": "medium",
          "remediation_suggestion": "Add jsonschema>=4.19.0 and pyyaml validation libraries for workflow definition validation",
          "confidence": 0.88
        },
        {
          "file_path": "app/api/endpoints",
          "line_number": 1,
          "description": "Medium violation: No task status polling endpoints. ADR-007 integration requires GET /api/v1/tasks/{task_id} for status polling. Current endpoints directory has no task management endpoints.",
          "risk_level": "medium",
          "remediation_suggestion": "Create tasks.py endpoint module with GET /api/v1/tasks/{task_id} and related task status management endpoints",
          "confidence": 0.91
        }
      ],
      "compliant_areas": [
        "Redis infrastructure available for message brokering (requirements.txt:28)",
        "Jinja2 templating engine available for prompt rendering per ADR-F1.1 (requirements.txt:56)",
        "Asynchronous application architecture with lifespan management (main.py:106-136)",
        "FastAPI framework supports async/await patterns required for task processing",
        "Database infrastructure (SQLAlchemy) available for state persistence",
        "Proper error handling and logging framework for orchestration debugging"
      ],
      "recommendations": [
        "CRITICAL: Implement core orchestration endpoints following ADR-007 async pattern with 202 Accepted responses",
        "CRITICAL: Create comprehensive database schema for orchestration state management and conversation tracking",
        "CRITICAL: Add Celery task queue infrastructure with proper worker management and monitoring",
        "HIGH: Develop state machine execution engine with workflow parsing, state transitions, and condition evaluation",
        "HIGH: Integrate with ADR-F1.1 templating engine for dynamic prompt rendering in orchestration states",
        "MEDIUM: Add robust YAML/JSON schema validation for orchestration workflow definitions",
        "MEDIUM: Implement comprehensive logging and monitoring for orchestration debugging per ADR consequences",
        "LOW: Create administrative endpoints for orchestration management and introspection tools"
      ],
      "analysis_timestamp": "2025-08-06T01:44:09.900841+00:00",
      "files_analyzed": [
        "docs/architecture/ADRs/ADR-F1-2_ServersideOrchestration.md",
        "docs/architecture/ADRs/ADR-007_AsyncTaskProcessing.md",
        "app/api/routes.py",
        "app/main.py",
        "app/core/config.py",
        "requirements.txt",
        "app/models/__init__.py"
      ],
      "analysis_summary": "ADR-F1-2 Server-Side Orchestration is severely non-compliant with only 15.2% implementation. The ADR mandates a complete orchestration engine for multi-turn AI attacks with declarative YAML/JSON workflows, state machine execution, and async task processing integration. Critical gaps include missing API endpoints (/api/v1/orchestrators/execute), no database models for state management, absent Celery task queue infrastructure, and no orchestration service layer. While foundational components exist (Redis, Jinja2, FastAPI async), the core orchestration architecture is entirely unimplemented. This represents a major architectural debt requiring substantial development effort to achieve compliance."
    },
    "ADR-F4-1_UntrustedModelInteractions": {
      "adr_id": "ADR-F4-1_UntrustedModelInteractions",
      "compliance_score": 15.0,
      "violations": [
        {
          "file_path": "app/main.py",
          "line_number": 238,
          "description": "No container-based sandboxing infrastructure implemented for untrusted model execution. The application lacks the mandatory Docker SDK integration and ephemeral container provisioning capabilities required by ADR-F4-1.",
          "risk_level": "critical",
          "remediation_suggestion": "Implement Docker SDK integration with container lifecycle management for untrusted model execution",
          "confidence": 0.98
        },
        {
          "file_path": "app/core/external_services.py",
          "line_number": 38,
          "description": "AI_MODEL service type exists but lacks secure sandboxed execution implementation. No container isolation, security profiles, or untrusted code execution safeguards present.",
          "risk_level": "critical",
          "remediation_suggestion": "Implement secure container execution wrapper for AI_MODEL service type with proper isolation",
          "confidence": 0.95
        },
        {
          "file_path": "app/api/routes.py",
          "line_number": 21,
          "description": "No API endpoints exist for untrusted model execution or container management. ADR requires orchestration endpoints to handle sandboxed model interactions.",
          "risk_level": "high",
          "remediation_suggestion": "Add API endpoints for model execution requests with container-based processing",
          "confidence": 0.9
        },
        {
          "file_path": "app/core/config.py",
          "line_number": 1,
          "description": "Configuration lacks container runtime settings, security profiles, and resource limits required for sandboxed execution as mandated by ADR-F4-1.",
          "risk_level": "high",
          "remediation_suggestion": "Add configuration settings for Docker runtime, container security profiles, and resource limits",
          "confidence": 0.92
        },
        {
          "file_path": "Dockerfile",
          "line_number": 1,
          "description": "Application Dockerfile exists but no separate sandbox container image or security-hardened execution environment for untrusted models.",
          "risk_level": "high",
          "remediation_suggestion": "Create hardened sandbox container image with minimal base, non-root user, and restricted capabilities",
          "confidence": 0.88
        },
        {
          "file_path": "pyproject.toml",
          "line_number": 10,
          "description": "Missing Docker SDK dependency required for container management. No container orchestration libraries present in dependencies.",
          "risk_level": "medium",
          "remediation_suggestion": "Add docker library and container management dependencies to pyproject.toml",
          "confidence": 0.85
        }
      ],
      "compliant_areas": [
        "Basic security middleware architecture exists for request validation",
        "HTTP client infrastructure available for external service communication",
        "Configuration management system supports adding container-related settings"
      ],
      "recommendations": [
        "Implement Docker SDK integration for ephemeral container provisioning",
        "Create secure container profile with read-only filesystem, non-root user execution, and dropped capabilities",
        "Add container lifecycle management service for model execution orchestration",
        "Implement stdin/stdout communication channels between platform and sandboxed containers",
        "Add resource limits and timeout enforcement for container execution",
        "Create API endpoints for submitting untrusted models and retrieving execution results",
        "Implement proper error handling and cleanup for failed container executions",
        "Add monitoring and logging for container execution events"
      ],
      "analysis_timestamp": "2025-08-06T01:46:08.647008+00:00",
      "files_analyzed": [
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/docs/architecture/ADRs/ADR-F4-1_UntrustedModelInteractions.md",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/main.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/config.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/external_services.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/api/routes.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/Dockerfile",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/pyproject.toml",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/config/violation_patterns.yml"
      ],
      "analysis_summary": "Critical non-compliance with ADR-F4-1. The architecture mandates container-based sandboxing for untrusted model execution with ephemeral containers, security profiles, and controlled communication channels. The current implementation lacks all these requirements, presenting a severe security risk if untrusted models were to be executed. While basic HTTP client and service infrastructure exists, there is no Docker SDK integration, container orchestration, or secure execution environment implementation."
    },
    "ADR-002_Authentication": {
      "adr_id": "ADR-002_Authentication",
      "compliance_score": 72.5,
      "violations": [
        {
          "file_path": "app/core/config.py",
          "line_number": 42,
          "description": "JWT algorithm is set to HS256 (symmetric) instead of RS256 (asymmetric) as required by ADR-002. ADR specifies 'RS256 will be used, as asymmetric keys allow the signing key to be kept private while the public key for verification can be widely distributed'",
          "risk_level": "high",
          "remediation_suggestion": "Change ALGORITHM from 'HS256' to 'RS256' and implement asymmetric key management with private/public key pairs",
          "confidence": 0.95
        },
        {
          "file_path": "app/core/security.py",
          "line_number": 96,
          "description": "No token blocklist implementation found for immediate token revocation. ADR-002 states 'A token blocklist will be implemented using a distributed cache (e.g., Redis) to enable immediate revocation of specific tokens or all tokens for a user'",
          "risk_level": "high",
          "remediation_suggestion": "Implement Redis-based token blocklist in decode_token() function to check revoked tokens before validation",
          "confidence": 0.9
        },
        {
          "file_path": "app/models/api_key.py",
          "line_number": 100,
          "description": "API key hash is stored as SHA-256, but ADR-002 does not specify this as the required hashing algorithm. Should use a strong hashing algorithm as specified",
          "risk_level": "medium",
          "remediation_suggestion": "Verify SHA-256 is acceptable or upgrade to bcrypt/Argon2 for API key hashing to match password hashing standards",
          "confidence": 0.75
        },
        {
          "file_path": "app/api/endpoints/auth.py",
          "line_number": 364,
          "description": "Token refresh implements rotation but lacks explicit validation of refresh token uniqueness or storage of used tokens to prevent replay attacks",
          "risk_level": "medium",
          "remediation_suggestion": "Implement refresh token tracking/rotation with database storage to prevent token replay attacks",
          "confidence": 0.8
        },
        {
          "file_path": "app/models/api_key.py",
          "line_number": 218,
          "description": "API key generation uses 'vutf_' prefix instead of the ADR-specified format. ADR states keys should be generated 'with a prefix (e.g., vutf-api_...)'",
          "risk_level": "low",
          "remediation_suggestion": "Change API key prefix from 'vutf_' to 'vutf-api_' to match ADR specification",
          "confidence": 0.85
        }
      ],
      "compliant_areas": [
        "JWT Bearer tokens implemented with proper access/refresh token structure",
        "API key management with creation, revocation, and rotation endpoints",
        "Proper password hashing using Argon2 with appropriate parameters",
        "Token expiration configuration (15-60 minutes for access, 7 days for refresh)",
        "API key permissions system with granular scopes",
        "User authentication with proper validation and error handling",
        "API key ownership verification and security checks",
        "Comprehensive audit logging for authentication events",
        "Token validation with proper error handling and structured responses",
        "API key hashing and secure storage (never plaintext)"
      ],
      "recommendations": [
        "CRITICAL: Implement RS256 asymmetric JWT signing as specified in ADR-002",
        "CRITICAL: Implement Redis-based token blocklist for immediate token revocation",
        "Enhance refresh token security with proper rotation and replay attack prevention",
        "Consider implementing JWT key rotation mechanism for long-term security",
        "Add API key rate limiting per key to prevent abuse",
        "Implement comprehensive JWT claims validation including 'jti' (JWT ID)",
        "Add monitoring and alerting for authentication failures and suspicious activities",
        "Update API key prefix format to match ADR specification exactly"
      ],
      "analysis_timestamp": "2025-08-06T01:47:17.965753+00:00",
      "files_analyzed": [
        "docs/architecture/ADRs/ADR-002_Authentication.md",
        "app/core/auth.py",
        "app/core/security.py",
        "app/middleware/authentication.py",
        "app/api/endpoints/auth.py",
        "app/models/api_key.py",
        "app/core/config.py",
        "app/api/endpoints/api_keys.py"
      ],
      "analysis_summary": "The implementation provides a solid foundation with dual authentication mechanisms (JWT + API keys) as required by ADR-002, but has critical gaps in asymmetric JWT implementation and token revocation capabilities. While core functionality like token generation, API key management, and user authentication work well, the symmetric JWT algorithm and missing Redis blocklist significantly impact security posture. The codebase demonstrates good security practices in password handling and API key management, but requires architectural changes to fully comply with ADR-002 specifications."
    },
    "ADR-F2-2_DataStorage": {
      "adr_id": "ADR-F2-2_DataStorage",
      "compliance_score": 32.5,
      "violations": [
        {
          "file_path": "app/core/config.py",
          "line_number": 59,
          "description": "Only PostgreSQL DATABASE_URL is configured. Missing MongoDB/DynamoDB connection settings required for session_evidence document storage per ADR lines 70-71",
          "risk_level": "critical",
          "remediation_suggestion": "Add MONGODB_URL, DOCUMENT_DB_NAME, and DOCUMENT_DB_COLLECTION_NAME settings for evidence storage",
          "confidence": 0.98
        },
        {
          "file_path": "app/core/config.py",
          "line_number": 60,
          "description": "No S3/blob storage configuration found. ADR line 71 requires blob storage for cost-effective long-term archival of large raw artifacts",
          "risk_level": "critical",
          "remediation_suggestion": "Add S3_BUCKET_URL, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, and blob storage lifecycle configuration",
          "confidence": 0.97
        },
        {
          "file_path": "app/models/",
          "line_number": 1,
          "description": "Missing critical data models specified in ADR. No models exist for test_configurations, vulnerability_taxonomies, session_summaries, or session_evidence collections",
          "risk_level": "critical",
          "remediation_suggestion": "Create SQLAlchemy models for PostgreSQL tables (test_configurations, session_summaries, vulnerability_taxonomies) and Pydantic models for MongoDB documents (session_evidence)",
          "confidence": 0.99
        },
        {
          "file_path": "app/db/session.py",
          "line_number": 40,
          "description": "Only relational database session management exists. Missing document database session factory and blob storage client initialization per ADR polyglot architecture",
          "risk_level": "high",
          "remediation_suggestion": "Implement MongoDBSessionFactory and S3Client classes with connection pooling and circuit breakers",
          "confidence": 0.95
        },
        {
          "file_path": "app/repositories/",
          "line_number": 1,
          "description": "No polyglot persistence repository pattern implemented. ADR requires database routing logic to direct queries to appropriate storage system based on data type",
          "risk_level": "high",
          "remediation_suggestion": "Create PolyglotRepository base class with routing logic: structured data → PostgreSQL, evidence data → MongoDB, large files → S3",
          "confidence": 0.93
        },
        {
          "file_path": "alembic/versions/",
          "line_number": 1,
          "description": "Missing database migrations for ADR-specified tables. Lines 88-89 require test_configurations, vulnerability_taxonomies, session_summaries tables in PostgreSQL",
          "risk_level": "high",
          "remediation_suggestion": "Create Alembic migrations for the three PostgreSQL tables with proper foreign key relationships and indexes",
          "confidence": 0.96
        },
        {
          "file_path": "app/",
          "line_number": 1,
          "description": "No data lifecycle management implementation found. ADR lines 96-100 mandate automated 90-day hot→cold storage migration with 7-year retention policy",
          "risk_level": "medium",
          "remediation_suggestion": "Implement Celery background tasks for data archival pipeline with configurable retention policies",
          "confidence": 0.9
        },
        {
          "file_path": "app/services/",
          "line_number": 1,
          "description": "Missing evidence storage service layer. ADR line 70 specifies session_evidence documents with structure: session_id, prompt, response, scores, vulnerability_ids",
          "risk_level": "medium",
          "remediation_suggestion": "Create EvidenceStorageService with methods for storing/retrieving test evidence documents in MongoDB with proper indexing",
          "confidence": 0.92
        }
      ],
      "compliant_areas": [
        "PostgreSQL database configuration with connection pooling and health checks",
        "Relational database session management with circuit breaker protection",
        "Alembic migration system for schema versioning",
        "Database connection validation and recovery mechanisms",
        "Proper SQLAlchemy 2.0 async implementation with comprehensive error handling"
      ],
      "recommendations": [
        "CRITICAL: Implement complete polyglot persistence architecture with MongoDB and S3 integration",
        "CRITICAL: Create the missing data models for all ADR-specified entities (test_configurations, vulnerability_taxonomies, session_summaries, session_evidence)",
        "HIGH: Implement data routing layer to direct different data types to appropriate storage systems",
        "HIGH: Add automated data lifecycle management with hot/cold/archive tier transitions",
        "MEDIUM: Create comprehensive testing strategy for multi-database consistency",
        "MEDIUM: Implement monitoring and alerting for cross-database operations"
      ],
      "analysis_timestamp": "2025-08-06T01:48:43.551863+00:00",
      "files_analyzed": [
        "app/core/config.py",
        "app/db/session.py",
        "app/db/base.py",
        "app/models/user.py",
        "app/models/session.py",
        "app/models/audit_log.py",
        "alembic.ini",
        "alembic/versions/0d9d1d5fbe10_initial_database_models_with_.py"
      ],
      "analysis_summary": "The current implementation provides only 32.5% compliance with ADR-F2-2_DataStorage. While the PostgreSQL foundation is solid with proper connection management and basic models, the architecture completely lacks the document database (MongoDB/DynamoDB) and blob storage (S3) components that are central to the polyglot persistence strategy. Critical missing elements include session_evidence document storage, data lifecycle management, and the repository routing logic needed to direct different data types to appropriate storage systems. The implementation needs substantial work to achieve the intended polyglot persistence architecture."
    },
    "ADR-F4-2_SecretManagement": {
      "adr_id": "ADR-F4-2_SecretManagement",
      "compliance_score": 15.0,
      "violations": [
        {
          "file_path": "app/models/api_key.py",
          "line_number": 27,
          "description": "CRITICAL VIOLATION: API keys are stored as SHA256 hashes in the main application database, violating ADR requirement for dedicated secrets manager. Line 27: key_hash: Mapped[str] = mapped_column(String(255), unique=True, nullable=False, index=True, comment=\"SHA256 hash of the API key\")",
          "risk_level": "critical",
          "remediation_suggestion": "Replace database storage with secrets manager reference. Store only non-sensitive pointers to secrets manager locations.",
          "confidence": 0.98
        },
        {
          "file_path": "app/services/api_key_service.py",
          "line_number": 288,
          "description": "CRITICAL VIOLATION: API key generation creates SHA256 hash for database storage, implementing the explicitly rejected 'Encrypted in Application Database' pattern. Line 288: key_hash = hashlib.sha256(full_key.encode()).hexdigest()",
          "risk_level": "critical",
          "remediation_suggestion": "Implement SecretsManagerClient abstraction layer as defined in ADR. Store secrets in dedicated manager, not database.",
          "confidence": 0.95
        },
        {
          "file_path": "app/services/api_key_service.py",
          "line_number": 127,
          "description": "CRITICAL VIOLATION: API key validation retrieves secrets from database hash storage, creating single point of compromise. Line 127-145: validate_api_key method retrieves and validates against database stored hashes.",
          "risk_level": "critical",
          "remediation_suggestion": "Implement just-in-time retrieval from secrets manager instead of database lookup.",
          "confidence": 0.92
        },
        {
          "file_path": "app/core/config.py",
          "line_number": 39,
          "description": "HIGH VIOLATION: Application SECRET_KEY stored as environment variable, not in dedicated secrets manager. Line 39: SECRET_KEY: SecretStr = Field(..., min_length=32)",
          "risk_level": "high",
          "remediation_suggestion": "Move SECRET_KEY to dedicated secrets manager with just-in-time retrieval.",
          "confidence": 0.89
        },
        {
          "file_path": "app/core/security.py",
          "line_number": 53,
          "description": "HIGH VIOLATION: JWT token creation directly accesses SECRET_KEY from configuration, not through secrets manager. Line 53: settings.SECRET_KEY.get_secret_value()",
          "risk_level": "high",
          "remediation_suggestion": "Implement secrets manager client for runtime secret retrieval.",
          "confidence": 0.87
        },
        {
          "file_path": "requirements.txt",
          "line_number": 1,
          "description": "CRITICAL VIOLATION: No dedicated secrets management dependencies found. Missing HashiCorp Vault client, AWS Secrets Manager client, or similar dedicated secrets management libraries.",
          "risk_level": "critical",
          "remediation_suggestion": "Add hvac (HashiCorp Vault), boto3 (AWS Secrets Manager), or google-cloud-secret-manager dependencies to support dedicated secrets management.",
          "confidence": 0.93
        },
        {
          "file_path": "app/core/external_services.py",
          "line_number": 25,
          "description": "MEDIUM VIOLATION: External services integration exists but no AI_MODEL service type configured for third-party AI provider credentials. Line 38: AI_MODEL = \"ai_model\" exists but no implementation found.",
          "risk_level": "medium",
          "remediation_suggestion": "Implement AI provider credential management through secrets manager for OpenAI, Anthropic, and other third-party services.",
          "confidence": 0.78
        }
      ],
      "compliant_areas": [
        "Password hashing uses secure Argon2 algorithm (app/core/security.py:24)",
        "API key generation uses cryptographically secure random generation (app/services/api_key_service.py:280)",
        "Comprehensive input validation and sanitization middleware exists"
      ],
      "recommendations": [
        "IMMEDIATE ACTION REQUIRED: Implement SecretsManagerClient abstraction layer as specified in ADR lines 101-116",
        "Replace all database-stored secrets with non-sensitive pointers to secrets manager locations",
        "Implement just-in-time secret retrieval for API keys, JWT secrets, and third-party credentials",
        "Add dedicated secrets manager dependencies (hvac, boto3, or google-cloud-secret-manager)",
        "Create provider plugin system with secrets manager integration for AI services (OpenAI, Anthropic)",
        "Implement configurable secrets manager backend support (HashiCorp Vault, AWS Secrets Manager)",
        "Add comprehensive audit logging for all secret access operations",
        "Migrate existing API key hashes from database to secrets manager with secure migration process"
      ],
      "analysis_timestamp": "2025-08-06T01:50:09.044963+00:00",
      "files_analyzed": [
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/docs/architecture/ADRs/ADR-F4-2_SecretManagement.md",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/config.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/services/api_key_service.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/models/api_key.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/security.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/main.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/external_services.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/requirements.txt"
      ],
      "analysis_summary": "CRITICAL NON-COMPLIANCE: The ViolentUTF API currently implements the explicitly rejected 'Encrypted in Application Database' anti-pattern for secrets management. API keys are stored as SHA256 hashes in the main PostgreSQL database, creating a single point of compromise. No dedicated secrets manager infrastructure exists. This represents a fundamental architectural violation with catastrophic security implications. The ADR mandates externalized storage in dedicated secrets managers (HashiCorp Vault, AWS Secrets Manager) with just-in-time retrieval, none of which is implemented."
    },
    "ADR-F3-2_ReportGeneration": {
      "adr_id": "ADR-F3-2_ReportGeneration",
      "compliance_score": 35.2,
      "violations": [
        {
          "file_path": "app/api/routes.py",
          "line_number": null,
          "description": "Missing required report generation API endpoint '/api/v1/reports/generate' as specified in ADR execution flow step 1. The API router does not include any report-related endpoints.",
          "risk_level": "critical",
          "remediation_suggestion": "Add report generation endpoint with POST /api/v1/reports/generate that accepts config_id parameter and returns 202 Accepted with task_id",
          "confidence": 0.95
        },
        {
          "file_path": "app/api/endpoints/",
          "line_number": null,
          "description": "Missing reports.py endpoint file - no dedicated report endpoints implementation exists in the FastAPI application endpoints directory",
          "risk_level": "critical",
          "remediation_suggestion": "Create app/api/endpoints/reports.py with FastAPI router implementing report generation endpoints",
          "confidence": 0.98
        },
        {
          "file_path": "requirements.txt",
          "line_number": 28,
          "description": "Missing Celery dependency for asynchronous task processing as required by ADR step 2 (task queue integration). Redis is available but Celery worker framework is not installed.",
          "risk_level": "critical",
          "remediation_suggestion": "Add celery>=5.3.0 to requirements.txt and implement Celery worker configuration for report generation tasks",
          "confidence": 0.9
        },
        {
          "file_path": "requirements.txt",
          "line_number": 56,
          "description": "Missing Playwright dependency for HTML to PDF conversion as specified in ADR recommended technology stack. Only Jinja2 templating is present.",
          "risk_level": "high",
          "remediation_suggestion": "Add playwright>=1.40.0 to requirements.txt and implement PDF rendering using headless browser instead of ReportLab",
          "confidence": 0.88
        },
        {
          "file_path": "tools/pre_audit/reporting/",
          "line_number": null,
          "description": "Report generation logic exists in tools directory but is not integrated with FastAPI application as server-side engine. Implementation is standalone rather than part of main API service.",
          "risk_level": "high",
          "remediation_suggestion": "Move report generation logic from tools to app/services and integrate with FastAPI application endpoints",
          "confidence": 0.85
        },
        {
          "file_path": "tools/pre_audit/reporting/exporters/pdf_generator.py",
          "line_number": 15,
          "description": "PDF generation uses ReportLab instead of ADR-specified Playwright headless browser approach. This violates the recommended technology stack in ADR implementation details.",
          "risk_level": "medium",
          "remediation_suggestion": "Replace ReportLab PDF generation with Playwright-based HTML to PDF conversion as specified in ADR",
          "confidence": 0.82
        },
        {
          "file_path": "app/",
          "line_number": null,
          "description": "Missing dedicated reporting worker processes and task management infrastructure for long-running report generation jobs",
          "risk_level": "high",
          "remediation_suggestion": "Implement Celery worker processes specifically configured for report generation with proper resource limits",
          "confidence": 0.9
        },
        {
          "file_path": "app/models/",
          "line_number": null,
          "description": "Missing report configuration and task models for storing report generation state and configuration as required by ADR execution flow",
          "risk_level": "medium",
          "remediation_suggestion": "Create SQLAlchemy models for ReportConfiguration and ReportTask to support async task tracking",
          "confidence": 0.87
        },
        {
          "file_path": "app/",
          "line_number": null,
          "description": "Missing blob storage integration for saving generated PDF and JSON artifacts as specified in ADR step 8 (storage and completion)",
          "risk_level": "medium",
          "remediation_suggestion": "Implement blob storage service integration for persisting generated report files with secure URLs",
          "confidence": 0.85
        }
      ],
      "compliant_areas": [
        "Jinja2 templating engine is properly installed and used in HTML report generator with sandboxed environment",
        "Comprehensive report data processing logic exists with multi-format support (HTML, PDF, JSON)",
        "Security measures implemented including input validation, output encoding, and path sanitization",
        "Template-based HTML generation with proper structure and styling",
        "Report metadata and statistical analysis capabilities are well-developed",
        "Multi-format export manager with parallel processing support"
      ],
      "recommendations": [
        "CRITICAL: Implement POST /api/v1/reports/generate endpoint with proper async task queue integration",
        "CRITICAL: Add Celery dependency and configure async task processing workers for report generation",
        "HIGH: Replace ReportLab with Playwright for HTML to PDF conversion as specified in ADR",
        "HIGH: Integrate existing report generation tools into main FastAPI application as proper services",
        "MEDIUM: Create proper database models for report configurations and task tracking",
        "MEDIUM: Implement blob storage integration for generated report artifacts",
        "MEDIUM: Add webhook support for report completion notifications as mentioned in ADR-007",
        "LOW: Enhance logging and monitoring for report generation processes"
      ],
      "analysis_timestamp": "2025-08-06T01:51:25.945908+00:00",
      "files_analyzed": [
        "docs/architecture/ADRs/ADR-F3-2_ReportGeneration.md",
        "tools/pre_audit/reporting/export_manager.py",
        "tools/pre_audit/reporting/exporters/pdf_generator.py",
        "tools/pre_audit/reporting/base.py",
        "tools/pre_audit/reporting/exporters/html_generator.py",
        "docs/architecture/ADRs/ADR-007_AsyncTaskProcessing.md",
        "requirements.txt",
        "app/api/routes.py",
        "app/main.py"
      ],
      "analysis_summary": "The codebase shows partial implementation of report generation capabilities but fails to meet the core ADR requirement of server-side engine integration with the main FastAPI application. While comprehensive report generation logic exists in the tools/pre_audit directory with proper multi-format support (HTML, PDF, JSON), security measures, and Jinja2 templating, it operates as a standalone tool rather than an integrated API service. Critical missing components include the /api/v1/reports/generate endpoint, Celery task queue integration, dedicated reporting workers, and proper blob storage for artifacts. The compliance score of 35.2% reflects that foundational report generation capabilities exist but lack proper architectural integration as specified in the ADR."
    }
  },
  "all_violations": [
    {
      "file_path": "tools/pre_audit/historical_analyzer.py",
      "line_number": 1254,
      "description": "Missing --min-risk parameter validation range enforcement - ADR specifies reasonable bounds checking but implementation allows any float value",
      "risk_level": "medium",
      "remediation_suggestion": "Add validation: if args.min_risk < 0.0 or args.min_risk > 100.0: logger.error('min-risk must be between 0.0 and 100.0'); sys.exit(1)",
      "confidence": 0.85
    },
    {
      "file_path": "tools/pre_audit/historical_analyzer.py",
      "line_number": 1125,
      "description": "Report path enhancement may fail silently - ADR requires comprehensive error handling but implementation has generic exception catch",
      "risk_level": "low",
      "remediation_suggestion": "Replace generic except Exception with specific exceptions for better error reporting and debugging",
      "confidence": 0.72
    },
    {
      "file_path": "config/violation_patterns.yml",
      "line_number": 418,
      "description": "Configuration file truncated at line 418 - ADR specifies comprehensive coverage of 20+ ADRs but implementation appears incomplete",
      "risk_level": "medium",
      "remediation_suggestion": "Verify complete configuration file covers all implemented ADRs including ADR-011 itself and other recent ADRs",
      "confidence": 0.78
    },
    {
      "file_path": "tools/pre_audit/historical_analyzer.py",
      "line_number": 665,
      "description": "Default configuration path uses hardcoded relative path which may not work in all deployment scenarios",
      "risk_level": "low",
      "remediation_suggestion": "Use absolute path resolution or environment-variable-based path discovery for better deployment flexibility",
      "confidence": 0.68
    },
    {
      "file_path": "tools/pre_audit/historical_analyzer.py",
      "line_number": 796,
      "description": "Analysis duration calculation lacks bounds checking - potential division by zero handled but with magic number 0.001",
      "risk_level": "low",
      "remediation_suggestion": "Use more robust duration calculation with proper constants and explain why 0.001 is chosen",
      "confidence": 0.65
    },
    {
      "file_path": "app/api/routes.py",
      "line_number": 1,
      "description": "CRITICAL: No async task endpoints implemented. ADR requires /api/v1/scans and /api/v1/tasks endpoints for HTTP Polling pattern but these are completely missing from the API router configuration.",
      "risk_level": "critical",
      "remediation_suggestion": "Create scans.py and tasks.py endpoint files and register them in routes.py with proper 202 Accepted responses",
      "confidence": 0.95
    },
    {
      "file_path": "requirements.txt",
      "line_number": 28,
      "description": "CRITICAL: Redis dependency exists but no Celery task queue system implemented. ADR mandates Celery for backend task processing but it's entirely absent from dependencies and implementation.",
      "risk_level": "critical",
      "remediation_suggestion": "Add celery>=5.3.0 to requirements.txt and implement celery worker configuration",
      "confidence": 0.98
    },
    {
      "file_path": "app/models/__init__.py",
      "line_number": 20,
      "description": "CRITICAL: No Task model exists for tracking async jobs. ADR requires task records in database with PENDING/RUNNING/SUCCESS states but no such model is implemented.",
      "risk_level": "critical",
      "remediation_suggestion": "Create Task model with fields: id, status, task_type, result_url, webhook_url, created_at, updated_at",
      "confidence": 0.95
    },
    {
      "file_path": "app/core/config.py",
      "line_number": 64,
      "description": "HIGH: Redis configured but no task queue or worker configuration. ADR requires message broker setup for Celery but implementation is missing.",
      "risk_level": "high",
      "remediation_suggestion": "Add CELERY_BROKER_URL, CELERY_RESULT_BACKEND, and worker configuration settings",
      "confidence": 0.9
    },
    {
      "file_path": "app/main.py",
      "line_number": 238,
      "description": "HIGH: No Celery worker process or task queue initialization in application startup. ADR requires dedicated worker processes but they're not configured.",
      "risk_level": "high",
      "remediation_suggestion": "Add Celery app initialization and worker startup configuration in lifespan handler",
      "confidence": 0.88
    },
    {
      "file_path": "app/api/endpoints/",
      "line_number": 1,
      "description": "CRITICAL: No scan initiation endpoints exist. ADR specifically requires POST /api/v1/scans to initiate long-running tasks like PyRIT orchestrator or Garak scans.",
      "risk_level": "critical",
      "remediation_suggestion": "Create scans.py with endpoints for initiating PyRIT orchestrator and Garak security scans",
      "confidence": 0.95
    },
    {
      "file_path": "app/api/endpoints/",
      "line_number": 1,
      "description": "CRITICAL: No task status polling endpoints. ADR mandates GET /api/v1/tasks/{task_id} for HTTP polling pattern but this endpoint doesn't exist.",
      "risk_level": "critical",
      "remediation_suggestion": "Create tasks.py with status checking endpoint returning task status, progress, and result URLs",
      "confidence": 0.95
    },
    {
      "file_path": "app/schemas/__init__.py",
      "line_number": 1,
      "description": "HIGH: No task-related schemas defined. ADR requires schemas for task creation, status responses, and webhook payloads.",
      "risk_level": "high",
      "remediation_suggestion": "Create TaskCreate, TaskStatus, TaskResponse, and WebhookPayload schemas with proper validation",
      "confidence": 0.85
    },
    {
      "file_path": "app/services/",
      "line_number": 1,
      "description": "CRITICAL: No task service layer for managing async operations. ADR requires service layer to handle task creation, status tracking, and webhook delivery.",
      "risk_level": "critical",
      "remediation_suggestion": "Create TaskService class with methods for create_task, get_task_status, update_task_status, and send_webhook",
      "confidence": 0.9
    },
    {
      "file_path": "app/api/routes.py",
      "line_number": 21,
      "description": "API router structure does not implement versioned prefixes using APIRouter instances for different versions. All endpoints are included under a single router without version-specific organization.",
      "risk_level": "high",
      "remediation_suggestion": "Implement version-specific APIRouter instances (e.g., v1_router, v2_router) and structure routing to support concurrent API versions as specified in ADR-004",
      "confidence": 0.95
    },
    {
      "file_path": "app/main.py",
      "line_number": 216,
      "description": "Application router mounting uses a single API_V1_STR prefix without provisions for multiple concurrent versions. No backend architecture for handling version-specific controllers exists.",
      "risk_level": "high",
      "remediation_suggestion": "Modify the application startup to support multiple versioned routers and implement shared business logic services called by version-specific controllers",
      "confidence": 0.9
    },
    {
      "file_path": "app/core/config.py",
      "line_number": 31,
      "description": "Configuration hardcodes API_V1_STR without provisions for API_V2_STR or dynamic version configuration. No support for managing multiple concurrent API versions.",
      "risk_level": "medium",
      "remediation_suggestion": "Add configuration support for multiple API versions (API_V1_STR, API_V2_STR) and implement version-specific settings management",
      "confidence": 0.85
    },
    {
      "file_path": "app/api/endpoints/auth.py",
      "line_number": 26,
      "description": "No implementation of deprecation headers (Deprecation, Warning) in API responses as required by ADR-004 deprecation policy.",
      "risk_level": "medium",
      "remediation_suggestion": "Implement middleware or response handling to add Deprecation and Warning headers for deprecated API versions",
      "confidence": 0.8
    },
    {
      "file_path": "app/main.py",
      "line_number": 146,
      "description": "OpenAPI documentation generation does not support version-specific documentation paths. No provisions for /api/v1/docs, /api/v2/docs separation.",
      "risk_level": "medium",
      "remediation_suggestion": "Implement version-specific OpenAPI documentation generation with separate docs endpoints for each API version",
      "confidence": 0.85
    },
    {
      "file_path": "app/main.py",
      "line_number": 1,
      "description": "Missing ProviderPlugin abstract interface implementation. The main application does not define or import the required ProviderPlugin abstract base class as specified in lines 85-116 of the ADR.",
      "risk_level": "critical",
      "remediation_suggestion": "Create app/providers/base.py with the ProviderPlugin abstract interface including send_chat_completion, list_available_models, and validate_credentials methods",
      "confidence": 0.98
    },
    {
      "file_path": "app/",
      "line_number": 1,
      "description": "Missing plugin discovery mechanism. The ADR specifies that plugins should be discovered by scanning a violentutf_api/plugins/ directory at startup (line 120-121), but no such directory or discovery mechanism exists.",
      "risk_level": "critical",
      "remediation_suggestion": "Create app/providers/plugins/ directory structure and implement plugin discovery in app/core/startup.py to automatically register plugin modules",
      "confidence": 0.99
    },
    {
      "file_path": "app/models/",
      "line_number": 1,
      "description": "Missing Generator database model. The ADR specifies a Generator database schema with name, plugin_name, model_id, and credentials_id fields (lines 122-130), but no such model exists in app/models/",
      "risk_level": "critical",
      "remediation_suggestion": "Create app/models/generator.py with Generator model including name, plugin_name, model_id, and credentials_id fields as specified in the ADR",
      "confidence": 0.97
    },
    {
      "file_path": "app/core/external_services.py",
      "line_number": 38,
      "description": "Generic external services implementation does not follow the specific ProviderPlugin pattern. While AI_MODEL service type exists, it lacks the standardized send_chat_completion, list_available_models, and validate_credentials interface methods required by the ADR.",
      "risk_level": "high",
      "remediation_suggestion": "Refactor external_services.py to implement provider-specific plugins that inherit from ProviderPlugin interface or create separate plugin system alongside existing external services",
      "confidence": 0.85
    },
    {
      "file_path": "app/core/startup.py",
      "line_number": 13,
      "description": "Startup handler does not implement plugin registration. The ADR requires dynamic loading and registration of plugins at application startup, but on_startup() only initializes cache and auth services.",
      "risk_level": "high",
      "remediation_suggestion": "Add plugin discovery and registration logic to on_startup() function to scan plugins directory and register ProviderPlugin implementations",
      "confidence": 0.92
    },
    {
      "file_path": "app/",
      "line_number": 1,
      "description": "Missing provider-specific plugin implementations. The ADR explicitly mentions OpenAI, Anthropic, and Ollama as examples, but no concrete plugin implementations exist for any AI providers.",
      "risk_level": "critical",
      "remediation_suggestion": "Create concrete plugin implementations such as app/providers/plugins/openai_plugin.py, app/providers/plugins/anthropic_plugin.py that implement the ProviderPlugin interface",
      "confidence": 0.96
    },
    {
      "file_path": "app/repositories/",
      "line_number": 1,
      "description": "Missing Generator repository for managing generator configurations. The ADR implies CRUD operations for Generator entities, but no repository exists for managing generators.",
      "risk_level": "medium",
      "remediation_suggestion": "Create app/repositories/generator.py with GeneratorRepository class to handle CRUD operations for Generator entities",
      "confidence": 0.88
    },
    {
      "file_path": "app/api/endpoints/",
      "line_number": 1,
      "description": "Missing Generator management endpoints. The ADR describes generators as user-configurable endpoints, but no API endpoints exist for managing generator configurations.",
      "risk_level": "medium",
      "remediation_suggestion": "Create app/api/endpoints/generators.py with endpoints for creating, reading, updating, and deleting generator configurations",
      "confidence": 0.9
    },
    {
      "file_path": "app/db/base.py",
      "line_number": 11,
      "description": "Database schema missing Generator table registration. The base.py file imports models for Alembic discovery but does not include any Generator model import.",
      "risk_level": "medium",
      "remediation_suggestion": "Add 'from app.models.generator import Generator' import to base.py after creating the Generator model",
      "confidence": 0.94
    },
    {
      "file_path": "app/middleware/authentication.py",
      "line_number": 114,
      "description": "JWT payload missing 'organization_id' claim required by ADR-003. Only 'sub' and 'roles' claims are extracted, but ABAC layer requires organization_id for multi-tenant data isolation.",
      "risk_level": "critical",
      "remediation_suggestion": "Add organization_id extraction from JWT payload: request.state.organization_id = payload.get('organization_id')",
      "confidence": 0.95
    },
    {
      "file_path": "app/repositories/base.py",
      "line_number": 97,
      "description": "Base repository missing ABAC enforcement - queries do not filter by organization_id. ADR-003 requires all data access queries to filter by organization_id from user's token.",
      "risk_level": "critical",
      "remediation_suggestion": "Add organization_id filtering to all data access methods in BaseRepository and override in specific repositories",
      "confidence": 0.9
    },
    {
      "file_path": "app/api/endpoints/users.py",
      "line_number": 304,
      "description": "User endpoint missing ABAC organization_id filtering. Current user lookup does not enforce organization boundary as required by ADR-003.",
      "risk_level": "high",
      "remediation_suggestion": "Add organization_id filtering to user repository calls and ensure queries include AND organization_id = :org_id clause",
      "confidence": 0.88
    },
    {
      "file_path": "app/api/endpoints/api_keys.py",
      "line_number": 324,
      "description": "API Key listing missing organization_id filtering. Users can potentially access API keys from other organizations violating ABAC requirements.",
      "risk_level": "high",
      "remediation_suggestion": "Add organization_id filtering to API key repository queries to ensure tenant data isolation",
      "confidence": 0.85
    },
    {
      "file_path": "app/core/permissions.py",
      "line_number": 232,
      "description": "Permission checking system lacks organization context. RBAC service calls don't consider organization_id for permission checks, violating hybrid RBAC+ABAC model.",
      "risk_level": "high",
      "remediation_suggestion": "Modify permission checking to include organization context and validate user permissions within their organization scope",
      "confidence": 0.82
    },
    {
      "file_path": "app/models/user.py",
      "line_number": 95,
      "description": "User model defines roles as simple array but lacks organization-scoped roles. ADR-003 requires roles to be organization-aware for proper RBAC implementation.",
      "risk_level": "medium",
      "remediation_suggestion": "Consider implementing organization-scoped roles or ensure role validation considers organization context",
      "confidence": 0.78
    },
    {
      "file_path": "app/services/rbac_service.py",
      "line_number": 324,
      "description": "RBAC service get_user_roles method missing organization filtering. Roles should be scoped to user's organization per ADR-003 requirements.",
      "risk_level": "high",
      "remediation_suggestion": "Add organization_id parameter to role queries and ensure role assignments are organization-scoped",
      "confidence": 0.85
    },
    {
      "file_path": "app/db/base.py",
      "line_number": 9,
      "description": "Missing import for vulnerability_taxonomies model - ADR requires database tables for vulnerability classification but no models exist",
      "risk_level": "critical",
      "remediation_suggestion": "Create VulnerabilityTaxonomy and TaxonomyMapping models as specified in ADR schema",
      "confidence": 0.99
    },
    {
      "file_path": "app/models/__init__.py",
      "line_number": 12,
      "description": "No vulnerability taxonomy models exported - ADR requires VulnerabilityTaxonomy model but it's missing from __all__",
      "risk_level": "critical",
      "remediation_suggestion": "Create VulnerabilityTaxonomy and TaxonomyMapping models and add them to __all__",
      "confidence": 0.99
    },
    {
      "file_path": "alembic/versions/0d9d1d5fbe10_initial_database_models_with_.py",
      "line_number": 194,
      "description": "Missing database tables for vulnerability taxonomy - ADR specifies vulnerability_taxonomies and taxonomy_mappings tables but they were never created",
      "risk_level": "critical",
      "remediation_suggestion": "Create new Alembic migration to add vulnerability_taxonomies and taxonomy_mappings tables with specified schema",
      "confidence": 0.99
    },
    {
      "file_path": "app/api/routes.py",
      "line_number": 120,
      "description": "Missing API endpoints for vulnerability taxonomy management - ADR requires ability to manage vulnerability classifications via API",
      "risk_level": "high",
      "remediation_suggestion": "Create vulnerability taxonomy API endpoints for CRUD operations on taxonomies and mappings",
      "confidence": 0.95
    },
    {
      "file_path": "app/schemas/__init__.py",
      "line_number": 1,
      "description": "No Pydantic schemas for vulnerability taxonomies - ADR requires data validation for vulnerability classification",
      "risk_level": "high",
      "remediation_suggestion": "Create VulnerabilityTaxonomySchema and TaxonomyMappingSchema for API validation",
      "confidence": 0.95
    },
    {
      "file_path": "app/repositories/__init__.py",
      "line_number": 1,
      "description": "Missing repository classes for vulnerability taxonomy data access - ADR requires database-driven taxonomy but no data access layer exists",
      "risk_level": "high",
      "remediation_suggestion": "Create VulnerabilityTaxonomyRepository and TaxonomyMappingRepository for data access",
      "confidence": 0.95
    },
    {
      "file_path": "app/core/errors.py",
      "line_number": 15,
      "description": "ErrorDetail model uses custom format instead of RFC 7807 structure. Missing required fields: 'type', 'title', 'status', 'detail', 'instance'. Using non-standard fields: 'error', 'message', 'request_id', 'path', 'timestamp'",
      "risk_level": "critical",
      "remediation_suggestion": "Replace ErrorDetail with RFC 7807 compliant model containing 'type', 'title', 'status', 'detail', 'instance' fields, plus custom 'correlation_id' and 'error_code' extensions",
      "confidence": 0.98
    },
    {
      "file_path": "app/core/errors.py",
      "line_number": 153,
      "description": "Error responses not using 'application/problem+json' content type as required by RFC 7807",
      "risk_level": "critical",
      "remediation_suggestion": "Add Content-Type header 'application/problem+json' to all JSONResponse error returns",
      "confidence": 0.99
    },
    {
      "file_path": "app/core/errors.py",
      "line_number": 121,
      "description": "Missing Error Dictionary implementation. No centralized mapping of error codes to RFC 7807 type URIs as specified in ADR",
      "risk_level": "high",
      "remediation_suggestion": "Create error_dictionary.py with mappings like {'VUTF-1001': {'status': 400, 'title': 'Validation Error', 'type': '/errors/validation-error'}}",
      "confidence": 0.95
    },
    {
      "file_path": "app/core/errors.py",
      "line_number": 132,
      "description": "Using 'request_id' instead of 'correlation_id' as specified in ADR-009. Also missing 'error_code' field",
      "risk_level": "medium",
      "remediation_suggestion": "Change field name from 'request_id' to 'correlation_id' and add 'error_code' field to match ADR specification",
      "confidence": 0.97
    },
    {
      "file_path": "app/schemas/base.py",
      "line_number": 182,
      "description": "APIErrorResponse schema exists but implements RFC 7807 structure, however it's not being used in actual error handlers",
      "risk_level": "medium",
      "remediation_suggestion": "Update error handlers in app/core/errors.py to use APIErrorResponse schema instead of ErrorDetail",
      "confidence": 0.85
    },
    {
      "file_path": "app/main.py",
      "line_number": 49,
      "description": "Rate limit handler returns non-RFC 7807 compliant error format with 'detail' and 'type' fields but missing required 'title', 'status', 'instance'",
      "risk_level": "medium",
      "remediation_suggestion": "Update rate_limit_handler to return RFC 7807 compliant response using centralized error handling",
      "confidence": 0.9
    },
    {
      "file_path": "app/middleware/request_signing.py",
      "line_number": 95,
      "description": "Multiple middleware files returning ad-hoc error responses instead of using centralized RFC 7807 handler",
      "risk_level": "medium",
      "remediation_suggestion": "Replace direct JSONResponse usage with centralized error handling that enforces RFC 7807 format",
      "confidence": 0.88
    },
    {
      "file_path": "app/api/endpoints/audit_logs.py",
      "line_number": 620,
      "description": "Export endpoint supports CSV format (text/csv) in addition to JSON, violating the ADR requirement for JSON-only data serialization",
      "risk_level": "medium",
      "remediation_suggestion": "Remove CSV export functionality and provide JSON-only exports, or document this as an approved exception for data export requirements",
      "confidence": 0.95
    },
    {
      "file_path": "app/api/endpoints/oauth.py",
      "line_number": 220,
      "description": "OAuth authorization endpoint uses HTMLResponse for user authorization flow, violating JSON-only requirement",
      "risk_level": "high",
      "remediation_suggestion": "Refactor OAuth authorization flow to use JSON-based API responses with separate frontend handling, or document as approved exception for OAuth2 specification compliance",
      "confidence": 0.9
    },
    {
      "file_path": "app/api/endpoints/oauth.py",
      "line_number": 235,
      "description": "OAuth authorization page returns HTML content directly from API endpoint",
      "risk_level": "high",
      "remediation_suggestion": "Separate HTML OAuth pages from API endpoints and serve via static content or dedicated frontend service",
      "confidence": 0.9
    },
    {
      "file_path": "app/middleware/input_sanitization.py",
      "line_number": 46,
      "description": "Input sanitization middleware explicitly handles text/plain content type, indicating API accepts non-JSON request bodies",
      "risk_level": "medium",
      "remediation_suggestion": "Remove text/plain content type support and restrict to application/json only",
      "confidence": 0.8
    },
    {
      "file_path": ".github/workflows/pr-validation.yml",
      "line_number": 62,
      "description": "pip-audit is not implemented as a blocking CI/CD step in PR validation workflow. ADR mandates pip-audit as mandatory blocking quality gate, but workflow uses 'safety check' instead on line 62",
      "risk_level": "critical",
      "remediation_suggestion": "Add pip-audit as blocking step with '--fail-on-high --fail-on-critical' flags before the existing safety check",
      "confidence": 0.95
    },
    {
      "file_path": ".github/workflows/ci.yml",
      "line_number": 1,
      "description": "Main CI pipeline lacks pip-audit integration completely. ADR requires pip-audit scanning on every code change, but CI workflow has no dependency vulnerability scanning",
      "risk_level": "high",
      "remediation_suggestion": "Add pip-audit scanning step to quick-quality job with failure conditions for CRITICAL/HIGH vulnerabilities",
      "confidence": 0.92
    },
    {
      "file_path": "security/pip-audit-report.json",
      "line_number": 1,
      "description": "Current pip-audit scan shows 10 vulnerable dependencies (aiohttp, mcp, pillow, protobuf, requests, starlette, torch, tornado, transformers, urllib3) with 12 total vulnerabilities, violating ADR blocking policy",
      "risk_level": "high",
      "remediation_suggestion": "Upgrade or replace vulnerable dependencies immediately as per ADR-010 SLO requirements",
      "confidence": 0.98
    },
    {
      "file_path": "docs/architecture/ADRs/ADR-010_SoftwareDependencies.md",
      "line_number": 77,
      "description": "No formal Vulnerability Management Policy implementation with defined SLOs. ADR specifies CRITICAL (7 days), HIGH (30 days), MEDIUM (90 days) remediation timelines but no enforcement mechanism exists",
      "risk_level": "medium",
      "remediation_suggestion": "Implement automated vulnerability SLO tracking system with alerts and escalation procedures",
      "confidence": 0.85
    },
    {
      "file_path": "docs/architecture/ADRs/ADR-010_SoftwareDependencies.md",
      "line_number": 85,
      "description": "No License Compliance Policy implementation. ADR defines approved (MIT, Apache-2.0), restricted (LGPL), and prohibited (GPL) licenses but no automated checking exists",
      "risk_level": "medium",
      "remediation_suggestion": "Integrate license scanning tools like pip-licenses with CI/CD pipeline to enforce license policy",
      "confidence": 0.88
    },
    {
      "file_path": ".github/workflows/pr-validation.yml",
      "line_number": 62,
      "description": "Safety tool used as primary dependency scanner, but ADR specifically mandates pip-audit. While both are valid SCA tools, this deviates from ADR specifications",
      "risk_level": "medium",
      "remediation_suggestion": "Replace safety with pip-audit as primary scanner, or supplement safety with pip-audit to ensure ADR compliance",
      "confidence": 0.78
    },
    {
      "file_path": ".pre-commit-config.yaml",
      "line_number": 74,
      "description": "No pip-audit integration in pre-commit hooks. While bandit is present, ADR specifically requires pip-audit for dependency vulnerability scanning in development workflow",
      "risk_level": "low",
      "remediation_suggestion": "Add pip-audit hook to pre-commit configuration to catch vulnerabilities during development",
      "confidence": 0.72
    },
    {
      "file_path": "app/services/",
      "line_number": null,
      "description": "Missing core templating service implementation - no service class found that implements Jinja2 sandboxed templating for attack payloads as specified in ADR",
      "risk_level": "critical",
      "remediation_suggestion": "Create app/services/templating_service.py implementing SandboxedEnvironment with custom filters (base64encode, leetspeak, urlencode, json_escape) and resource limits",
      "confidence": 0.99
    },
    {
      "file_path": "app/api/endpoints/",
      "line_number": null,
      "description": "Missing templating API endpoint - no REST endpoint found for template rendering functionality required by ADR",
      "risk_level": "critical",
      "remediation_suggestion": "Create app/api/endpoints/templating.py with POST /template/render endpoint accepting template and data parameters",
      "confidence": 0.99
    },
    {
      "file_path": "app/schemas/",
      "line_number": null,
      "description": "Missing templating schema models - no Pydantic models found for template request/response validation",
      "risk_level": "high",
      "remediation_suggestion": "Create app/schemas/templating.py with TemplateRequest, TemplateResponse, and TemplateError models",
      "confidence": 0.95
    },
    {
      "file_path": "requirements.txt",
      "line_number": 56,
      "description": "Jinja2 dependency present but no custom filters implementation found - ADR requires base64encode, leetspeak, urlencode, json_escape, reverse filters",
      "risk_level": "high",
      "remediation_suggestion": "Implement custom filter functions in templating service and register them with SandboxedEnvironment",
      "confidence": 0.9
    },
    {
      "file_path": "app/core/",
      "line_number": null,
      "description": "Missing resource limiting implementation - ADR requires CPU time and memory limits for template execution",
      "risk_level": "high",
      "remediation_suggestion": "Implement resource limiting wrapper using multiprocessing or threading with timeout controls in templating service",
      "confidence": 0.85
    },
    {
      "file_path": "tests/",
      "line_number": null,
      "description": "Missing security tests for templating engine - no tests found validating sandbox escape prevention or SSTI protection",
      "risk_level": "high",
      "remediation_suggestion": "Create tests/unit/services/test_templating_security.py with SSTI injection attempt tests and sandbox validation",
      "confidence": 0.9
    },
    {
      "file_path": "app/models/",
      "line_number": null,
      "description": "Missing database models for template storage - no models found for storing user templates or template execution history",
      "risk_level": "medium",
      "remediation_suggestion": "Consider creating Template and TemplateExecution models if persistent storage is required",
      "confidence": 0.75
    },
    {
      "file_path": "app/middleware/rate_limiting.py",
      "line_number": 154,
      "description": "Rate limiting middleware bypasses actual enforcement with comment 'Skip actual rate limiting in test/development mode'. This violates ADR-005's requirement for consistent multi-layered protection.",
      "risk_level": "high",
      "remediation_suggestion": "Implement proper rate limiting logic using Redis backend as specified in ADR-005, replacing the test/development bypass",
      "confidence": 0.95
    },
    {
      "file_path": "app/core/rate_limiting.py",
      "line_number": 105,
      "description": "Token Bucket algorithm not properly implemented - using SlowAPI's default implementation instead of the specified Token Bucket algorithm from ADR-005.",
      "risk_level": "medium",
      "remediation_suggestion": "Implement proper Token Bucket algorithm as specified in ADR-005 decision section",
      "confidence": 0.9
    },
    {
      "file_path": "app/core/rate_limiting.py",
      "line_number": 195,
      "description": "Function add_rate_limit_headers() is empty implementation with comment 'Headers are automatically added by SlowAPI'. Missing validation that required headers (X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset) are actually present.",
      "risk_level": "medium",
      "remediation_suggestion": "Implement verification that all required rate limit headers per ADR-005 are included in responses",
      "confidence": 0.88
    },
    {
      "file_path": "app/core/config.py",
      "line_number": 64,
      "description": "Redis URL is optional with default None, but ADR-005 explicitly requires Redis for state management in distributed deployments. Missing enforcement of Redis requirement for production.",
      "risk_level": "high",
      "remediation_suggestion": "Enforce Redis URL as required setting when ENVIRONMENT=production and RATE_LIMIT_ENABLED=True",
      "confidence": 0.92
    },
    {
      "file_path": "app/middleware/rate_limiting.py",
      "line_number": 87,
      "description": "Rate limit headers are added with placeholder values (X-RateLimit-Remaining=0, X-RateLimit-Limit=varies) instead of actual rate limit state, violating ADR-005 transparency requirements.",
      "risk_level": "medium",
      "remediation_suggestion": "Integrate with actual rate limiter state to provide accurate remaining count and reset time",
      "confidence": 0.85
    },
    {
      "file_path": "app/api/endpoints/auth.py",
      "line_number": 20,
      "description": "Rate limiting import present but no evidence of @rate_limit decorator usage on authentication endpoints, violating ADR-005 Layer 3 requirement for authentication endpoint protection.",
      "risk_level": "high",
      "remediation_suggestion": "Apply @rate_limit('auth_login') decorator to login endpoints and other auth endpoints as specified in ADR-005",
      "confidence": 0.87
    },
    {
      "file_path": "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/auth_failover.py",
      "line_number": 12,
      "description": "Missing import for connection pooling implementation - ADR specifies consistent hashing for distributed caching but no connection pooling strategy is implemented",
      "risk_level": "medium",
      "remediation_suggestion": "Add Redis connection pooling configuration with consistent hashing for distributed cache scenarios as specified in ADR Implementation Components section 1",
      "confidence": 0.85
    },
    {
      "file_path": "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/services/health_service.py",
      "line_number": 232,
      "description": "Circuit breaker health check implementation references non-existent function get_all_circuit_stats() - should be get_all_circuit_breaker_stats() from utils module",
      "risk_level": "high",
      "remediation_suggestion": "Fix import path to use correct function from app.utils.circuit_breaker module: 'from app.utils.circuit_breaker import get_all_circuit_breaker_stats'",
      "confidence": 0.95
    },
    {
      "file_path": "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/cache.py",
      "line_number": 304,
      "description": "Redis pipeline implementation lacks proper error handling for partial failures during batch operations, violating write-through caching consistency requirement",
      "risk_level": "medium",
      "remediation_suggestion": "Add transaction rollback logic for failed pipeline operations to maintain cache consistency as required by ADR section 1",
      "confidence": 0.8
    },
    {
      "file_path": "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/middleware/authentication.py",
      "line_number": 94,
      "description": "Authentication middleware lacks integration with fallback auth provider - no failover mechanism implemented when primary JWT validation fails",
      "risk_level": "high",
      "remediation_suggestion": "Integrate FallbackAuthProvider.authenticate_fallback() as secondary authentication method when JWT validation fails to implement ADR requirement 3",
      "confidence": 0.9
    },
    {
      "file_path": "app/middleware/authentication.py",
      "line_number": 114,
      "description": "Authentication middleware sets user_id in request.state but does not bind organization_id and user_id to logging context for multi-tenant auditing as required by ADR-008",
      "risk_level": "high",
      "remediation_suggestion": "Add log_request_context call in authentication middleware to bind user_id and organization_id from token payload to all subsequent logs",
      "confidence": 0.95
    },
    {
      "file_path": "app/core/logging.py",
      "line_number": 15,
      "description": "Missing service_name field in log schema - ADR-008 requires 'service_name' field but only 'service' is added via add_app_context processor",
      "risk_level": "medium",
      "remediation_suggestion": "Rename 'service' field to 'service_name' in add_app_context function to match ADR-008 schema requirement",
      "confidence": 0.9
    },
    {
      "file_path": "app/middleware/logging.py",
      "line_number": 30,
      "description": "HTTP logging middleware doesn't populate auth_context with organization_id and user_id as required by ADR-008 multi-tenant logging schema",
      "risk_level": "high",
      "remediation_suggestion": "Extract user_id and organization_id from request.state and include in log entries as auth_context object",
      "confidence": 0.92
    },
    {
      "file_path": "app/db/init_mfa_policies.py",
      "line_number": 86,
      "description": "Using unstructured print() statements instead of structured JSON logging as mandated by ADR-008",
      "risk_level": "medium",
      "remediation_suggestion": "Replace print() calls with structured logger.info() calls to maintain consistent JSON logging format",
      "confidence": 0.98
    },
    {
      "file_path": "app/middleware/logging.py",
      "line_number": 34,
      "description": "Missing required http_context fields - ADR-008 requires source_ip, method, path, status_code but only partial implementation exists",
      "risk_level": "medium",
      "remediation_suggestion": "Add complete http_context object with source_ip from request headers and status_code from response",
      "confidence": 0.88
    },
    {
      "file_path": "app/",
      "line_number": 0,
      "description": "Missing ScorerPlugin abstract base class - The ADR specifies a 'ScorerPlugin' interface with SCORER_TYPE, SCORER_NAME, and score() method, but no such implementation exists in the codebase",
      "risk_level": "critical",
      "remediation_suggestion": "Implement app/core/scoring/plugin.py with the ScorerPlugin ABC as specified in ADR lines 108-124",
      "confidence": 0.95
    },
    {
      "file_path": "app/models/session.py",
      "line_number": 1,
      "description": "Missing evidence document storage model - The ADR requires storing prompt/response pairs as 'evidence documents' with triage and deep analysis scores, but Session model only handles user authentication sessions",
      "risk_level": "critical",
      "remediation_suggestion": "Create app/models/evidence.py with fields for prompt_text, response_text, triage_scores, deep_analysis_scores, and session_id foreign key",
      "confidence": 0.98
    },
    {
      "file_path": "app/models/session.py",
      "line_number": 93,
      "description": "Missing session_summary table with analysis_status - ADR specifies session_summary needs analysis_status column to track scoring completion, but current session model lacks this field",
      "risk_level": "high",
      "remediation_suggestion": "Add analysis_status field to Session model or create separate SessionSummary model as specified in ADR line 146",
      "confidence": 0.9
    },
    {
      "file_path": "app/",
      "line_number": 0,
      "description": "Missing async task processing infrastructure - ADR requires task queue system (ADR-007) for background scoring workers, but no Celery/Redis task queue implementation found",
      "risk_level": "critical",
      "remediation_suggestion": "Implement Celery task queue with Redis broker as specified in ADR-007, create app/workers/scoring_worker.py for deep analysis processing",
      "confidence": 0.95
    },
    {
      "file_path": "app/",
      "line_number": 0,
      "description": "Missing real-time triage scoring integration - No evidence of lightweight real-time scorers being applied during test execution as required by Phase 1 of the hybrid architecture",
      "risk_level": "high",
      "remediation_suggestion": "Implement real-time scoring integration in orchestration endpoints to apply lightweight scorers immediately after receiving model responses",
      "confidence": 0.92
    },
    {
      "file_path": "app/",
      "line_number": 0,
      "description": "Missing deep analysis batch processing - No implementation of Phase 2 asynchronous batch job processing for expensive computational scoring after test completion",
      "risk_level": "high",
      "remediation_suggestion": "Create deep analysis worker process to handle batch scoring jobs triggered after test completion using the task queue system",
      "confidence": 0.93
    },
    {
      "file_path": "app/api/endpoints/",
      "line_number": 0,
      "description": "Missing orchestration endpoints - ADR refers to orchestration workers receiving responses from target AI models, but no AI model interaction endpoints found",
      "risk_level": "medium",
      "remediation_suggestion": "Implement endpoints for AI model orchestration that integrate with the scoring architecture as specified in ADR execution flow",
      "confidence": 0.85
    },
    {
      "file_path": "app/",
      "line_number": 0,
      "description": "Missing document database integration - ADR specifies evidence documents stored in document database, but only PostgreSQL/SQLAlchemy relational DB found",
      "risk_level": "medium",
      "remediation_suggestion": "Integrate document database (MongoDB, CouchDB) for flexible evidence storage or extend current models to handle nested scoring data",
      "confidence": 0.88
    },
    {
      "file_path": "app/main.py",
      "line_number": 146,
      "description": "OpenAPI documentation URL does not follow versioned URI path pattern '/api/v1/openapi.json' - uses f'{app_settings.API_V1_STR}/openapi.json' which may not align with clear URI versioning strategy",
      "risk_level": "medium",
      "remediation_suggestion": "Ensure API_V1_STR consistently resolves to '/api/v1' and validate URI path versioning strategy aligns with ADR requirement for clear URI path versioning (e.g., '/api/v1/...')",
      "confidence": 0.75
    },
    {
      "file_path": "app/core/config.py",
      "line_number": 31,
      "description": "API versioning is defined as field but not explicitly validated for REST-compliant URI pattern format. ADR requires clear URI path versioning strategy",
      "risk_level": "low",
      "remediation_suggestion": "Add validation to ensure API_V1_STR follows REST-compliant versioning pattern '/api/v{version}' and add field validator to enforce proper URI structure",
      "confidence": 0.85
    },
    {
      "file_path": "app/api/base.py",
      "line_number": 77,
      "description": "Pagination implementation may not fully mitigate REST's over-fetching weakness as specified in ADR. While pagination exists, comprehensive field selection capabilities for addressing over-fetching are not evident in base CRUD operations",
      "risk_level": "medium",
      "remediation_suggestion": "Enhance field selection implementation in BaseCRUDRouter to fully address REST over-fetching concerns. Implement comprehensive field selection parameters in all list endpoints as specified in ADR rationale point 4",
      "confidence": 0.8
    },
    {
      "file_path": "app/utils/field_selection.py",
      "line_number": 1,
      "description": "Field selection utility exists but integration with main CRUD endpoints is not evident in the analyzed base router implementation",
      "risk_level": "medium",
      "remediation_suggestion": "Ensure field_selection utility is properly integrated into all REST endpoints to implement comprehensive field selection capabilities as required by ADR for mitigating over-fetching",
      "confidence": 0.7
    },
    {
      "file_path": "app/api/endpoints/users.py",
      "line_number": 35,
      "description": "Custom CRUD router implementation bypasses some base functionality, potentially inconsistent with standardized REST patterns across the API surface",
      "risk_level": "low",
      "remediation_suggestion": "Review user endpoint implementation to ensure it maintains consistent REST patterns and doesn't create 'endpoint sprawl' mentioned as a concern in ADR consequences",
      "confidence": 0.65
    },
    {
      "file_path": "app/api/routes.py",
      "line_number": 21,
      "description": "Critical violation: No orchestrator API endpoints implemented. ADR mandates POST /api/v1/orchestrators/execute endpoint that accepts YAML/JSON workflow definitions and returns 202 Accepted with task_id. Current routes.py only includes basic CRUD endpoints (auth, users, sessions, etc.) but no orchestrator endpoints.",
      "risk_level": "critical",
      "remediation_suggestion": "Add orchestrator router import and include POST /api/v1/orchestrators/execute endpoint that integrates with ADR-007 async task processing",
      "confidence": 0.98
    },
    {
      "file_path": "app/models/__init__.py",
      "line_number": 1,
      "description": "Critical violation: No database models for orchestration state management. ADR requires storing orchestration definitions, running state, conversation transcripts, and state transitions. Current models only include user management (user, api_key, session, audit_log, etc.) but no orchestration-related models.",
      "risk_level": "critical",
      "remediation_suggestion": "Create OrchestrationJob, OrchestrationState, OrchestrationTransition, and ConversationTurn models with proper relationships and status tracking",
      "confidence": 0.97
    },
    {
      "file_path": "requirements.txt",
      "line_number": 28,
      "description": "Critical violation: Missing task queue infrastructure. ADR-007 specifies Celery workers for background orchestration execution, but requirements.txt has Redis but no Celery. Background workers are essential for state machine execution.",
      "risk_level": "critical",
      "remediation_suggestion": "Add celery>=5.3.0 and flower>=2.0.0 dependencies for task queue management and monitoring",
      "confidence": 0.95
    },
    {
      "file_path": "app/core/config.py",
      "line_number": 64,
      "description": "High violation: No task queue configuration settings. ADR requires configuration for task queue brokers, worker scaling, and orchestration timeouts. Current config has Redis URL but no Celery or task-specific settings.",
      "risk_level": "high",
      "remediation_suggestion": "Add CELERY_BROKER_URL, CELERY_RESULT_BACKEND, ORCHESTRATION_TIMEOUT, and WORKER_CONCURRENCY configuration fields",
      "confidence": 0.92
    },
    {
      "file_path": "app/main.py",
      "line_number": 216,
      "description": "High violation: No orchestration engine initialization. ADR requires state machine execution engine startup during application lifespan. Current main.py initializes database and cache but no orchestration workers or state machine components.",
      "risk_level": "high",
      "remediation_suggestion": "Add orchestration engine initialization in the lifespan context manager with proper worker startup and shutdown",
      "confidence": 0.9
    },
    {
      "file_path": "app/services",
      "line_number": 1,
      "description": "High violation: Missing orchestration service layer. ADR specifies complex state machine logic, prompt rendering via ADR-F1.1, and transition evaluation. No orchestration service exists in services directory.",
      "risk_level": "high",
      "remediation_suggestion": "Create orchestration_service.py with StateMachineEngine, WorkflowParser, and TransitionEvaluator classes",
      "confidence": 0.93
    },
    {
      "file_path": "requirements.txt",
      "line_number": 56,
      "description": "Medium violation: Template engine dependency exists but orchestration-specific validation missing. ADR requires YAML/JSON schema validation for workflow definitions. Jinja2 is present for ADR-F1.1 but no orchestration schema validation.",
      "risk_level": "medium",
      "remediation_suggestion": "Add jsonschema>=4.19.0 and pyyaml validation libraries for workflow definition validation",
      "confidence": 0.88
    },
    {
      "file_path": "app/api/endpoints",
      "line_number": 1,
      "description": "Medium violation: No task status polling endpoints. ADR-007 integration requires GET /api/v1/tasks/{task_id} for status polling. Current endpoints directory has no task management endpoints.",
      "risk_level": "medium",
      "remediation_suggestion": "Create tasks.py endpoint module with GET /api/v1/tasks/{task_id} and related task status management endpoints",
      "confidence": 0.91
    },
    {
      "file_path": "app/main.py",
      "line_number": 238,
      "description": "No container-based sandboxing infrastructure implemented for untrusted model execution. The application lacks the mandatory Docker SDK integration and ephemeral container provisioning capabilities required by ADR-F4-1.",
      "risk_level": "critical",
      "remediation_suggestion": "Implement Docker SDK integration with container lifecycle management for untrusted model execution",
      "confidence": 0.98
    },
    {
      "file_path": "app/core/external_services.py",
      "line_number": 38,
      "description": "AI_MODEL service type exists but lacks secure sandboxed execution implementation. No container isolation, security profiles, or untrusted code execution safeguards present.",
      "risk_level": "critical",
      "remediation_suggestion": "Implement secure container execution wrapper for AI_MODEL service type with proper isolation",
      "confidence": 0.95
    },
    {
      "file_path": "app/api/routes.py",
      "line_number": 21,
      "description": "No API endpoints exist for untrusted model execution or container management. ADR requires orchestration endpoints to handle sandboxed model interactions.",
      "risk_level": "high",
      "remediation_suggestion": "Add API endpoints for model execution requests with container-based processing",
      "confidence": 0.9
    },
    {
      "file_path": "app/core/config.py",
      "line_number": 1,
      "description": "Configuration lacks container runtime settings, security profiles, and resource limits required for sandboxed execution as mandated by ADR-F4-1.",
      "risk_level": "high",
      "remediation_suggestion": "Add configuration settings for Docker runtime, container security profiles, and resource limits",
      "confidence": 0.92
    },
    {
      "file_path": "Dockerfile",
      "line_number": 1,
      "description": "Application Dockerfile exists but no separate sandbox container image or security-hardened execution environment for untrusted models.",
      "risk_level": "high",
      "remediation_suggestion": "Create hardened sandbox container image with minimal base, non-root user, and restricted capabilities",
      "confidence": 0.88
    },
    {
      "file_path": "pyproject.toml",
      "line_number": 10,
      "description": "Missing Docker SDK dependency required for container management. No container orchestration libraries present in dependencies.",
      "risk_level": "medium",
      "remediation_suggestion": "Add docker library and container management dependencies to pyproject.toml",
      "confidence": 0.85
    },
    {
      "file_path": "app/core/config.py",
      "line_number": 42,
      "description": "JWT algorithm is set to HS256 (symmetric) instead of RS256 (asymmetric) as required by ADR-002. ADR specifies 'RS256 will be used, as asymmetric keys allow the signing key to be kept private while the public key for verification can be widely distributed'",
      "risk_level": "high",
      "remediation_suggestion": "Change ALGORITHM from 'HS256' to 'RS256' and implement asymmetric key management with private/public key pairs",
      "confidence": 0.95
    },
    {
      "file_path": "app/core/security.py",
      "line_number": 96,
      "description": "No token blocklist implementation found for immediate token revocation. ADR-002 states 'A token blocklist will be implemented using a distributed cache (e.g., Redis) to enable immediate revocation of specific tokens or all tokens for a user'",
      "risk_level": "high",
      "remediation_suggestion": "Implement Redis-based token blocklist in decode_token() function to check revoked tokens before validation",
      "confidence": 0.9
    },
    {
      "file_path": "app/models/api_key.py",
      "line_number": 100,
      "description": "API key hash is stored as SHA-256, but ADR-002 does not specify this as the required hashing algorithm. Should use a strong hashing algorithm as specified",
      "risk_level": "medium",
      "remediation_suggestion": "Verify SHA-256 is acceptable or upgrade to bcrypt/Argon2 for API key hashing to match password hashing standards",
      "confidence": 0.75
    },
    {
      "file_path": "app/api/endpoints/auth.py",
      "line_number": 364,
      "description": "Token refresh implements rotation but lacks explicit validation of refresh token uniqueness or storage of used tokens to prevent replay attacks",
      "risk_level": "medium",
      "remediation_suggestion": "Implement refresh token tracking/rotation with database storage to prevent token replay attacks",
      "confidence": 0.8
    },
    {
      "file_path": "app/models/api_key.py",
      "line_number": 218,
      "description": "API key generation uses 'vutf_' prefix instead of the ADR-specified format. ADR states keys should be generated 'with a prefix (e.g., vutf-api_...)'",
      "risk_level": "low",
      "remediation_suggestion": "Change API key prefix from 'vutf_' to 'vutf-api_' to match ADR specification",
      "confidence": 0.85
    },
    {
      "file_path": "app/core/config.py",
      "line_number": 59,
      "description": "Only PostgreSQL DATABASE_URL is configured. Missing MongoDB/DynamoDB connection settings required for session_evidence document storage per ADR lines 70-71",
      "risk_level": "critical",
      "remediation_suggestion": "Add MONGODB_URL, DOCUMENT_DB_NAME, and DOCUMENT_DB_COLLECTION_NAME settings for evidence storage",
      "confidence": 0.98
    },
    {
      "file_path": "app/core/config.py",
      "line_number": 60,
      "description": "No S3/blob storage configuration found. ADR line 71 requires blob storage for cost-effective long-term archival of large raw artifacts",
      "risk_level": "critical",
      "remediation_suggestion": "Add S3_BUCKET_URL, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, and blob storage lifecycle configuration",
      "confidence": 0.97
    },
    {
      "file_path": "app/models/",
      "line_number": 1,
      "description": "Missing critical data models specified in ADR. No models exist for test_configurations, vulnerability_taxonomies, session_summaries, or session_evidence collections",
      "risk_level": "critical",
      "remediation_suggestion": "Create SQLAlchemy models for PostgreSQL tables (test_configurations, session_summaries, vulnerability_taxonomies) and Pydantic models for MongoDB documents (session_evidence)",
      "confidence": 0.99
    },
    {
      "file_path": "app/db/session.py",
      "line_number": 40,
      "description": "Only relational database session management exists. Missing document database session factory and blob storage client initialization per ADR polyglot architecture",
      "risk_level": "high",
      "remediation_suggestion": "Implement MongoDBSessionFactory and S3Client classes with connection pooling and circuit breakers",
      "confidence": 0.95
    },
    {
      "file_path": "app/repositories/",
      "line_number": 1,
      "description": "No polyglot persistence repository pattern implemented. ADR requires database routing logic to direct queries to appropriate storage system based on data type",
      "risk_level": "high",
      "remediation_suggestion": "Create PolyglotRepository base class with routing logic: structured data → PostgreSQL, evidence data → MongoDB, large files → S3",
      "confidence": 0.93
    },
    {
      "file_path": "alembic/versions/",
      "line_number": 1,
      "description": "Missing database migrations for ADR-specified tables. Lines 88-89 require test_configurations, vulnerability_taxonomies, session_summaries tables in PostgreSQL",
      "risk_level": "high",
      "remediation_suggestion": "Create Alembic migrations for the three PostgreSQL tables with proper foreign key relationships and indexes",
      "confidence": 0.96
    },
    {
      "file_path": "app/",
      "line_number": 1,
      "description": "No data lifecycle management implementation found. ADR lines 96-100 mandate automated 90-day hot→cold storage migration with 7-year retention policy",
      "risk_level": "medium",
      "remediation_suggestion": "Implement Celery background tasks for data archival pipeline with configurable retention policies",
      "confidence": 0.9
    },
    {
      "file_path": "app/services/",
      "line_number": 1,
      "description": "Missing evidence storage service layer. ADR line 70 specifies session_evidence documents with structure: session_id, prompt, response, scores, vulnerability_ids",
      "risk_level": "medium",
      "remediation_suggestion": "Create EvidenceStorageService with methods for storing/retrieving test evidence documents in MongoDB with proper indexing",
      "confidence": 0.92
    },
    {
      "file_path": "app/models/api_key.py",
      "line_number": 27,
      "description": "CRITICAL VIOLATION: API keys are stored as SHA256 hashes in the main application database, violating ADR requirement for dedicated secrets manager. Line 27: key_hash: Mapped[str] = mapped_column(String(255), unique=True, nullable=False, index=True, comment=\"SHA256 hash of the API key\")",
      "risk_level": "critical",
      "remediation_suggestion": "Replace database storage with secrets manager reference. Store only non-sensitive pointers to secrets manager locations.",
      "confidence": 0.98
    },
    {
      "file_path": "app/services/api_key_service.py",
      "line_number": 288,
      "description": "CRITICAL VIOLATION: API key generation creates SHA256 hash for database storage, implementing the explicitly rejected 'Encrypted in Application Database' pattern. Line 288: key_hash = hashlib.sha256(full_key.encode()).hexdigest()",
      "risk_level": "critical",
      "remediation_suggestion": "Implement SecretsManagerClient abstraction layer as defined in ADR. Store secrets in dedicated manager, not database.",
      "confidence": 0.95
    },
    {
      "file_path": "app/services/api_key_service.py",
      "line_number": 127,
      "description": "CRITICAL VIOLATION: API key validation retrieves secrets from database hash storage, creating single point of compromise. Line 127-145: validate_api_key method retrieves and validates against database stored hashes.",
      "risk_level": "critical",
      "remediation_suggestion": "Implement just-in-time retrieval from secrets manager instead of database lookup.",
      "confidence": 0.92
    },
    {
      "file_path": "app/core/config.py",
      "line_number": 39,
      "description": "HIGH VIOLATION: Application SECRET_KEY stored as environment variable, not in dedicated secrets manager. Line 39: SECRET_KEY: SecretStr = Field(..., min_length=32)",
      "risk_level": "high",
      "remediation_suggestion": "Move SECRET_KEY to dedicated secrets manager with just-in-time retrieval.",
      "confidence": 0.89
    },
    {
      "file_path": "app/core/security.py",
      "line_number": 53,
      "description": "HIGH VIOLATION: JWT token creation directly accesses SECRET_KEY from configuration, not through secrets manager. Line 53: settings.SECRET_KEY.get_secret_value()",
      "risk_level": "high",
      "remediation_suggestion": "Implement secrets manager client for runtime secret retrieval.",
      "confidence": 0.87
    },
    {
      "file_path": "requirements.txt",
      "line_number": 1,
      "description": "CRITICAL VIOLATION: No dedicated secrets management dependencies found. Missing HashiCorp Vault client, AWS Secrets Manager client, or similar dedicated secrets management libraries.",
      "risk_level": "critical",
      "remediation_suggestion": "Add hvac (HashiCorp Vault), boto3 (AWS Secrets Manager), or google-cloud-secret-manager dependencies to support dedicated secrets management.",
      "confidence": 0.93
    },
    {
      "file_path": "app/core/external_services.py",
      "line_number": 25,
      "description": "MEDIUM VIOLATION: External services integration exists but no AI_MODEL service type configured for third-party AI provider credentials. Line 38: AI_MODEL = \"ai_model\" exists but no implementation found.",
      "risk_level": "medium",
      "remediation_suggestion": "Implement AI provider credential management through secrets manager for OpenAI, Anthropic, and other third-party services.",
      "confidence": 0.78
    },
    {
      "file_path": "app/api/routes.py",
      "line_number": null,
      "description": "Missing required report generation API endpoint '/api/v1/reports/generate' as specified in ADR execution flow step 1. The API router does not include any report-related endpoints.",
      "risk_level": "critical",
      "remediation_suggestion": "Add report generation endpoint with POST /api/v1/reports/generate that accepts config_id parameter and returns 202 Accepted with task_id",
      "confidence": 0.95
    },
    {
      "file_path": "app/api/endpoints/",
      "line_number": null,
      "description": "Missing reports.py endpoint file - no dedicated report endpoints implementation exists in the FastAPI application endpoints directory",
      "risk_level": "critical",
      "remediation_suggestion": "Create app/api/endpoints/reports.py with FastAPI router implementing report generation endpoints",
      "confidence": 0.98
    },
    {
      "file_path": "requirements.txt",
      "line_number": 28,
      "description": "Missing Celery dependency for asynchronous task processing as required by ADR step 2 (task queue integration). Redis is available but Celery worker framework is not installed.",
      "risk_level": "critical",
      "remediation_suggestion": "Add celery>=5.3.0 to requirements.txt and implement Celery worker configuration for report generation tasks",
      "confidence": 0.9
    },
    {
      "file_path": "requirements.txt",
      "line_number": 56,
      "description": "Missing Playwright dependency for HTML to PDF conversion as specified in ADR recommended technology stack. Only Jinja2 templating is present.",
      "risk_level": "high",
      "remediation_suggestion": "Add playwright>=1.40.0 to requirements.txt and implement PDF rendering using headless browser instead of ReportLab",
      "confidence": 0.88
    },
    {
      "file_path": "tools/pre_audit/reporting/",
      "line_number": null,
      "description": "Report generation logic exists in tools directory but is not integrated with FastAPI application as server-side engine. Implementation is standalone rather than part of main API service.",
      "risk_level": "high",
      "remediation_suggestion": "Move report generation logic from tools to app/services and integrate with FastAPI application endpoints",
      "confidence": 0.85
    },
    {
      "file_path": "tools/pre_audit/reporting/exporters/pdf_generator.py",
      "line_number": 15,
      "description": "PDF generation uses ReportLab instead of ADR-specified Playwright headless browser approach. This violates the recommended technology stack in ADR implementation details.",
      "risk_level": "medium",
      "remediation_suggestion": "Replace ReportLab PDF generation with Playwright-based HTML to PDF conversion as specified in ADR",
      "confidence": 0.82
    },
    {
      "file_path": "app/",
      "line_number": null,
      "description": "Missing dedicated reporting worker processes and task management infrastructure for long-running report generation jobs",
      "risk_level": "high",
      "remediation_suggestion": "Implement Celery worker processes specifically configured for report generation with proper resource limits",
      "confidence": 0.9
    },
    {
      "file_path": "app/models/",
      "line_number": null,
      "description": "Missing report configuration and task models for storing report generation state and configuration as required by ADR execution flow",
      "risk_level": "medium",
      "remediation_suggestion": "Create SQLAlchemy models for ReportConfiguration and ReportTask to support async task tracking",
      "confidence": 0.87
    },
    {
      "file_path": "app/",
      "line_number": null,
      "description": "Missing blob storage integration for saving generated PDF and JSON artifacts as specified in ADR step 8 (storage and completion)",
      "risk_level": "medium",
      "remediation_suggestion": "Implement blob storage service integration for persisting generated report files with secure URLs",
      "confidence": 0.85
    }
  ],
  "violation_summary": {
    "total_violations": 137,
    "by_risk_level": {
      "medium": 43,
      "low": 7,
      "critical": 38,
      "high": 49
    },
    "by_adr": {
      "unknown": 137
    },
    "top_violated_files": [
      {
        "file": "app/core/config.py",
        "violation_count": 10
      },
      {
        "file": "app/",
        "violation_count": 10
      },
      {
        "file": "app/main.py",
        "violation_count": 8
      },
      {
        "file": "requirements.txt",
        "violation_count": 7
      },
      {
        "file": "app/api/routes.py",
        "violation_count": 6
      },
      {
        "file": "app/api/endpoints/",
        "violation_count": 6
      },
      {
        "file": "tools/pre_audit/historical_analyzer.py",
        "violation_count": 4
      },
      {
        "file": "app/models/",
        "violation_count": 4
      },
      {
        "file": "app/core/errors.py",
        "violation_count": 4
      },
      {
        "file": "app/models/__init__.py",
        "violation_count": 3
      }
    ]
  },
  "architectural_hotspots": [
    {
      "file_path": ".pre-commit-config.yaml",
      "churn_score": 20,
      "architectural_fix_count": 2,
      "fix_types": [
        "architectural_fix",
        "dependency_fix"
      ],
      "complexity_indicators": [
        "dependency_issues"
      ],
      "risk_level": "medium",
      "recommendations": [
        "Analyze and reduce coupling",
        "Introduce dependency injection or interfaces"
      ],
      "last_fix_date": "2025-08-03T13:06:24-04:00",
      "adr_references": []
    }
  ],
  "recommendations": [
    "Address 38 critical violations immediately"
  ]
}
