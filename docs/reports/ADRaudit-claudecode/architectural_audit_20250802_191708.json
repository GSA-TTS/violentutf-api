{
  "audit_metadata": {
    "repository_path": ".",
    "adr_path": "docs/architecture/ADRs",
    "analysis_timestamp": "2025-08-02T23:17:08.721632+00:00",
    "execution_time_seconds": 5007.373224020004,
    "total_adrs_analyzed": 21
  },
  "overall_compliance_score": 42.55238095238095,
  "discovered_adrs": [
    {
      "adr_id": "ADR-011_HistoricalCodeAnalysis",
      "title": "ADR-011: Historical Code Analysis for ADR Compliance Auditing",
      "file_path": "docs/architecture/ADRs/ADR-011_HistoricalCodeAnalysis.md",
      "requirements": [
        "This decision establishes a systematic, automated approach to ADR compliance auditing that scales with the growing complexity of the ViolentUTF API architecture. The Historical Code Analysis Tool addresses critical audit team needs while maintaining security, performance, and operational requirements.",
        "2. **Configurable Detection**: YAML-based patterns adapt to evolving ADR requirements"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-007_AsyncTaskProcessing",
      "title": "ADR-007: Asynchronous Task Processing with HTTP Polling and Webhooks",
      "file_path": "docs/architecture/ADRs/ADR-007_AsyncTaskProcessing.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-004_Versioning",
      "title": "ADR-004: URI Path Versioning Strategy",
      "file_path": "docs/architecture/ADRs/ADR-004_Versioning.md",
      "requirements": [
        "Non-breaking, backward-compatible changes (e.g., adding a new optional field to a response or adding a completely new endpoint) will **not** require a new version. The current major version will simply be updated."
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-F1-3_EndpointIntegrationArchitecture",
      "title": "ADR-F1.3: Extensible Plugin Architecture for Target AI Integration",
      "file_path": "docs/architecture/ADRs/ADR-F1-3_EndpointIntegrationArchitecture.md",
      "requirements": [
        "1.  **Standard Interface**: A standardized **`ProviderPlugin` abstract interface** will be defined in the core application. This interface will specify a set of methods that every plugin must implement (e.g., `send_chat_completion`, `list_available_models`)."
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-003_RBAC+ABAC",
      "title": "ADR-003: Hybrid Authorization Model using RBAC and ABAC",
      "file_path": "docs/architecture/ADRs/ADR-003_RBAC+ABAC.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-F2-1_VulnerabilityTaxonomies",
      "title": "ADR-F2.1: Database-Driven Vulnerability Taxonomy Model",
      "file_path": "docs/architecture/ADRs/ADR-F2-1_VulnerabilityTaxonomies.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-009_ErrorandResponses",
      "title": "ADR-009: Standardized Error Handling with RFC 7807",
      "file_path": "docs/architecture/ADRs/ADR-009_ErrorandResponses.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-006_DataSerializationFormat",
      "title": "ADR-006: JSON as the Exclusive Data Serialization Format",
      "file_path": "docs/architecture/ADRs/ADR-006_DataSerializationFormat.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-010_SoftwareDependencies",
      "title": "ADR-010: Automated Dependency Management and SCA Policy",
      "file_path": "docs/architecture/ADRs/ADR-010_SoftwareDependencies.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-F1-1_TemplatingEngine",
      "title": "ADR-F1.1: Sandboxed Templating Engine for Attack Payloads",
      "file_path": "docs/architecture/ADRs/ADR-F1-1_TemplatingEngine.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-005_RateLimiting",
      "title": "ADR-005: Multi-Layered Rate Limiting and Resource Consumption Policy",
      "file_path": "docs/architecture/ADRs/ADR-005_RateLimiting.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-007_Auth_Failover",
      "title": "ADR-007: Authentication Failover Mechanisms",
      "file_path": "docs/architecture/ADRs/ADR-007_Auth_Failover.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-008_LoggingandAuditing",
      "title": "ADR-008: Structured JSON Logging for Multi-Tenant Auditing and Observability",
      "file_path": "docs/architecture/ADRs/ADR-008_LoggingandAuditing.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-F3-1_ScoringArchitecture",
      "title": "ADR-F3.1: Hybrid Scoring Architecture for Model Risk Analysis",
      "file_path": "docs/architecture/ADRs/ADR-F3-1_ScoringArchitecture.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-001_RESTstyle",
      "title": "ADR-001: Adopt REST for Standalone API Endpoints",
      "file_path": "docs/architecture/ADRs/ADR-001_RESTstyle.md",
      "requirements": [
        "The ViolentUTF API will adopt and enhance a **RESTful architectural style** for all public-facing endpoints. This decision reaffirms the existing approach but adapts it to meet the new requirements of a standalone, GSA-compliant service."
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-F1-2_ServersideOrchestration",
      "title": "ADR-F1.2: Server-Side Orchestration for Multi-Turn Attacks",
      "file_path": "docs/architecture/ADRs/ADR-F1-2_ServersideOrchestration.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-F4-1_UntrustedModelInteractions",
      "title": "ADR-F4.1: Container-based Sandboxing for Untrusted Model Execution",
      "file_path": "docs/architecture/ADRs/ADR-F4-1_UntrustedModelInteractions.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-002_Authentication",
      "title": "ADR-002: Phased Authentication Strategy using JWT and API Keys",
      "file_path": "docs/architecture/ADRs/ADR-002_Authentication.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-F2-2_DataStorage",
      "title": "ADR-F2.2: Polyglot Persistence Strategy for Session Evidence",
      "file_path": "docs/architecture/ADRs/ADR-F2-2_DataStorage.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-F4-2_SecretManagement",
      "title": "ADR-F4.2: Centralized Secrets Management for Target System Credentials",
      "file_path": "docs/architecture/ADRs/ADR-F4-2_SecretManagement.md",
      "requirements": [
        "3.  **Just-in-Time (JIT) Retrieval**: Application services (e.g., background workers) will retrieve secrets from the manager on a just-in-time basis immediately before they are needed. Secrets will only be held in memory for the minimal time required and will never be written to disk."
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    },
    {
      "adr_id": "ADR-F3-2_ReportGeneration",
      "title": "ADR-F3.2: Server-Side Engine for Automated Report Generation",
      "file_path": "docs/architecture/ADRs/ADR-F3-2_ReportGeneration.md",
      "requirements": [
        "Follow architectural decision guidelines",
        "Maintain consistency with existing patterns"
      ],
      "code_areas": [
        "app/",
        "services/",
        "api/"
      ],
      "risk_level": "medium"
    }
  ],
  "adr_compliance": {
    "ADR-011_HistoricalCodeAnalysis": {
      "adr_id": "ADR-011_HistoricalCodeAnalysis",
      "compliance_score": 87.5,
      "violations": [
        {
          "file_path": "tools/pre_audit/historical_analyzer.py",
          "line_number": 102,
          "description": "Type annotation unreachable warning with severity_weights validation - suggests defensive coding with unreachable branch after isinstance check",
          "risk_level": "low",
          "remediation_suggestion": "Remove the type: ignore[unreachable] comment or restructure the validation logic to avoid unreachable code",
          "confidence": 0.75
        },
        {
          "file_path": "tests/",
          "line_number": 0,
          "description": "Missing comprehensive unit tests for historical analyzer - No test files found for core implementation (ConventionalCommitParser, ADRPatternMatcher, ComplexityAnalyzer, HistoricalAnalyzer classes)",
          "risk_level": "high",
          "remediation_suggestion": "Implement test suite covering: test_conventional_commit_parser.py, test_adr_pattern_matcher.py, test_complexity_analyzer.py, test_historical_analyzer.py with edge cases and security validation",
          "confidence": 0.95
        },
        {
          "file_path": "tools/pre_audit/historical_analyzer.py",
          "line_number": 621,
          "description": "Path traversal protection logic is overly restrictive - rejects paths starting with '/' which are valid absolute paths",
          "risk_level": "medium",
          "remediation_suggestion": "Refine path validation logic to distinguish between malicious path traversal and legitimate absolute paths within repository bounds",
          "confidence": 0.85
        },
        {
          "file_path": "config/violation_patterns.yml",
          "line_number": 418,
          "description": "Configuration file ends abruptly without closing YAML structure - potential parsing issues",
          "risk_level": "medium",
          "remediation_suggestion": "Ensure YAML file has proper structure and validate with yaml.safe_load() test",
          "confidence": 0.8
        },
        {
          "file_path": "docs/architecture/ADRs/ADR-011_HistoricalCodeAnalysis.md",
          "line_number": 301,
          "description": "ADR specifies 'comprehensive unit test suite development' as short-term enhancement but tests are missing from current implementation",
          "risk_level": "medium",
          "remediation_suggestion": "Implement the promised comprehensive unit test suite as specified in the ADR to validate all architectural components",
          "confidence": 0.9
        }
      ],
      "compliant_areas": [
        "Core Architecture Components - All 5 components implemented: Git History Parser (PyDriller), ADR Pattern Matcher, Multi-Factor Risk Scorer, Report Generator, Security Layer",
        "Key Design Principles - Pattern-driven detection with YAML configuration, multi-layer analysis, temporal risk weighting, security-first design, performance optimization with caching",
        "Technical Implementation - Complete tool architecture with ConventionalCommitParser, ADRPatternMatcher, ComplexityAnalyzer, HistoricalAnalyzer, and ReportGenerator classes",
        "Configuration System - Robust violation_patterns.yml with 20+ ADR patterns covering Core ADRs, Feature ADRs, Security ADRs, and General patterns",
        "Risk Scoring Algorithm - Sophisticated multi-factor scoring with frequency, recency weight, severity weight, and complexity score with logarithmic normalization",
        "Security Considerations - Comprehensive input validation, path traversal protection, resource limits, secure file permissions",
        "Performance Characteristics - Benchmarked 100+ commits/second processing with caching and memory leak prevention",
        "Dependencies Integration - PyDriller and Lizard properly integrated as specified in ADR-010",
        "Report Generation - Enhanced Markdown reports with descriptive ADRaudit_ naming and comprehensive content structure",
        "CLI Interface - Complete command-line interface with security validation and comprehensive error handling"
      ],
      "recommendations": [
        "CRITICAL: Implement comprehensive unit test suite covering all core classes (ConventionalCommitParser, ADRPatternMatcher, ComplexityAnalyzer, HistoricalAnalyzer) with security validation test cases",
        "HIGH: Add integration tests that validate end-to-end functionality including Git repository analysis, pattern matching, and report generation",
        "MEDIUM: Refine path validation logic to be less restrictive while maintaining security - distinguish between malicious traversal and legitimate absolute paths",
        "MEDIUM: Validate and fix YAML configuration file structure to ensure proper parsing",
        "LOW: Remove unreachable code warnings and clean up defensive coding patterns that create dead code paths",
        "ENHANCEMENT: Add performance benchmarking tests to validate the claimed 100+ commits/second processing speed",
        "ENHANCEMENT: Implement CI/CD integration as suggested in ADR for automated compliance checking"
      ],
      "analysis_timestamp": "2025-08-02T21:53:41.350296+00:00",
      "files_analyzed": [
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/docs/architecture/ADRs/ADR-011_HistoricalCodeAnalysis.md",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/tools/pre_audit/historical_analyzer.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/config/violation_patterns.yml",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/config/ci_violation_patterns.yml",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/requirements-dev.txt",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/docs/reports/ISSUE_41_COMPLETION_REPORT.md",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/tests/"
      ],
      "analysis_summary": "ADR-011_HistoricalCodeAnalysis shows strong architectural compliance with 87.5% overall score. The implementation delivers all core requirements including Git history analysis, violation pattern matching, multi-factor risk scoring, and comprehensive reporting. Key strengths include robust security validation, performance optimization, and comprehensive configuration management. The primary gap is missing unit tests for core components, which poses maintenance and reliability risks. The architectural design follows ADR principles well with proper separation of concerns, security-first approach, and configurable pattern-based detection. Dependencies are properly managed and the tool demonstrates sophisticated functionality with advanced features like temporal risk weighting and logarithmic score normalization."
    },
    "ADR-007_AsyncTaskProcessing": {
      "adr_id": "ADR-007_AsyncTaskProcessing",
      "compliance_score": 15.0,
      "violations": [
        {
          "file_path": "requirements.txt",
          "line_number": 1,
          "description": "Missing task queue system dependencies: No Celery, RQ, or other task queue libraries found in requirements.txt. ADR mandates 'Task Queue system (e.g., Celery) with a message broker (e.g., Redis)'",
          "risk_level": "critical",
          "remediation_suggestion": "Add celery>=5.3.0 and celery[redis]>=5.3.0 to requirements.txt",
          "confidence": 0.98
        },
        {
          "file_path": "app/api/routes.py",
          "line_number": 21,
          "description": "No async task endpoints implemented: ADR requires '/api/v1/scans' endpoint that returns 202 Accepted with task_id and status_url, but no such endpoints exist",
          "risk_level": "critical",
          "remediation_suggestion": "Implement scan endpoints with 202 Accepted responses containing task_id and status_url fields",
          "confidence": 0.95
        },
        {
          "file_path": "app/models/",
          "line_number": 1,
          "description": "Missing Task model: No database model for tracking async tasks with PENDING/RUNNING/SUCCESS states as required by ADR implementation details",
          "risk_level": "high",
          "remediation_suggestion": "Create Task model with fields: task_id (UUID), status (PENDING/RUNNING/SUCCESS/FAILED), result_url, webhook_url, created_at, updated_at",
          "confidence": 0.92
        },
        {
          "file_path": "app/core/config.py",
          "line_number": 63,
          "description": "Incomplete task queue configuration: Redis URL is present but missing Celery broker configuration, worker settings, and task routing configuration",
          "risk_level": "high",
          "remediation_suggestion": "Add CELERY_BROKER_URL, CELERY_RESULT_BACKEND, task routing, and worker configuration settings",
          "confidence": 0.89
        },
        {
          "file_path": "app/api/endpoints/",
          "line_number": 1,
          "description": "Missing status polling endpoints: ADR requires 'GET /api/v1/tasks/{task_id}' endpoint for status checking, but no task status endpoints implemented",
          "risk_level": "high",
          "remediation_suggestion": "Implement GET /api/v1/tasks/{task_id} endpoint returning task status and result_url when complete",
          "confidence": 0.94
        },
        {
          "file_path": "app/services/",
          "line_number": 1,
          "description": "No worker processes implementation: ADR mandates 'separate processes that pull jobs from the queue, execute the long-running task', but no Celery workers or task services found",
          "risk_level": "critical",
          "remediation_suggestion": "Create Celery worker service with tasks for PyRIT orchestrator and Garak scan execution",
          "confidence": 0.96
        },
        {
          "file_path": "app/main.py",
          "line_number": 1,
          "description": "Missing webhook support: ADR requires webhook callback functionality with signature verification, but no webhook handling middleware or services implemented",
          "risk_level": "medium",
          "remediation_suggestion": "Add webhook service with HMAC signature verification and callback POST functionality",
          "confidence": 0.87
        },
        {
          "file_path": "alembic/versions/",
          "line_number": 1,
          "description": "No task-related database migrations: Database schema lacks tables for task tracking, status management, and result storage as specified in ADR",
          "risk_level": "high",
          "remediation_suggestion": "Create migration for tasks table with proper indexing on status and created_at fields",
          "confidence": 0.91
        }
      ],
      "compliant_areas": [
        "FastAPI framework properly configured for async operations",
        "Redis configuration present in settings (partial infrastructure)",
        "Proper HTTP status code handling framework in place",
        "Database connection and session management implemented",
        "Request validation and security middleware properly configured"
      ],
      "recommendations": [
        "Implement complete Celery-based task queue system with Redis broker",
        "Create comprehensive Task model with proper state management (PENDING→RUNNING→SUCCESS/FAILED)",
        "Develop scan initiation endpoints that return 202 Accepted with proper task tracking",
        "Add task status polling endpoints with proper caching",
        "Implement webhook callback system with HMAC signature verification",
        "Create worker processes for PyRIT orchestrator and Garak scan execution",
        "Add proper task result storage and retrieval mechanisms",
        "Implement task timeout and failure handling as per ADR requirements"
      ],
      "analysis_timestamp": "2025-08-02T21:55:03.119113+00:00",
      "files_analyzed": [
        "docs/architecture/ADRs/ADR-007_AsyncTaskProcessing.md",
        "app/api/routes.py",
        "app/main.py",
        "app/core/config.py",
        "requirements.txt",
        "app/api/endpoints/upload.py",
        "app/api/endpoints/health.py",
        "app/models/audit_log.py",
        "alembic/versions/0d9d1d5fbe10_initial_database_models_with_.py"
      ],
      "analysis_summary": "The ViolentUTF API currently implements only basic CRUD operations and authentication but completely lacks the async task processing architecture mandated by ADR-007. Critical violations include missing task queue infrastructure (Celery), no async endpoint implementations, absence of task tracking models, and no worker processes. The 15% compliance score reflects only the presence of foundational components (FastAPI, Redis config) that could support the required architecture but are not currently utilized for async task processing."
    },
    "ADR-004_Versioning": {
      "adr_id": "ADR-004_Versioning",
      "compliance_score": 75.0,
      "violations": [
        {
          "file_path": "app/main.py",
          "line_number": 216,
          "description": "Router is included with API_V1_STR prefix but there is no provision for multiple API versions or deprecation headers implementation",
          "risk_level": "medium",
          "remediation_suggestion": "Implement version-specific router organization with separate v1/ and v2/ directory structure and add deprecation header middleware",
          "confidence": 0.95
        },
        {
          "file_path": "app/core/config.py",
          "line_number": 31,
          "description": "API_V1_STR is hardcoded as static string '/api/v1' with no configuration for other versions or deprecation policies",
          "risk_level": "medium",
          "remediation_suggestion": "Add configuration settings for API_V2_STR, deprecation policy settings, and version management flags",
          "confidence": 0.9
        },
        {
          "file_path": "app/api/routes.py",
          "line_number": 21,
          "description": "Single api_router with no version-specific routing structure - all endpoints are mixed in one router without version separation",
          "risk_level": "high",
          "remediation_suggestion": "Refactor to use version-specific routers (e.g., v1_router, v2_router) and implement clean architecture separation",
          "confidence": 0.95
        },
        {
          "file_path": "app/main.py",
          "line_number": 146,
          "description": "OpenAPI documentation URL uses API_V1_STR but there's no provision for version-specific documentation generation",
          "risk_level": "medium",
          "remediation_suggestion": "Implement version-specific OpenAPI documentation generation with separate docs for each API version",
          "confidence": 0.85
        },
        {
          "file_path": "app/api/endpoints/",
          "line_number": 1,
          "description": "No implementation of deprecation headers (Deprecation, Warning) in endpoint responses as specified in the ADR",
          "risk_level": "high",
          "remediation_suggestion": "Add middleware to automatically inject Deprecation and Warning headers for deprecated API versions based on configuration",
          "confidence": 0.95
        },
        {
          "file_path": "app/main.py",
          "line_number": 1,
          "description": "Missing implementation of 6-month deprecation policy enforcement and sunset date tracking",
          "risk_level": "high",
          "remediation_suggestion": "Implement deprecation policy middleware with configurable sunset dates and automatic header injection",
          "confidence": 0.9
        }
      ],
      "compliant_areas": [
        "URI path versioning strategy is correctly implemented with /api/v1 prefix structure",
        "FastAPI application uses API_V1_STR configuration for consistent versioning",
        "Audit middleware correctly handles version extraction from path (supports v1, v2)",
        "Tests consistently use /api/v1 prefix in endpoint testing",
        "OpenAPI documentation correctly uses versioned URL structure"
      ],
      "recommendations": [
        "Create separate router modules for each API version (app/api/v1/, app/api/v2/)",
        "Implement deprecation middleware to automatically add required headers (Deprecation, Warning) with sunset dates",
        "Add configuration settings for managing multiple API versions and deprecation policies",
        "Create version-specific OpenAPI documentation generation",
        "Implement breaking change detection and validation in CI/CD pipeline",
        "Add API version negotiation logic and backward compatibility testing",
        "Create documentation templates for version migration guides"
      ],
      "analysis_timestamp": "2025-08-02T21:57:06.268144+00:00",
      "files_analyzed": [
        "docs/architecture/ADRs/ADR-004_Versioning.md",
        "app/main.py",
        "app/api/routes.py",
        "app/core/config.py",
        "app/api/endpoints/users.py",
        "app/api/endpoints/health.py",
        "app/middleware/audit.py"
      ],
      "analysis_summary": "The ViolentUTF API partially implements ADR-004 URI path versioning strategy. While the basic v1 prefix structure is correctly implemented, critical components are missing: deprecation policy enforcement, version-specific router organization, deprecation headers, and support for concurrent API versions. The current implementation supports the technical foundation but lacks the operational aspects required for production version management."
    },
    "ADR-F1-3_EndpointIntegrationArchitecture": {
      "adr_id": "ADR-F1-3_EndpointIntegrationArchitecture",
      "compliance_score": 15.0,
      "violations": [
        {
          "file_path": "N/A - Missing Implementation",
          "line_number": 0,
          "description": "Critical ADR Violation: ProviderPlugin abstract interface is completely missing. ADR requires 'A standardized ProviderPlugin abstract interface will be defined in the core application' with methods send_chat_completion, list_available_models, and validate_credentials.",
          "risk_level": "critical",
          "remediation_suggestion": "Create app/core/provider_plugin.py with the ProviderPlugin ABC class as specified in ADR lines 85-116",
          "confidence": 1.0
        },
        {
          "file_path": "N/A - Missing Implementation",
          "line_number": 0,
          "description": "Critical ADR Violation: Plugin directory violentutf_api/plugins/ does not exist. ADR specifies 'The application will discover plugins at startup by scanning a dedicated violentutf_api/plugins/ directory'",
          "risk_level": "critical",
          "remediation_suggestion": "Create violentutf_api/plugins/ directory structure and implement plugin discovery mechanism",
          "confidence": 1.0
        },
        {
          "file_path": "N/A - Missing Implementation",
          "line_number": 0,
          "description": "Critical ADR Violation: Generator database model is missing. ADR requires Generator schema with fields: name, plugin_name, model_id, credentials_id (lines 122-130)",
          "risk_level": "critical",
          "remediation_suggestion": "Create app/models/generator.py with required fields and add to database schema",
          "confidence": 1.0
        },
        {
          "file_path": "N/A - Missing Implementation",
          "line_number": 0,
          "description": "Critical ADR Violation: No plugin discovery and registration mechanism exists. ADR requires dynamic loading of plugins at startup",
          "risk_level": "critical",
          "remediation_suggestion": "Implement plugin discovery in app/core/startup.py to scan and register plugins automatically",
          "confidence": 1.0
        },
        {
          "file_path": "app/core/startup.py",
          "line_number": 13,
          "description": "High ADR Violation: Startup handler missing plugin initialization. ADR implementation requires plugin discovery during application startup",
          "risk_level": "high",
          "remediation_suggestion": "Add plugin discovery and registration logic to on_startup() function",
          "confidence": 0.9
        },
        {
          "file_path": "app/models/__init__.py",
          "line_number": 12,
          "description": "High ADR Violation: Generator model not imported/exported in models package",
          "risk_level": "high",
          "remediation_suggestion": "Add Generator to __all__ list after implementing the model",
          "confidence": 0.9
        },
        {
          "file_path": "app/core/external_services.py",
          "line_number": 38,
          "description": "Medium ADR Violation: AI_MODEL service type exists but is not integrated with ProviderPlugin architecture. This represents partial implementation without proper abstraction",
          "risk_level": "medium",
          "remediation_suggestion": "Integrate AI_MODEL service type with ProviderPlugin architecture when implementing the plugin system",
          "confidence": 0.8
        }
      ],
      "compliant_areas": [
        "External service infrastructure exists with circuit breaker pattern (app/core/external_services.py)",
        "Service registry pattern partially implemented for external services",
        "AI_MODEL service type defined in ServiceType enum, showing awareness of AI integrations",
        "Async/await patterns used consistently for external service calls",
        "Error handling and monitoring infrastructure present"
      ],
      "recommendations": [
        "IMMEDIATE: Implement ProviderPlugin abstract base class with required methods (send_chat_completion, list_available_models, validate_credentials)",
        "IMMEDIATE: Create violentutf_api/plugins/ directory structure and plugin discovery mechanism",
        "IMMEDIATE: Implement Generator database model with required fields (name, plugin_name, model_id, credentials_id)",
        "HIGH: Add plugin registration system to application startup process",
        "HIGH: Create database migration for Generator table schema",
        "MEDIUM: Integrate existing ExternalServiceClient with ProviderPlugin architecture",
        "MEDIUM: Implement concrete plugin examples (OpenAI, Anthropic, Ollama) to validate architecture",
        "LOW: Add plugin management endpoints for CRUD operations on Generator configurations"
      ],
      "analysis_timestamp": "2025-08-02T21:58:28.522952+00:00",
      "files_analyzed": [
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/docs/architecture/ADRs/ADR-F1-3_EndpointIntegrationArchitecture.md",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/main.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/api/routes.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/external_services.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/models/__init__.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/startup.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/pyproject.toml"
      ],
      "analysis_summary": "ADR-F1-3 is in severe non-compliance with only 15% implementation. The core plugin architecture is completely missing - no ProviderPlugin interface, no plugin directory, no Generator model, and no plugin discovery mechanism. While basic external service infrastructure exists, it is not integrated with the required plugin pattern. This represents a fundamental architectural gap that must be addressed immediately to meet ADR requirements."
    },
    "ADR-003_RBAC+ABAC": {
      "adr_id": "ADR-003_RBAC+ABAC",
      "compliance_score": 65.2,
      "violations": [
        {
          "file_path": "app/api/endpoints/users.py",
          "line_number": 53,
          "description": "Admin permission check uses only `is_superuser` flag instead of proper RBAC role-based checks. ADR-003 requires admin role validation, not just superuser flag.",
          "risk_level": "high",
          "remediation_suggestion": "Replace `is_superuser` check with proper RBAC role validation using `require_permissions(['admin'])` decorator",
          "confidence": 0.92
        },
        {
          "file_path": "app/models/user.py",
          "line_number": 90,
          "description": "User model stores roles as JSON array directly instead of using proper RBAC UserRole relationship. This bypasses the formal role management system.",
          "risk_level": "high",
          "remediation_suggestion": "Remove direct `roles` field and use only the UserRole relationship table for proper RBAC implementation",
          "confidence": 0.95
        },
        {
          "file_path": "app/middleware/permissions.py",
          "line_number": 63,
          "description": "Permission middleware attempts to extract user roles from token but doesn't enforce organization_id filtering for ABAC. Missing the critical ABAC layer.",
          "risk_level": "critical",
          "remediation_suggestion": "Add organization_id filtering to all data access queries as specified in ADR-003 lines 113-126",
          "confidence": 0.98
        },
        {
          "file_path": "app/repositories/base.py",
          "line_number": 56,
          "description": "Base repository lacks organization_id filtering in queries. ADR-003 requires all tenant-owned resources to be filtered by organization_id automatically.",
          "risk_level": "critical",
          "remediation_suggestion": "Implement automatic organization_id filtering in base repository get/list methods as shown in ADR-003 pseudocode",
          "confidence": 0.96
        },
        {
          "file_path": "app/core/permissions.py",
          "line_number": 17,
          "description": "Permission decorators implement RBAC but lack ABAC integration. No automatic organization_id checks are performed on resources.",
          "risk_level": "high",
          "remediation_suggestion": "Enhance permission decorators to include ABAC checks by validating resource ownership via organization_id",
          "confidence": 0.91
        },
        {
          "file_path": "app/api/endpoints/users.py",
          "line_number": 129,
          "description": "List users endpoint lacks organization_id filtering, allowing users to see other organizations' data.",
          "risk_level": "critical",
          "remediation_suggestion": "Add organization_id filtering to user listing queries to enforce multi-tenant data isolation",
          "confidence": 0.97
        }
      ],
      "compliant_areas": [
        "JWT tokens correctly include 'sub', 'roles', and 'organization_id' claims as specified in ADR-003",
        "User model has organization_id field in BaseModelMixin (RowLevelSecurityMixin)",
        "RBAC service correctly implements role-based permission checking",
        "Authentication middleware properly extracts and validates JWT claims",
        "Database schema includes organization_id columns via RowLevelSecurityMixin",
        "Initial role definitions match ADR-003 specification (viewer, tester, admin)"
      ],
      "recommendations": [
        "Implement automatic organization_id filtering at the repository level for all data access operations",
        "Create FastAPI dependencies that combine RBAC and ABAC checks as specified in ADR-003",
        "Remove direct roles field from User model and use only the formal UserRole relationship",
        "Add comprehensive unit tests for both positive and negative authorization cases as required by ADR-003",
        "Implement the hybrid dependency pattern: `@app.post('/endpoint', dependencies=[Depends(require_role('tester'))])`",
        "Create reusable ABAC dependency that automatically filters queries by current user's organization_id",
        "Review all API endpoints to ensure both RBAC function-level and ABAC object-level authorization"
      ],
      "analysis_timestamp": "2025-08-02T22:00:44.153930+00:00",
      "files_analyzed": [
        "docs/architecture/ADRs/ADR-003_RBAC+ABAC.md",
        "app/core/auth.py",
        "app/core/permissions.py",
        "app/services/rbac_service.py",
        "app/middleware/permissions.py",
        "app/models/user.py",
        "app/models/mixins.py",
        "app/api/endpoints/users.py",
        "app/api/endpoints/auth.py",
        "app/middleware/authentication.py",
        "app/repositories/base.py"
      ],
      "analysis_summary": "The codebase has implemented the RBAC layer of ADR-003 hybrid authorization model but is missing critical ABAC implementation. While JWT tokens contain the required claims and RBAC service exists, the essential organization_id filtering for multi-tenant data isolation is not implemented. This creates a significant security vulnerability where users could potentially access data from other organizations. The authentication layer is well-implemented but authorization enforcement at the data access level is incomplete."
    },
    "ADR-F2-1_VulnerabilityTaxonomies": {
      "adr_id": "ADR-F2-1_VulnerabilityTaxonomies",
      "compliance_score": 15.0,
      "violations": [
        {
          "file_path": "app/models/__init__.py",
          "line_number": 13,
          "description": "Missing VulnerabilityTaxonomy and TaxonomyMapping models in the models package. ADR requires two database tables: vulnerability_taxonomies and taxonomy_mappings, but no corresponding SQLAlchemy models exist.",
          "risk_level": "critical",
          "remediation_suggestion": "Create VulnerabilityTaxonomy and TaxonomyMapping SQLAlchemy models with the schema specified in ADR lines 70-83",
          "confidence": 0.98
        },
        {
          "file_path": "app/db/base.py",
          "line_number": 11,
          "description": "No import statements for vulnerability taxonomy models. The base.py file imports all models for Alembic discovery but is missing the required taxonomy models.",
          "risk_level": "critical",
          "remediation_suggestion": "Add imports for VulnerabilityTaxonomy and TaxonomyMapping models once they are created",
          "confidence": 0.97
        },
        {
          "file_path": "alembic/versions/",
          "line_number": 1,
          "description": "No database migration files exist for vulnerability_taxonomies and taxonomy_mappings tables. ADR requires specific database schema with UUID primary keys, hierarchical parent_id relationships, and framework mapping tables.",
          "risk_level": "critical",
          "remediation_suggestion": "Create Alembic migration to add vulnerability_taxonomies table with columns: id (UUID), name (String), description (Text), remediation_advice (Text), parent_id (UUID FK), default_severity (Enum), and taxonomy_mappings table with framework mapping fields",
          "confidence": 0.99
        },
        {
          "file_path": "app/api/routes.py",
          "line_number": 120,
          "description": "No API endpoints for vulnerability taxonomy management. ADR implies need for CRUD operations on taxonomy data, but no endpoints exist in the API router.",
          "risk_level": "high",
          "remediation_suggestion": "Create API endpoints for vulnerability taxonomy management including GET /taxonomies, POST /taxonomies, PUT /taxonomies/{id}, DELETE /taxonomies/{id}",
          "confidence": 0.85
        },
        {
          "file_path": "app/schemas/",
          "line_number": 1,
          "description": "Missing Pydantic schemas for vulnerability taxonomy data validation. No schemas exist for VulnerabilityTaxonomy or TaxonomyMapping request/response models.",
          "risk_level": "high",
          "remediation_suggestion": "Create Pydantic schemas: VulnerabilityTaxonomyCreate, VulnerabilityTaxonomyUpdate, VulnerabilityTaxonomyResponse, TaxonomyMappingCreate, TaxonomyMappingResponse",
          "confidence": 0.92
        },
        {
          "file_path": "app/services/",
          "line_number": 1,
          "description": "No service layer implementation for vulnerability taxonomy business logic. No service exists to handle taxonomy operations, hierarchy management, or framework mapping.",
          "risk_level": "high",
          "remediation_suggestion": "Create VulnerabilityTaxonomyService with methods for: creating taxonomies, managing hierarchical relationships, mapping to external frameworks (OWASP, MITRE), and validating taxonomy data",
          "confidence": 0.88
        },
        {
          "file_path": "app/repositories/",
          "line_number": 1,
          "description": "Missing repository layer for vulnerability taxonomy data access. No repository pattern implementation for database operations on taxonomy data.",
          "risk_level": "medium",
          "remediation_suggestion": "Create VulnerabilityTaxonomyRepository and TaxonomyMappingRepository classes with methods for CRUD operations, hierarchy queries, and framework mapping lookups",
          "confidence": 0.85
        },
        {
          "file_path": "docs/architecture/ADRs/ADR-F2-2_DataStorage.md",
          "line_number": 89,
          "description": "ADR-F2-2 references vulnerability_taxonomies table in PostgreSQL implementation but table doesn't exist. This creates inconsistency between related ADRs.",
          "risk_level": "medium",
          "remediation_suggestion": "Ensure vulnerability_taxonomies table implementation aligns with both ADR-F2-1 and ADR-F2-2 requirements",
          "confidence": 0.9
        },
        {
          "file_path": "app/",
          "line_number": 1,
          "description": "No initial data seeding implementation for OWASP LLM Top 10. ADR line 85-86 requires seeding the vulnerability_taxonomies table with OWASP definitions upon deployment.",
          "risk_level": "medium",
          "remediation_suggestion": "Create data seeding script or migration to populate vulnerability_taxonomies with OWASP LLM Top 10 classifications including hierarchy and framework mappings",
          "confidence": 0.87
        }
      ],
      "compliant_areas": [
        "Database infrastructure (PostgreSQL) is properly configured to support the required relational taxonomy storage",
        "Alembic migration system is in place to support adding the required database schema",
        "SQLAlchemy ORM framework is properly configured to support the hierarchical data model requirements"
      ],
      "recommendations": [
        "CRITICAL: Implement the complete database schema with VulnerabilityTaxonomy and TaxonomyMapping models as specified in ADR lines 70-83",
        "CRITICAL: Create Alembic migration to establish the vulnerability_taxonomies and taxonomy_mappings tables with proper indexes and constraints",
        "HIGH: Develop comprehensive API layer with CRUD endpoints for taxonomy management following the existing patterns in the codebase",
        "HIGH: Implement service layer with business logic for hierarchy management and framework mapping operations",
        "MEDIUM: Create data seeding mechanism to populate initial OWASP LLM Top 10 taxonomy entries",
        "MEDIUM: Add comprehensive test coverage for all taxonomy-related functionality following the existing test patterns",
        "LOW: Consider adding caching layer for frequently accessed taxonomy data to improve performance"
      ],
      "analysis_timestamp": "2025-08-02T22:02:38.611269+00:00",
      "files_analyzed": [
        "docs/architecture/ADRs/ADR-F2-1_VulnerabilityTaxonomies.md",
        "docs/architecture/ADRs/ADR-F2-2_DataStorage.md",
        "docs/architecture/ADRs/ADR-F3-1_ScoringArchitecture.md",
        "app/models/__init__.py",
        "app/db/base.py",
        "app/api/routes.py",
        "alembic/versions/0d9d1d5fbe10_initial_database_models_with_.py",
        "alembic/versions/41eb10f48a60_add_last_login_at_and_last_login_ip_.py",
        "alembic/versions/add_roles_field_rbac.py",
        "app/models/session.py",
        "app/models/audit_log.py"
      ],
      "analysis_summary": "ADR-F2-1_VulnerabilityTaxonomies is severely non-compliant with a 15% compliance score. The ADR requires a complete database-driven vulnerability taxonomy system with hierarchical structure and framework mapping capabilities, but the current implementation has NONE of the required components. Critical missing elements include: database models, migration files, API endpoints, service layer, and data seeding. The only compliant aspects are the foundational database infrastructure components that could support the required implementation."
    },
    "ADR-009_ErrorandResponses": {
      "adr_id": "ADR-009_ErrorandResponses",
      "compliance_score": 25.0,
      "violations": [
        {
          "file_path": "app/core/errors.py",
          "line_number": 15,
          "description": "ErrorDetail model does not follow RFC 7807 standard - missing required fields: type, title, status, detail, instance. Current implementation uses non-standard fields: error, message, request_id, path, timestamp",
          "risk_level": "critical",
          "remediation_suggestion": "Replace ErrorDetail model with RFC 7807 compliant ProblemDetail model containing type, title, status, detail, instance fields",
          "confidence": 0.95
        },
        {
          "file_path": "app/core/errors.py",
          "line_number": 132,
          "description": "api_error_handler returns non-standard error format instead of RFC 7807 application/problem+json format",
          "risk_level": "critical",
          "remediation_suggestion": "Update handler to return Content-Type: application/problem+json with RFC 7807 compliant structure",
          "confidence": 0.95
        },
        {
          "file_path": "app/core/errors.py",
          "line_number": 160,
          "description": "validation_error_handler does not conform to RFC 7807 - missing type URI, status, title fields and uses non-standard structure",
          "risk_level": "critical",
          "remediation_suggestion": "Implement RFC 7807 validation error format with type URI pointing to validation error documentation",
          "confidence": 0.95
        },
        {
          "file_path": "app/core/errors.py",
          "line_number": 199,
          "description": "generic_error_handler lacks RFC 7807 compliance - missing type URI, proper status field, and application/problem+json content type",
          "risk_level": "critical",
          "remediation_suggestion": "Implement RFC 7807 compliant generic error handler with proper content type and structure",
          "confidence": 0.95
        },
        {
          "file_path": "app/schemas/base.py",
          "line_number": 182,
          "description": "APIErrorResponse schema exists but is not used in actual error handlers. It follows RFC 7807 but lacks correlation_id and error_code as required by ADR",
          "risk_level": "high",
          "remediation_suggestion": "Update APIErrorResponse to include correlation_id and error_code fields, then integrate with error handlers",
          "confidence": 0.9
        },
        {
          "file_path": "app/schemas/common.py",
          "line_number": 11,
          "description": "ErrorResponse schema uses non-standard format (error, detail, request_id, timestamp) instead of RFC 7807 fields",
          "risk_level": "high",
          "remediation_suggestion": "Replace with RFC 7807 compliant schema or deprecate in favor of APIErrorResponse",
          "confidence": 0.9
        },
        {
          "file_path": "app/main.py",
          "line_number": 40,
          "description": "rate_limit_handler returns non-RFC 7807 compliant error format with type field but missing other required RFC 7807 fields",
          "risk_level": "medium",
          "remediation_suggestion": "Update rate limit handler to use centralized RFC 7807 error response format",
          "confidence": 0.85
        },
        {
          "file_path": "Missing Implementation",
          "line_number": 0,
          "description": "No centralized Error Dictionary found as specified in ADR - should map error codes to RFC 7807 type URIs, titles, and status codes",
          "risk_level": "critical",
          "remediation_suggestion": "Create centralized error dictionary mapping error codes (VUTF-XXXX) to RFC 7807 compliant error definitions",
          "confidence": 0.95
        },
        {
          "file_path": "Missing Implementation",
          "line_number": 0,
          "description": "No correlation_id implementation found - ADR requires linking errors to structured logs via correlation_id from ADR-008",
          "risk_level": "high",
          "remediation_suggestion": "Implement correlation_id extraction from request state and include in all error responses",
          "confidence": 0.9
        },
        {
          "file_path": "Missing Implementation",
          "line_number": 0,
          "description": "No error_code field implementation found - ADR requires stable error codes like VUTF-1001 for programmatic error handling",
          "risk_level": "high",
          "remediation_suggestion": "Add error_code field to all error responses using VUTF-XXXX format",
          "confidence": 0.9
        }
      ],
      "compliant_areas": [
        "Global exception handling mechanism exists via setup_error_handlers function",
        "Centralized error handling implemented in app/core/errors.py",
        "No stack traces exposed in production mode (line 212-215 in errors.py)",
        "Basic error logging implemented with structured logging",
        "APIErrorResponse schema in base.py follows RFC 7807 structure (unused)"
      ],
      "recommendations": [
        "Implement complete RFC 7807 compliance by updating all error handlers to return application/problem+json content type",
        "Create centralized error dictionary mapping VUTF error codes to RFC 7807 problem details",
        "Integrate correlation_id from request state into all error responses for traceability",
        "Add error_code field with VUTF-XXXX format to enable programmatic error handling",
        "Update Content-Type headers to application/problem+json for all error responses",
        "Replace existing ErrorDetail and ErrorResponse schemas with RFC 7807 compliant versions",
        "Implement type URIs that link to error documentation (e.g., https://api.violentutf.gsa.gov/errors/validation-error)",
        "Update all custom exception handlers to use the centralized RFC 7807 error format",
        "Add invalid_params extension for validation errors as shown in ADR example",
        "Ensure all error responses include required RFC 7807 fields: type, title, status, detail, instance"
      ],
      "analysis_timestamp": "2025-08-02T22:04:20.382269+00:00",
      "files_analyzed": [
        "docs/architecture/ADRs/ADR-009_ErrorandResponses.md",
        "app/main.py",
        "app/core/errors.py",
        "tests/unit/test_errors.py",
        "app/schemas/base.py",
        "app/schemas/common.py",
        "app/api/endpoints/auth.py"
      ],
      "analysis_summary": "The ViolentUTF API has only basic compliance with ADR-009. While centralized error handling exists, the implementation uses custom error formats instead of RFC 7807 standard. Critical missing components include RFC 7807 compliant response format, correlation_id integration, error_code implementation, and the centralized error dictionary. The existing APIErrorResponse schema follows RFC 7807 but is not actually used in error handlers."
    },
    "ADR-006_DataSerializationFormat": {
      "adr_id": "ADR-006_DataSerializationFormat",
      "compliance_score": 92.0,
      "violations": [
        {
          "file_path": "app/api/endpoints/audit_logs.py",
          "line_number": 159,
          "description": "Export endpoint supports CSV format (text/csv) in addition to JSON, violating the 'exclusive JSON' requirement. The endpoint allows users to export audit logs in CSV format which is not the mandated application/json media type.",
          "risk_level": "medium",
          "remediation_suggestion": "Remove CSV export functionality or document this as an approved exception for data export purposes. Consider implementing JSON-only export with CSV generation on the client side.",
          "confidence": 0.95
        },
        {
          "file_path": "tests/integration/test_security_middleware_chain.py",
          "line_number": 45,
          "description": "Test cases include XML content types (application/xml, text/xml) which suggests the API may accept non-JSON formats during testing, potentially indicating insufficient content-type validation.",
          "risk_level": "low",
          "remediation_suggestion": "Ensure these test cases are specifically for rejection scenarios and that the middleware properly rejects non-JSON content types.",
          "confidence": 0.8
        }
      ],
      "compliant_areas": [
        "All FastAPI endpoints properly configured with Pydantic models for JSON serialization",
        "Main application configured with JSONResponse as default response type",
        "All API schemas inherit from BaseSchema with proper JSON-compatible field definitions",
        "OpenAPI specification generation uses application/json as default media type",
        "Error handling framework consistently returns JSONResponse objects",
        "All CRUD operations use BaseResponse[T] pattern ensuring JSON serialization",
        "Request/response models properly configured with Pydantic for clean JSON serialization",
        "No XML, Protobuf, or other serialization formats found in production endpoints",
        "FastAPI automatic OpenAPI generation exclusively defines application/json media types"
      ],
      "recommendations": [
        "Remove CSV export functionality from audit logs endpoint to achieve full ADR compliance",
        "Add explicit content-type validation middleware to reject non-JSON requests",
        "Document the audit log export exception if CSV export is business-critical",
        "Consider implementing a JSON-based export format with client-side CSV conversion",
        "Add OpenAPI documentation explicitly stating application/json as the only supported media type",
        "Implement runtime validation to ensure all responses use application/json content-type"
      ],
      "analysis_timestamp": "2025-08-02T22:05:52.130629+00:00",
      "files_analyzed": [
        "app/main.py",
        "app/api/routes.py",
        "app/api/base.py",
        "app/schemas/base.py",
        "app/schemas/user.py",
        "app/api/endpoints/users.py",
        "app/api/endpoints/audit_logs.py",
        "app/core/config.py",
        "app/core/errors.py",
        "pyproject.toml"
      ],
      "analysis_summary": "The ViolentUTF API demonstrates strong compliance with ADR-006's JSON-exclusive serialization requirements. The architecture correctly uses FastAPI with Pydantic models, ensuring clean JSON serialization throughout the application. All endpoints properly define response_model parameters using Pydantic schemas that serialize to JSON. The main violation is a single audit log export endpoint that offers CSV format alongside JSON, representing 8% non-compliance. The codebase shows excellent architectural patterns with BaseResponse wrappers, comprehensive error handling via JSONResponse, and proper OpenAPI integration. The compliance score reflects the overall adherence to JSON-only serialization with minor deviations for data export functionality."
    },
    "ADR-010_SoftwareDependencies": {
      "adr_id": "ADR-010_SoftwareDependencies",
      "compliance_score": 72.5,
      "violations": [
        {
          "file_path": ".github/workflows/pr-validation.yml",
          "line_number": 62,
          "description": "pip-audit is missing from CI/CD pipeline as a blocking step. ADR requires pip-audit to block PR merges on CRITICAL/HIGH vulnerabilities, but workflow only uses 'safety check' which doesn't match ADR specifications",
          "risk_level": "critical",
          "remediation_suggestion": "Add pip-audit as a mandatory blocking step in PR validation with --fail-on-high flag",
          "confidence": 0.95
        },
        {
          "file_path": ".github/workflows/ci.yml",
          "line_number": null,
          "description": "CI pipeline lacks pip-audit integration completely. ADR mandates pip-audit as blocking CI step but it's absent from quick CI checks",
          "risk_level": "high",
          "remediation_suggestion": "Add pip-audit step to ci.yml workflow with appropriate failure conditions",
          "confidence": 0.9
        },
        {
          "file_path": "security/pip-audit-report.json",
          "line_number": 1,
          "description": "Current pip-audit scan shows 15 HIGH/CRITICAL vulnerabilities (aiohttp, mcp, pillow, protobuf, requests, starlette, torch, tornado, transformers, urllib3) but no blocking mechanism prevents deployment",
          "risk_level": "critical",
          "remediation_suggestion": "Fix identified vulnerabilities and implement automated blocking for CRITICAL/HIGH severity issues",
          "confidence": 0.98
        },
        {
          "file_path": "scripts/security-scan.sh",
          "line_number": 17,
          "description": "Safety check allows failures with '|| true' pattern, violating ADR's requirement for blocking security scans",
          "risk_level": "medium",
          "remediation_suggestion": "Remove '|| true' pattern and implement proper failure handling for safety check",
          "confidence": 0.85
        },
        {
          "file_path": ".github/workflows/security.yml",
          "line_number": 40,
          "description": "Security workflow uses 'safety check' instead of pip-audit for dependency scanning, not matching ADR tooling requirements",
          "risk_level": "medium",
          "remediation_suggestion": "Replace or supplement safety with pip-audit in security workflow",
          "confidence": 0.8
        }
      ],
      "compliant_areas": [
        "Dependabot configuration is properly implemented with weekly schedules and grouped updates",
        "Security scanning tools (bandit, safety, detect-secrets) are integrated in development workflow",
        "Pre-commit hooks include comprehensive security scanning with bandit",
        "Requirements files are properly maintained with version pinning",
        "Approved open-source license policy is documented (MIT, Apache-2.0, BSD licenses)",
        "Security reports directory structure is established",
        "Development dependencies include pip-audit in requirements-dev.txt"
      ],
      "recommendations": [
        "Implement pip-audit as mandatory blocking step in PR validation workflow with --fail-on-high flag",
        "Add pip-audit to CI pipeline with proper exit codes for CRITICAL/HIGH vulnerabilities",
        "Remediate 15 identified HIGH/CRITICAL vulnerabilities in current dependencies",
        "Remove '|| true' failure masking patterns from security scan scripts",
        "Establish SLA monitoring for vulnerability remediation timelines (7 days CRITICAL, 30 days HIGH)",
        "Implement license compliance scanning beyond just vulnerability detection",
        "Add semgrep integration to CI/CD pipeline as specified in ADR",
        "Create automated reports for compliance dashboard showing ADR adherence metrics"
      ],
      "analysis_timestamp": "2025-08-02T22:07:19.018597+00:00",
      "files_analyzed": [
        "docs/architecture/ADRs/ADR-010_SoftwareDependencies.md",
        ".github/dependabot.yml",
        ".github/workflows/security.yml",
        ".github/workflows/security-ci-validation.yml",
        ".github/workflows/pr-validation.yml",
        ".github/workflows/ci.yml",
        "requirements.txt",
        "requirements-dev.txt",
        "pyproject.toml",
        "security/pip-audit-report.json",
        "security/bandit-report.json",
        "scripts/security-scan.sh",
        "check_security.sh",
        ".pre-commit-config.yaml"
      ],
      "analysis_summary": "The codebase demonstrates partial compliance with ADR-010 SoftwareDependencies. While Dependabot, security scanning tools, and development practices are well-implemented, critical gaps exist in CI/CD pipeline enforcement. The most significant issue is the absence of pip-audit as a blocking mechanism in CI/CD, despite 15 HIGH/CRITICAL vulnerabilities being detected. The ADR's core requirement for automated blocking of vulnerable dependencies is not fully implemented, creating security risks."
    },
    "ADR-F1-1_TemplatingEngine": {
      "adr_id": "ADR-F1-1_TemplatingEngine",
      "compliance_score": 0.0,
      "violations": [
        {
          "file_path": "/Users/tamnguyen/Documents/GitHub/violentutf-api/requirements.txt",
          "line_number": 1,
          "description": "Critical violation: Jinja2 dependency is completely missing from requirements.txt. ADR mandates Jinja2 as the chosen templating engine with specific version pinning for security.",
          "risk_level": "critical",
          "remediation_suggestion": "Add 'jinja2>=3.1.0,<4.0.0' to requirements.txt with proper version constraints for security",
          "confidence": 1.0
        },
        {
          "file_path": "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/api/routes.py",
          "line_number": 1,
          "description": "Critical violation: No templating endpoints exist. ADR requires API endpoints for template rendering (e.g., POST /templates/render) with sandboxed Jinja2 environment implementation.",
          "risk_level": "critical",
          "remediation_suggestion": "Create template rendering endpoints with SandboxedEnvironment implementation, input validation, and proper error handling",
          "confidence": 1.0
        },
        {
          "file_path": "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/services",
          "line_number": 1,
          "description": "Critical violation: No TemplatingService implementation found. ADR requires a secure service layer for rendering sandboxed templates with resource limiting and custom filters.",
          "risk_level": "critical",
          "remediation_suggestion": "Implement TemplateService class using jinja2.SandboxedEnvironment with disabled dangerous methods, custom filters, and resource limiting",
          "confidence": 1.0
        },
        {
          "file_path": "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/config.py",
          "line_number": 524,
          "description": "High violation: No template rendering configuration found in Settings class. ADR requires CPU time and memory limits for template execution to prevent DoS attacks.",
          "risk_level": "high",
          "remediation_suggestion": "Add template engine configuration fields: TEMPLATE_CPU_TIME_LIMIT, TEMPLATE_MEMORY_LIMIT, MAX_TEMPLATE_SIZE, TEMPLATE_TIMEOUT",
          "confidence": 0.95
        },
        {
          "file_path": "/Users/tamnguyen/Documents/GitHub/violentutf-api/app",
          "line_number": 1,
          "description": "Critical violation: No custom filter implementation found. ADR mandates specific filters: base64encode, base64decode, urlencode, leetspeak, reverse, json_escape for secure template transformations.",
          "risk_level": "critical",
          "remediation_suggestion": "Implement custom filter library in app/utils/template_filters.py with security-reviewed transformation functions and proper error handling",
          "confidence": 1.0
        },
        {
          "file_path": "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/utils/validation.py",
          "line_number": 402,
          "description": "Medium violation: Template injection validation missing. While prompt injection validation exists (line 199), no specific Jinja2 template injection protection is implemented for additional security layers.",
          "risk_level": "medium",
          "remediation_suggestion": "Extend validation.py to include template injection pattern detection ({{ }}, {% %}, {# #}) for additional security layers beyond sandboxing",
          "confidence": 0.85
        },
        {
          "file_path": "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/main.py",
          "line_number": 254,
          "description": "High violation: No template service initialization in application startup. ADR requires proper initialization of sandboxed environment during app startup.",
          "risk_level": "high",
          "remediation_suggestion": "Add template service initialization to the lifespan context manager or startup handlers",
          "confidence": 0.9
        }
      ],
      "compliant_areas": [
        "Strong input validation framework exists (app/utils/validation.py) with security pattern detection that can be extended for template validation",
        "Comprehensive security-focused configuration system (app/core/config.py) with proper validation that can accommodate template engine settings",
        "Request size limiting middleware exists that could be extended for template size limits",
        "Structured logging system with security logging patterns that could support template rendering audit trails",
        "Robust middleware architecture that could integrate template security checks",
        "Comprehensive error handling patterns that could be applied to template rendering failures"
      ],
      "recommendations": [
        "IMMEDIATE: Add Jinja2 dependency to requirements.txt with version pinning (jinja2>=3.1.0,<4.0.0)",
        "IMMEDIATE: Implement TemplateService class using jinja2.SandboxedEnvironment with disabled dangerous built-ins and methods",
        "HIGH PRIORITY: Create custom filter library with the six mandated filters (base64encode, base64decode, urlencode, leetspeak, reverse, json_escape)",
        "HIGH PRIORITY: Add template rendering endpoints (POST /api/v1/templates/render) with proper input validation and error handling",
        "HIGH PRIORITY: Implement resource limiting for template execution (CPU time, memory, execution timeout) to prevent DoS attacks",
        "MEDIUM PRIORITY: Add template engine configuration to Settings class with security-focused defaults",
        "MEDIUM PRIORITY: Add comprehensive template security testing to existing test suite",
        "LOW PRIORITY: Create template injection validation patterns in the existing validation framework for defense-in-depth"
      ],
      "analysis_timestamp": "2025-08-02T22:08:38.468351+00:00",
      "files_analyzed": [
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/docs/architecture/ADRs/ADR-F1-1_TemplatingEngine.md",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/requirements.txt",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/main.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/api/routes.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/config.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/utils/validation.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/services"
      ],
      "analysis_summary": "Complete non-compliance with ADR-F1-1_TemplatingEngine requirements. The entire sandboxed templating engine implementation is missing from the codebase. No Jinja2 dependency, no template rendering endpoints, no TemplateService implementation, no custom filters, and no sandboxed environment configuration found. However, the codebase has excellent security foundations including input validation, configuration management, middleware architecture, and logging systems that provide a solid foundation for implementing the required templating engine. The implementation gap is complete but the architectural foundation is strong and compliance-ready."
    },
    "ADR-005_RateLimiting": {
      "adr_id": "ADR-005_RateLimiting",
      "compliance_score": 35.2,
      "violations": [
        {
          "file_path": "app/core/rate_limiting.py",
          "line_number": 103,
          "description": "Rate limiter does not explicitly implement Token Bucket algorithm as required by ADR. Uses SlowAPI default algorithm which may not be Token Bucket.",
          "risk_level": "high",
          "remediation_suggestion": "Verify SlowAPI uses Token Bucket algorithm or implement custom Token Bucket rate limiter with explicit bucket size and refill rate",
          "confidence": 0.85
        },
        {
          "file_path": "app/core/rate_limiting.py",
          "line_number": 105,
          "description": "Redis storage configuration uses conditional fallback to memory:// which violates ADR requirement for centralized Redis state management",
          "risk_level": "critical",
          "remediation_suggestion": "Remove memory:// fallback and enforce Redis requirement. Add proper Redis connection validation before enabling rate limiting",
          "confidence": 0.95
        },
        {
          "file_path": "app/core/rate_limiting.py",
          "line_number": 43,
          "description": "Missing rate limit configuration for scan_create (10/minute) as specified in ADR implementation details",
          "risk_level": "high",
          "remediation_suggestion": "Add rate limit configuration: 'scan_create': '10/minute' and implement POST /api/v1/scans endpoint",
          "confidence": 0.9
        },
        {
          "file_path": "app/core/rate_limiting.py",
          "line_number": 44,
          "description": "Missing rate limit configuration for report_generate (20/minute) as specified in ADR implementation details",
          "risk_level": "high",
          "remediation_suggestion": "Add rate limit configuration: 'report_generate': '20/minute' and implement POST /api/v1/reports/generate endpoint",
          "confidence": 0.9
        },
        {
          "file_path": "app/api/endpoints",
          "line_number": 0,
          "description": "Critical business endpoints POST /api/v1/scans and POST /api/v1/reports/generate are completely missing from implementation",
          "risk_level": "critical",
          "remediation_suggestion": "Implement missing resource-intensive endpoints with proper rate limiting decorators applied",
          "confidence": 1.0
        },
        {
          "file_path": "app/middleware/rate_limiting.py",
          "line_number": 146,
          "description": "Rate limiting enforcement is disabled in middleware with comment 'Skip actual rate limiting in test/development mode'",
          "risk_level": "critical",
          "remediation_suggestion": "Implement proper rate limiting logic in production mode and remove test mode bypasses",
          "confidence": 0.95
        },
        {
          "file_path": "app/core/rate_limiting.py",
          "line_number": 81,
          "description": "Rate limit principal uses API key truncation ([:8]) which may not provide sufficient uniqueness for organization-based limiting",
          "risk_level": "medium",
          "remediation_suggestion": "Use proper API key hashing or full organization_id extraction from API key metadata",
          "confidence": 0.75
        },
        {
          "file_path": "app/middleware/rate_limiting.py",
          "line_number": 206,
          "description": "HTTP headers implementation is incomplete - hardcoded values instead of actual rate limit state",
          "risk_level": "medium",
          "remediation_suggestion": "Integrate with SlowAPI internals to provide accurate X-RateLimit-Remaining and X-RateLimit-Reset headers",
          "confidence": 0.8
        }
      ],
      "compliant_areas": [
        "Multi-layered rate limiting architecture is correctly designed",
        "Organization-based rate limiting principal extraction is implemented",
        "SlowAPI library integration provides Redis backend support",
        "Standard HTTP 429 responses with Retry-After headers are implemented",
        "Rate limiting is configurable via settings and can be disabled for testing",
        "Authentication endpoint rate limits are properly configured (5/minute for login, 3/minute for password reset)",
        "IP-based fallback rate limiting is available for unauthenticated requests"
      ],
      "recommendations": [
        "Implement missing POST /api/v1/scans and POST /api/v1/reports/generate endpoints with specified rate limits",
        "Verify and document that SlowAPI uses Token Bucket algorithm as required, or implement custom Token Bucket limiter",
        "Remove memory:// fallback and enforce Redis dependency for production deployments",
        "Enable actual rate limiting enforcement in middleware (remove development mode bypass)",
        "Implement proper rate limit header calculation using SlowAPI internal state",
        "Add comprehensive rate limiting tests to verify Token Bucket behavior and Redis state management",
        "Document rate limiting configuration and provide monitoring dashboards for rate limit metrics"
      ],
      "analysis_timestamp": "2025-08-02T22:10:16.635690+00:00",
      "files_analyzed": [
        "docs/architecture/ADRs/ADR-005_RateLimiting.md",
        "app/core/rate_limiting.py",
        "app/middleware/rate_limiting.py",
        "app/main.py",
        "app/core/config.py",
        "app/api/endpoints/health.py",
        "requirements.txt"
      ],
      "analysis_summary": "The ViolentUTF API has a well-architected rate limiting foundation using SlowAPI with Redis backend, but suffers from critical implementation gaps. While the multi-layered architecture and configuration are sound, the system lacks the core business endpoints that require rate limiting, has disabled enforcement in middleware, and doesn't guarantee Token Bucket algorithm usage. The 35.2% compliance score reflects partial implementation of ADR requirements with significant missing functionality."
    },
    "ADR-007_Auth_Failover": {
      "adr_id": "ADR-007_Auth_Failover",
      "compliance_score": 78.5,
      "violations": [
        {
          "file_path": "app/core/cache.py",
          "line_number": 19,
          "description": "Missing Redis Sentinel support - ADR requires Redis Sentinel for high availability but CacheManager only implements basic redis connection without sentinel configuration",
          "risk_level": "high",
          "remediation_suggestion": "Implement Redis Sentinel support in CacheManager constructor and connection logic to enable automatic failover between Redis instances",
          "confidence": 0.92
        },
        {
          "file_path": "app/core/cache.py",
          "line_number": 162,
          "description": "Missing write-through caching implementation - ADR requires write-through caching for consistency but current implementation only provides write-behind pattern",
          "risk_level": "medium",
          "remediation_suggestion": "Implement write-through caching by ensuring database writes occur before cache updates in set() method",
          "confidence": 0.88
        },
        {
          "file_path": "app/core/auth_failover.py",
          "line_number": 344,
          "description": "Circuit breaker integration incomplete - get_circuit_breaker function calls may fail if circuit breakers are not properly initialized",
          "risk_level": "medium",
          "remediation_suggestion": "Add null checks and proper error handling for circuit breaker retrieval in is_service_degraded method",
          "confidence": 0.85
        },
        {
          "file_path": "app/services/health_service.py",
          "line_number": 313,
          "description": "Missing RBAC model import - Line references 'app.models.rbac' which does not exist in the codebase",
          "risk_level": "high",
          "remediation_suggestion": "Fix import to use correct model path 'app.models.role' or create the missing rbac model module",
          "confidence": 0.95
        },
        {
          "file_path": "app/core/session.py",
          "line_number": 26,
          "description": "Cache dependency mismatch - Uses get_cache_client() instead of get_cache() from core.cache module, creating inconsistent cache management",
          "risk_level": "medium",
          "remediation_suggestion": "Update import to use get_cache() from app.core.cache for consistent cache management across the application",
          "confidence": 0.9
        },
        {
          "file_path": "app/core/auth_failover.py",
          "line_number": 117,
          "description": "Insecure password hashing fallback - Uses SHA256 as fallback when bcrypt is unavailable, which violates security requirements",
          "risk_level": "high",
          "remediation_suggestion": "Remove SHA256 fallback and make bcrypt mandatory, or implement proper key derivation function like PBKDF2",
          "confidence": 0.93
        }
      ],
      "compliant_areas": [
        "Circuit Breaker Pattern implementation with proper state management (CLOSED/OPEN/HALF_OPEN)",
        "Fallback authentication provider with cached credentials and API key support",
        "Emergency token generation and validation for critical operations",
        "Health monitoring service with comprehensive component checks",
        "Cache-based session management with Redis fallback to in-memory storage",
        "Exponential backoff logic implemented in circuit breaker recovery timeout",
        "Graceful degradation detection through circuit breaker state monitoring"
      ],
      "recommendations": [
        "Implement Redis Sentinel configuration for true high availability as specified in ADR",
        "Add consistent hashing support for distributed caching as mentioned in ADR Component #1",
        "Implement proper write-through caching to ensure data consistency",
        "Fix model import issues in health service RBAC checks",
        "Standardize cache client usage across all modules",
        "Add comprehensive integration tests for failover scenarios",
        "Implement metrics and alerting as specified in ADR Component #4",
        "Add read-only access mode when write operations fail as specified in graceful degradation requirements"
      ],
      "analysis_timestamp": "2025-08-02T22:13:43.842370+00:00",
      "files_analyzed": [
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/auth_failover.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/cache.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/circuit_breaker.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/services/health_service.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/session.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/config.py"
      ],
      "analysis_summary": "The authentication failover implementation demonstrates good architectural foundation with 78.5% compliance to ADR-007. Key components like FallbackAuthProvider, CircuitBreaker, and HealthMonitor are properly implemented. However, critical gaps exist in Redis Sentinel support, write-through caching, and some integration issues. The system provides basic failover capabilities but lacks the high availability features specified in the ADR architecture diagram. Security concerns include insecure password hashing fallbacks that need immediate attention."
    },
    "ADR-008_LoggingandAuditing": {
      "adr_id": "ADR-008_LoggingandAuditing",
      "compliance_score": 68.5,
      "violations": [
        {
          "file_path": "app/core/logging.py",
          "line_number": 108,
          "description": "Missing required organization_id and correlation_id context binding. log_request_context function only binds request_id, method, path, client_ip, and user_id but fails to include organization_id which is mandated by ADR-008 for multi-tenant identity tracking.",
          "risk_level": "high",
          "remediation_suggestion": "Add organization_id parameter to log_request_context function and bind it using bind_contextvars. Extract organization_id from JWT token claims or request headers.",
          "confidence": 0.95
        },
        {
          "file_path": "app/core/logging.py",
          "line_number": 88,
          "description": "Log level configuration does not enforce ADR-008 production policy. LOG_LEVEL is read from settings but there's no validation to prevent DEBUG level in production as required by the ADR.",
          "risk_level": "medium",
          "remediation_suggestion": "Add validation in setup_logging() to enforce LOG_LEVEL != 'DEBUG' when ENVIRONMENT == 'production'",
          "confidence": 0.9
        },
        {
          "file_path": "app/middleware/request_id.py",
          "line_number": 39,
          "description": "Uses request_id instead of correlation_id as specified in ADR-008. The ADR explicitly requires correlation_id for end-to-end tracing through asynchronous workers.",
          "risk_level": "medium",
          "remediation_suggestion": "Rename request_id to correlation_id throughout the codebase to align with ADR-008 terminology and ensure consistency with async task processing requirements.",
          "confidence": 0.85
        },
        {
          "file_path": "app/core/logging.py",
          "line_number": 25,
          "description": "Data redaction policy incomplete. Missing required PII fields from ADR-008: firstName, lastName, email are not included in sensitive_keys set as mandated by the specification.",
          "risk_level": "high",
          "remediation_suggestion": "Add 'firstname', 'lastname', 'email', 'first_name', 'last_name' to sensitive_keys set in sanitize_sensitive_data function.",
          "confidence": 0.92
        },
        {
          "file_path": "app/middleware/logging.py",
          "line_number": 30,
          "description": "Log entries do not follow ADR-008 schema. Missing required fields: service_name, auth_context with organization_id/user_id, http_context structured object. Current logs only include basic request information.",
          "risk_level": "high",
          "remediation_suggestion": "Restructure log entries to include complete ADR-008 schema: timestamp (ISO 8601), level, message, correlation_id, service_name, auth_context, http_context, extra_data objects.",
          "confidence": 0.88
        },
        {
          "file_path": "app/middleware/audit.py",
          "line_number": 234,
          "description": "Audit logging writes to database instead of stdout as mandated by ADR-008. The ADR explicitly requires 'log to standard output (stdout) as a stream of JSON objects' for containerization best practices.",
          "risk_level": "medium",
          "remediation_suggestion": "Modify audit middleware to emit structured JSON logs to stdout in addition to database storage. Use logger.info() with complete ADR-008 schema for audit events.",
          "confidence": 0.9
        }
      ],
      "compliant_areas": [
        "Uses structlog for structured JSON logging with proper JSON renderer",
        "Implements data sanitization with _sanitize_dict function for sensitive fields",
        "Logs to stdout via structlog configuration in setup_logging()",
        "Includes request ID generation and tracking through middleware",
        "Implements comprehensive audit service with proper categorization",
        "Includes user context binding in authentication middleware",
        "Uses ISO timestamp format through structlog.processors.TimeStamper"
      ],
      "recommendations": [
        "Implement complete ADR-008 log schema with all required fields (service_name, auth_context, http_context)",
        "Add organization_id extraction from JWT tokens and include in all log contexts",
        "Rename request_id to correlation_id throughout codebase for ADR compliance",
        "Extend data redaction to include all PII fields specified in ADR-008",
        "Add production environment validation to prevent DEBUG logging",
        "Configure asynchronous log writing for performance as mentioned in ADR-008",
        "Implement log sampling for DEBUG level as suggested in the ADR",
        "Create middleware to enrich all logs with complete contextual data automatically"
      ],
      "analysis_timestamp": "2025-08-02T22:14:47.688987+00:00",
      "files_analyzed": [
        "app/core/logging.py",
        "app/middleware/logging.py",
        "app/middleware/request_id.py",
        "app/middleware/audit.py",
        "app/services/audit_service.py",
        "app/main.py",
        "app/core/config.py",
        "app/middleware/authentication.py",
        "app/api/endpoints/auth.py"
      ],
      "analysis_summary": "The codebase has a solid foundation with structlog and structured logging, but lacks full ADR-008 compliance. Key issues include missing organization_id context for multi-tenancy, incomplete log schema implementation, using request_id instead of correlation_id, and insufficient PII redaction. The audit system is well-designed but doesn't emit structured logs to stdout as required. Overall compliance is moderate with significant remediation needed for production readiness."
    },
    "ADR-F3-1_ScoringArchitecture": {
      "adr_id": "ADR-F3-1_ScoringArchitecture",
      "compliance_score": 15.0,
      "violations": [
        {
          "file_path": "app/models/session.py",
          "line_number": 1,
          "description": "Session model exists but lacks scoring-specific fields like 'analysis_status' column required by ADR. The model tracks user authentication sessions but not red-teaming test session evidence with scoring metadata.",
          "risk_level": "critical",
          "remediation_suggestion": "Add analysis_status column to session model or create separate TestSession model for red-teaming sessions with scoring lifecycle tracking",
          "confidence": 0.95
        },
        {
          "file_path": "app/services/session_service.py",
          "line_number": 1,
          "description": "SessionService exists but is focused on authentication session management, not orchestration of red-teaming sessions. Missing triage scoring integration and deep analysis job triggering as required by ADR.",
          "risk_level": "critical",
          "remediation_suggestion": "Create OrchestrationService that implements real-time triage scoring during test execution and triggers batch deep analysis jobs",
          "confidence": 0.98
        },
        {
          "file_path": "Missing implementation",
          "line_number": 0,
          "description": "ScorerPlugin abstract base class is completely missing. ADR requires extensible scorer plugin architecture with SCORER_TYPE (real-time/batch) and SCORER_NAME attributes.",
          "risk_level": "critical",
          "remediation_suggestion": "Implement ScorerPlugin ABC as shown in ADR with score() method, SCORER_TYPE literal, and plugin registration system",
          "confidence": 1.0
        },
        {
          "file_path": "Missing implementation",
          "line_number": 0,
          "description": "No real-time triage scorers implemented. ADR requires lightweight scorers (regex, keyword matching) to run synchronously during test execution for immediate feedback.",
          "risk_level": "high",
          "remediation_suggestion": "Implement triage scorer plugins like RefusalDetectionScorer, ToxicityKeywordScorer using regex/keyword patterns",
          "confidence": 1.0
        },
        {
          "file_path": "Missing implementation",
          "line_number": 0,
          "description": "No batch deep analysis scorers implemented. ADR requires computationally expensive scorers (LLM-as-judge, semantic analysis) to run asynchronously after test completion.",
          "risk_level": "high",
          "remediation_suggestion": "Implement batch scorer plugins like LLMJudgeScorer, BiasAnalysisScorer, SemanticSimilarityScorer",
          "confidence": 1.0
        },
        {
          "file_path": "app/core/config.py",
          "line_number": 70,
          "description": "Task queue infrastructure referenced but no actual task queue implementation found. ADR requires task queue for triggering deep analysis jobs after test completion.",
          "risk_level": "high",
          "remediation_suggestion": "Implement Celery/Redis task queue or FastAPI BackgroundTasks for deep analysis job processing",
          "confidence": 0.9
        },
        {
          "file_path": "Missing implementation",
          "line_number": 0,
          "description": "Evidence document storage not implemented. ADR requires document database (MongoDB/DynamoDB) to store prompt/response pairs with triage and deep analysis scores.",
          "risk_level": "critical",
          "remediation_suggestion": "Implement evidence document storage using MongoDB or similar document database as defined in ADR-F2-2",
          "confidence": 1.0
        },
        {
          "file_path": "Missing implementation",
          "line_number": 0,
          "description": "No session_summary table with analysis_status column. ADR requires tracking completion state of deep analysis phase in relational database.",
          "risk_level": "high",
          "remediation_suggestion": "Add session_summary table with analysis_status enum ('pending', 'in_progress', 'completed') and deep analysis job tracking",
          "confidence": 0.95
        },
        {
          "file_path": "Missing implementation",
          "line_number": 0,
          "description": "Two-phase scoring lifecycle not implemented. ADR requires Phase 1 (real-time triage) during execution and Phase 2 (async deep analysis) after completion.",
          "risk_level": "critical",
          "remediation_suggestion": "Implement orchestration flow that runs triage scorers synchronously and enqueues deep analysis jobs to task queue upon test completion",
          "confidence": 1.0
        }
      ],
      "compliant_areas": [
        "Session model structure provides good foundation for red-teaming session tracking",
        "FastAPI application architecture supports plugin extensibility patterns",
        "Database session management patterns are well-established",
        "Configuration system can support scorer plugin settings"
      ],
      "recommendations": [
        "Implement ScorerPlugin abstract base class with registration system following ADR specification",
        "Create OrchestrationService to manage two-phase scoring lifecycle during red-teaming sessions",
        "Add task queue infrastructure (Celery/Redis) for asynchronous deep analysis jobs",
        "Set up document database for evidence storage with triage and deep analysis score fields",
        "Implement real-time triage scorers (regex-based keyword/refusal detection)",
        "Implement batch deep analysis scorers (LLM-as-judge, semantic analysis)",
        "Add session_summary table with analysis_status tracking for deep analysis completion",
        "Create scorer plugin registry and configuration management system",
        "Implement evidence document update workflow for adding deep analysis scores"
      ],
      "analysis_timestamp": "2025-08-02T22:16:01.244397+00:00",
      "files_analyzed": [
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/docs/architecture/ADRs/ADR-F3-1_ScoringArchitecture.md",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/models/session.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/services/session_service.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/api/endpoints/sessions.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/config.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/main.py",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/docs/architecture/ADRs/ADR-007_AsyncTaskProcessing.md",
        "/Users/tamnguyen/Documents/GitHub/violentutf-api/docs/architecture/ADRs/ADR-F2-2_DataStorage.md"
      ],
      "analysis_summary": "The codebase shows a 15% compliance score with ADR-F3-1 ScoringArchitecture. While foundational authentication session management exists, the critical scoring architecture components are missing. The ADR requires a hybrid real-time/batch scoring system with plugin architecture, but no scorer plugins, orchestration service, evidence document storage, or two-phase scoring lifecycle are implemented. The existing session management focuses on user authentication rather than red-teaming session orchestration. Major architectural components need implementation including scorer plugin system, task queue for deep analysis, evidence document storage, and orchestration service managing the two-phase scoring lifecycle."
    },
    "ADR-001_RESTstyle": {
      "adr_id": "ADR-001_RESTstyle",
      "compliance_score": 91.5,
      "violations": [
        {
          "file_path": "app/main.py",
          "line_number": 146,
          "description": "OpenAPI documentation URL uses API_V1_STR prefix but should follow pure REST versioning pattern. Current: '/api/v1/openapi.json' suggests correct versioning, but production disabling reduces discoverability.",
          "risk_level": "low",
          "remediation_suggestion": "Consider exposing OpenAPI schema at '/api/v1/schema' even in production for better API discoverability while maintaining security",
          "confidence": 0.85
        },
        {
          "file_path": "app/api/routes.py",
          "line_number": 94,
          "description": "OAuth2 endpoints included without clear REST resource mapping. OAuth2 follows its own spec which may not align perfectly with REST principles for token endpoints.",
          "risk_level": "medium",
          "remediation_suggestion": "Document OAuth2 endpoints as exception to pure REST in ADR, or restructure as '/api/v1/tokens' resource with appropriate verbs",
          "confidence": 0.75
        },
        {
          "file_path": "app/middleware/authentication.py",
          "line_number": 18,
          "description": "Hardcoded protected paths list couples middleware to specific API versions. This creates maintenance burden when adding new API versions.",
          "risk_level": "medium",
          "remediation_suggestion": "Implement dynamic path protection based on route metadata or use pattern matching for '/api/v*/protected-resource-types'",
          "confidence": 0.9
        },
        {
          "file_path": "app/core/config.py",
          "line_number": 31,
          "description": "API versioning is configured properly ('/api/v1') but lacks strategy for handling multiple concurrent versions as mentioned in ADR.",
          "risk_level": "low",
          "remediation_suggestion": "Add configuration support for multiple API versions and implement version deprecation strategy per ADR-004 reference",
          "confidence": 0.8
        }
      ],
      "compliant_areas": [
        "Proper HTTP methods usage (GET, POST, PUT, DELETE, PATCH) implemented consistently across all endpoints",
        "JSON data serialization standardized throughout the API using Pydantic models",
        "URI path versioning strategy correctly implemented with '/api/v1' prefix",
        "Resource-oriented endpoint structure with proper REST resource naming (users, sessions, api-keys, audit-logs)",
        "Comprehensive pagination, filtering, and field selection capabilities implemented per ADR requirements",
        "Stateless request handling with JWT tokens for authentication",
        "Standard HTTP status codes used appropriately (200, 201, 400, 401, 403, 404, 409, 422, 500, 503)",
        "CRUD operations properly mapped to HTTP methods in BaseCRUDRouter",
        "Middleware implementation for authentication, authorization, rate limiting as required for standalone operation",
        "Security headers and CORS properly configured for standalone deployment",
        "Comprehensive error handling with structured error responses following RFC 7807",
        "Field selection (sparse fieldsets) implemented to address over-fetching concerns mentioned in ADR"
      ],
      "recommendations": [
        "Add explicit API versioning strategy documentation and configuration for handling multiple versions",
        "Implement content negotiation for different response formats if needed beyond JSON",
        "Add OpenAPI/Swagger documentation generation for better API discoverability per ADR ecosystem requirements",
        "Consider implementing HATEOAS principles for enhanced REST compliance",
        "Add API deprecation headers and strategy for future version management",
        "Document OAuth2 endpoints as necessary exception to pure REST principles in ADR addendum"
      ],
      "analysis_timestamp": "2025-08-02T22:17:49.334642+00:00",
      "files_analyzed": [
        "app/main.py",
        "app/api/routes.py",
        "app/api/base.py",
        "app/api/endpoints/health.py",
        "app/api/endpoints/auth.py",
        "app/core/config.py",
        "app/middleware/authentication.py",
        "app/utils/field_selection.py",
        "app/schemas/filtering.py",
        "app/schemas/base.py"
      ],
      "analysis_summary": "The ViolentUTF API demonstrates excellent adherence to ADR-001_RESTstyle requirements with a compliance score of 91.5%. The implementation successfully achieves the core ADR objectives: resource-oriented architecture, JSON serialization, URI versioning (/api/v1), comprehensive pagination/filtering, and standalone operation capabilities. Key strengths include proper HTTP method usage, stateless design, comprehensive middleware for auth/rate limiting, and advanced field selection to mitigate over-fetching concerns. Minor improvements needed in API version management strategy and OAuth2 endpoint documentation."
    },
    "ADR-F1-2_ServersideOrchestration": {
      "adr_id": "ADR-F1-2_ServersideOrchestration",
      "compliance_score": 15.0,
      "violations": [
        {
          "file_path": "app/api/routes.py",
          "line_number": 216,
          "description": "Missing orchestrator endpoints - no '/api/v1/orchestrators/execute' endpoint exists in the API routes. ADR requires 'POST /api/v1/orchestrators/execute' for workflow submission.",
          "risk_level": "critical",
          "remediation_suggestion": "Create orchestrator endpoints module and add to routes.py to handle workflow execution requests",
          "confidence": 0.95
        },
        {
          "file_path": "app/models/__init__.py",
          "line_number": 12,
          "description": "Missing orchestration database models - no Task, Orchestration, or Job models exist to store workflow definitions, execution state, and results as required by ADR.",
          "risk_level": "critical",
          "remediation_suggestion": "Create database models for orchestration tasks, workflow definitions, and execution state management",
          "confidence": 0.95
        },
        {
          "file_path": "requirements.txt",
          "line_number": 1,
          "description": "Missing Celery task queue dependency - ADR specifies backend task queue system (Celery) with message broker (Redis) for long-running orchestration execution.",
          "risk_level": "critical",
          "remediation_suggestion": "Add celery>=5.3.0 to requirements.txt and implement worker processes for orchestration execution",
          "confidence": 0.9
        },
        {
          "file_path": "app/main.py",
          "line_number": 238,
          "description": "Missing state machine execution engine - no implementation for parsing YAML/JSON workflow definitions and executing multi-turn conversations as specified in ADR.",
          "risk_level": "critical",
          "remediation_suggestion": "Implement state machine engine with YAML parser, prompt rendering, and transition logic evaluation",
          "confidence": 0.9
        },
        {
          "file_path": "app/api/routes.py",
          "line_number": 21,
          "description": "Missing task status polling endpoints - no '/api/v1/tasks/{task_id}' endpoint for clients to poll orchestration status as required by ADR-007 integration.",
          "risk_level": "high",
          "remediation_suggestion": "Implement task status endpoints returning task status, progress, and result URLs",
          "confidence": 0.85
        },
        {
          "file_path": "app/schemas/__init__.py",
          "line_number": 12,
          "description": "Missing orchestration schemas - no Pydantic models for workflow definitions, task status responses, or orchestration results validation.",
          "risk_level": "high",
          "remediation_suggestion": "Create schema models for workflow validation, task responses, and orchestration result structures",
          "confidence": 0.85
        },
        {
          "file_path": "app/core/config.py",
          "line_number": 50,
          "description": "Missing configuration for templating engine integration - ADR specifies dependency on ADR-F1.1 templating engine for prompt rendering during orchestration.",
          "risk_level": "medium",
          "remediation_suggestion": "Add Jinja2 or similar templating configuration and integrate with orchestration engine for prompt template rendering",
          "confidence": 0.8
        }
      ],
      "compliant_areas": [
        "Redis dependency available for message broker requirement",
        "FastAPI async architecture supports asynchronous task processing pattern",
        "Database infrastructure (SQLAlchemy) ready for orchestration state storage",
        "Logging and monitoring infrastructure available for orchestration debugging"
      ],
      "recommendations": [
        "Implement core orchestration service with Celery worker processes",
        "Create database schema for workflow definitions, task states, and execution transcripts",
        "Develop YAML/JSON workflow parser with state machine execution logic",
        "Add orchestrator API endpoints following ADR-007 async pattern (202 Accepted, task polling)",
        "Integrate with ADR-F1.1 templating engine for prompt rendering during execution",
        "Implement webhook support as optional secondary mechanism per ADR decision",
        "Add comprehensive error handling and state recovery for stuck orchestrations",
        "Create workflow schema validation and versioning system"
      ],
      "analysis_timestamp": "2025-08-02T22:18:59.291629+00:00",
      "files_analyzed": [
        "docs/architecture/ADRs/ADR-F1-2_ServersideOrchestration.md",
        "docs/architecture/ADRs/ADR-007_AsyncTaskProcessing.md",
        "app/main.py",
        "app/api/routes.py",
        "app/models/__init__.py",
        "app/core/config.py",
        "requirements.txt",
        "app/schemas/__init__.py",
        "app/api/endpoints/"
      ],
      "analysis_summary": "Critical non-compliance: The codebase has no implementation of the server-side orchestration engine specified in ADR-F1-2. Core missing components include orchestrator endpoints, state machine execution engine, Celery task queue integration, and orchestration database models. The existing FastAPI infrastructure provides a foundation but requires complete orchestration feature implementation."
    },
    "ADR-F4-1_UntrustedModelInteractions": {
      "adr_id": "ADR-F4-1_UntrustedModelInteractions",
      "compliance_score": 0.0,
      "violations": [
        {
          "file_path": "app/core/external_services.py",
          "line_number": 38,
          "description": "External service configuration includes AI_MODEL service type but no container-based sandboxing implementation exists. The ADR requires mandatory container-based sandboxing for all untrusted model interactions.",
          "risk_level": "critical",
          "remediation_suggestion": "Implement container-based sandboxing infrastructure with Docker SDK for Python, ephemeral container provisioning, and secure container profiles as specified in ADR requirements.",
          "confidence": 0.98
        },
        {
          "file_path": "/",
          "line_number": 0,
          "description": "No container management SDK implementation found. ADR requires Docker SDK for Python to launch sandboxed containers for untrusted model execution.",
          "risk_level": "critical",
          "remediation_suggestion": "Add Docker SDK for Python dependency and implement container orchestration worker as specified in ADR execution flow steps 1-6.",
          "confidence": 1.0
        },
        {
          "file_path": "/",
          "line_number": 0,
          "description": "No secure container profile implementation found. ADR mandates containers with --user=non-root, --read-only, --cap-drop=ALL, --network=none, and resource limits.",
          "risk_level": "critical",
          "remediation_suggestion": "Implement secure container profile configuration with all security restrictions specified in ADR section 'Secure Container Profile'.",
          "confidence": 1.0
        },
        {
          "file_path": "/",
          "line_number": 0,
          "description": "No ephemeral container lifecycle management found. ADR requires containers to be created on-demand and destroyed immediately after execution with no state reuse.",
          "risk_level": "critical",
          "remediation_suggestion": "Implement ephemeral container lifecycle management that creates new containers per execution and irrevocably destroys them upon completion.",
          "confidence": 1.0
        },
        {
          "file_path": "/",
          "line_number": 0,
          "description": "No orchestration worker implementation for untrusted model execution. ADR specifies detailed execution flow with worker receiving jobs and managing container lifecycle.",
          "risk_level": "critical",
          "remediation_suggestion": "Implement orchestration worker service that handles untrusted model execution jobs through the specified 6-step execution flow.",
          "confidence": 1.0
        },
        {
          "file_path": "Dockerfile",
          "line_number": 22,
          "description": "Application Dockerfile creates non-root user but does not implement sandboxing infrastructure for untrusted model execution. This is the application container, not the sandbox containers required by ADR.",
          "risk_level": "high",
          "remediation_suggestion": "Create separate minimal base container image for untrusted model sandboxing as specified in ADR technical impact section.",
          "confidence": 0.92
        }
      ],
      "compliant_areas": [
        "Non-root user configuration in application Dockerfile demonstrates security awareness",
        "External services framework exists with AI_MODEL service type enumerated",
        "Circuit breaker and retry mechanisms exist for external service integration",
        "Security-focused application architecture with proper authentication middleware"
      ],
      "recommendations": [
        "Implement Docker SDK for Python integration for container management",
        "Create orchestration worker service with job queue for untrusted model execution",
        "Build hardened minimal base container image for sandboxing environment",
        "Implement secure container profile with all ADR-specified restrictions",
        "Add ephemeral container lifecycle management with immediate destruction",
        "Create controlled communication channels between orchestration worker and sandbox containers",
        "Implement resource limits and monitoring for sandbox containers",
        "Add integration with existing external services framework for model provider plugins"
      ],
      "analysis_timestamp": "2025-08-02T22:20:44.148851+00:00",
      "files_analyzed": [
        "docs/architecture/ADRs/ADR-F4-1_UntrustedModelInteractions.md",
        "app/core/external_services.py",
        "app/core/config.py",
        "app/middleware/authentication.py",
        "app/core/startup.py",
        "app/api/base.py",
        "Dockerfile"
      ],
      "analysis_summary": "The ViolentUTF API project currently has no implementation of the container-based sandboxing architecture required by ADR-F4-1. While the codebase demonstrates security awareness with non-root containers and external service integration patterns, it lacks the critical untrusted model execution infrastructure mandated by the ADR. The external services framework includes AI_MODEL service types, indicating architectural awareness of model integration needs, but no actual container sandboxing implementation exists. This represents a complete non-compliance with the ADR's core security requirements for untrusted model interactions."
    },
    "ADR-002_Authentication": {
      "adr_id": "ADR-002_Authentication",
      "compliance_score": 72.5,
      "violations": [
        {
          "file_path": "app/core/config.py",
          "line_number": 42,
          "description": "Algorithm set to HS256 (symmetric) instead of RS256 (asymmetric) as required by ADR-002. ADR specifies 'RS256 will be used, as asymmetric keys allow the signing key to be kept private while the public key for verification can be widely distributed.'",
          "risk_level": "high",
          "remediation_suggestion": "Change ALGORITHM default from 'HS256' to 'RS256' and implement RSA key pair generation and management for JWT signing",
          "confidence": 0.95
        },
        {
          "file_path": "app/core/security.py",
          "line_number": 51,
          "description": "JWT tokens are signed with symmetric key (HS256) using SECRET_KEY instead of RSA private key. This violates ADR-002 requirement for asymmetric signing.",
          "risk_level": "high",
          "remediation_suggestion": "Implement RSA private/public key pair for JWT signing and verification, replace SECRET_KEY usage with RSA private key",
          "confidence": 0.95
        },
        {
          "file_path": "app/models/api_key.py",
          "line_number": 100,
          "description": "API keys stored with SHA-256 hashing but no evidence of strong hashing algorithm as required by ADR-002. ADR states 'Keys will be stored in the database using a strong hashing algorithm (e.g., SHA-256)'",
          "risk_level": "medium",
          "remediation_suggestion": "Consider using more secure hashing like bcrypt or Argon2 for API key storage, similar to password hashing",
          "confidence": 0.8
        },
        {
          "file_path": "app/middleware/authentication.py",
          "line_number": 96,
          "description": "No token blocklist implementation found for immediate JWT revocation. ADR-002 requires 'A token blocklist will be implemented using a distributed cache (e.g., Redis) to enable immediate revocation of specific tokens or all tokens for a user.'",
          "risk_level": "high",
          "remediation_suggestion": "Implement Redis-based token blocklist system with token JTI (JWT ID) tracking for immediate revocation capabilities",
          "confidence": 0.9
        },
        {
          "file_path": "app/core/security.py",
          "line_number": 48,
          "description": "JWT tokens missing JTI (JWT ID) claim as required by ADR-002. ADR specifies tokens should include 'jti' claim for revocation tracking.",
          "risk_level": "medium",
          "remediation_suggestion": "Add 'jti' (JWT ID) claim to token creation functions using unique identifiers for revocation tracking",
          "confidence": 0.85
        },
        {
          "file_path": "app/api/endpoints/api_keys.py",
          "line_number": 218,
          "description": "API key format uses 'vutf_' prefix but ADR-002 requires 'vutf-api_...' prefix format. ADR states 'Keys will be generated with a prefix (e.g., vutf-api_...) for identifiability'",
          "risk_level": "low",
          "remediation_suggestion": "Change API key prefix from 'vutf_' to 'vutf-api_' to match ADR specification",
          "confidence": 0.9
        }
      ],
      "compliant_areas": [
        "JWT access tokens have short lifespan (30-60 minutes configurable)",
        "JWT refresh tokens have longer lifespan (7 days configurable)",
        "API keys are properly hashed before database storage using SHA-256",
        "API keys have prefix for identification ('vutf_' format)",
        "Token refresh functionality implemented with token rotation",
        "API key management endpoints include create, list, revoke, and rotate operations",
        "API keys include permissions/scopes for authorization",
        "User authentication with password strength validation",
        "API key usage tracking with IP address and usage count",
        "Proper separation between access tokens and refresh tokens",
        "Token validation includes type checking (access vs refresh)",
        "API key expiration support implemented",
        "Comprehensive API key permissions system with granular scopes"
      ],
      "recommendations": [
        "Implement RS256 asymmetric signing for JWT tokens with RSA key pair management",
        "Add Redis-based token blocklist for immediate JWT revocation capabilities",
        "Include JTI claims in all JWT tokens for proper revocation tracking",
        "Consider upgrading API key hashing from SHA-256 to more secure algorithms like Argon2",
        "Update API key prefix format to match ADR specification ('vutf-api_' instead of 'vutf_')",
        "Implement key rotation schedule for JWT signing keys",
        "Add comprehensive audit logging for all token operations",
        "Consider implementing token binding to prevent token theft",
        "Add rate limiting specifically for authentication endpoints",
        "Implement proper key management service for production RSA keys"
      ],
      "analysis_timestamp": "2025-08-02T22:22:05.148099+00:00",
      "files_analyzed": [
        "docs/architecture/ADRs/ADR-002_Authentication.md",
        "app/core/auth.py",
        "app/core/security.py",
        "app/middleware/authentication.py",
        "app/api/endpoints/auth.py",
        "app/api/endpoints/api_keys.py",
        "app/models/api_key.py",
        "app/core/config.py",
        "app/main.py"
      ],
      "analysis_summary": "The ViolentUTF API has implemented a solid foundation for the phased authentication strategy outlined in ADR-002, with functional JWT and API key authentication systems. However, several key architectural requirements are not met: the implementation uses symmetric HS256 signing instead of the required asymmetric RS256, lacks the mandatory token blocklist for immediate revocation, and has minor format deviations. The dual authentication mechanism (JWT + API keys) is properly implemented with good separation of concerns, but needs the specified security enhancements to fully comply with the ADR requirements."
    },
    "ADR-F2-2_DataStorage": {
      "adr_id": "ADR-F2-2_DataStorage",
      "compliance_score": 25.0,
      "violations": [
        {
          "file_path": "app/core/config.py",
          "line_number": 59,
          "description": "Only PostgreSQL/SQLite database configuration found - missing MongoDB/DynamoDB configuration for document database as required by ADR polyglot persistence strategy",
          "risk_level": "critical",
          "remediation_suggestion": "Add configuration fields for MongoDB/DynamoDB connection string and credentials (MONGODB_URL, DYNAMODB_REGION, etc.)",
          "confidence": 0.95
        },
        {
          "file_path": "app/core/config.py",
          "line_number": 64,
          "description": "No blob storage configuration (S3, Google Cloud Storage) found in settings - ADR requires archival storage tier",
          "risk_level": "critical",
          "remediation_suggestion": "Add blob storage configuration fields (S3_BUCKET, S3_REGION, GCS_BUCKET, etc.) with lifecycle policies",
          "confidence": 0.95
        },
        {
          "file_path": "app/models/session.py",
          "line_number": 1,
          "description": "Session model stored only in relational database - violates ADR requirement for storing session evidence in document database",
          "risk_level": "high",
          "remediation_suggestion": "Create separate SessionEvidence model for document database storage with session_id, prompt, response, scores, vulnerability_ids fields",
          "confidence": 0.9
        },
        {
          "file_path": "app/db/session.py",
          "line_number": 36,
          "description": "Database session management only supports single relational database - missing document database and blob storage connections",
          "risk_level": "high",
          "remediation_suggestion": "Implement separate database connection managers for MongoDB and S3/blob storage with connection pooling",
          "confidence": 0.9
        },
        {
          "file_path": "requirements.txt",
          "line_number": 10,
          "description": "Missing document database dependencies - no PyMongo, aioboto3, boto3, or other polyglot storage libraries",
          "risk_level": "high",
          "remediation_suggestion": "Add PyMongo>=4.6.0, aioboto3>=12.0.0, motor>=3.3.0 for MongoDB and S3 support",
          "confidence": 0.95
        },
        {
          "file_path": "app/models/audit_log.py",
          "line_number": 60,
          "description": "Audit logs stored in relational DB with JSON fields - should follow ADR pattern with structured metadata in PostgreSQL and evidence details in document DB",
          "risk_level": "medium",
          "remediation_suggestion": "Split audit functionality: keep high-level summaries in PostgreSQL, move detailed evidence/logs to document database",
          "confidence": 0.8
        },
        {
          "file_path": "app/repositories/session.py",
          "line_number": 1,
          "description": "Session repository only implements relational database access patterns - missing document database and blob storage repository patterns",
          "risk_level": "high",
          "remediation_suggestion": "Create separate EvidenceRepository for document database operations and ArchiveRepository for blob storage lifecycle management",
          "confidence": 0.85
        }
      ],
      "compliant_areas": [
        "PostgreSQL configuration properly implemented with connection pooling",
        "Structured user and session metadata appropriate for relational database",
        "Database migration system (Alembic) properly configured for schema evolution",
        "Redis caching configuration present for performance optimization"
      ],
      "recommendations": [
        "Implement MongoDB connection configuration in settings.py with document database specific settings",
        "Add S3/blob storage configuration with lifecycle management policies (hot/cold/archive tiers)",
        "Create separate data models for evidence storage: session_evidence collection in MongoDB",
        "Implement data lifecycle management with automated archival process (90-day rule)",
        "Add polyglot persistence repository pattern with database routing logic",
        "Create database factory pattern to route different data types to appropriate storage systems",
        "Implement evidence archival service for moving data from hot MongoDB to cold S3 storage",
        "Add cross-database consistency checks and transaction coordination logic"
      ],
      "analysis_timestamp": "2025-08-02T22:23:19.641784+00:00",
      "files_analyzed": [
        "docs/architecture/ADRs/ADR-F2-2_DataStorage.md",
        "app/core/config.py",
        "app/db/session.py",
        "app/db/base.py",
        "app/db/base_class.py",
        "app/models/session.py",
        "app/models/user.py",
        "app/models/audit_log.py",
        "app/repositories/session.py",
        "requirements.txt",
        "pyproject.toml",
        "alembic.ini"
      ],
      "analysis_summary": "The current implementation uses a monolithic persistence strategy with only PostgreSQL/SQLite and Redis caching, completely missing the polyglot persistence architecture required by ADR-F2-2. The ADR mandates three distinct storage tiers: (1) PostgreSQL for structured metadata, (2) MongoDB/DynamoDB for session evidence, and (3) S3/blob storage for archival. None of the document database or blob storage components are implemented. This represents a critical architectural violation that severely limits the platform's ability to handle high-volume test evidence efficiently and cost-effectively."
    },
    "ADR-F4-2_SecretManagement": {
      "adr_id": "ADR-F4-2_SecretManagement",
      "compliance_score": 15.0,
      "violations": [
        {
          "file_path": "app/models/api_key.py",
          "line_number": 27,
          "description": "API keys are stored as SHA256 hashes directly in the main application database instead of using a dedicated secrets manager. This violates ADR requirement for externalized storage.",
          "risk_level": "critical",
          "remediation_suggestion": "Implement SecretsManagerClient interface from ADR and store only non-sensitive pointers to secrets in external secrets manager",
          "confidence": 0.98
        },
        {
          "file_path": "app/services/api_key_service.py",
          "line_number": 141,
          "description": "API key validation retrieves secrets directly from database via hash lookup instead of using just-in-time retrieval from dedicated secrets manager",
          "risk_level": "high",
          "remediation_suggestion": "Refactor to retrieve secrets from external secrets manager using stored pointer/reference",
          "confidence": 0.95
        },
        {
          "file_path": "app/core/config.py",
          "line_number": 39,
          "description": "SECRET_KEY stored as SecretStr in application configuration instead of being retrieved from dedicated secrets manager",
          "risk_level": "high",
          "remediation_suggestion": "Implement secrets manager client to retrieve SECRET_KEY at runtime using JIT pattern",
          "confidence": 0.92
        },
        {
          "file_path": "app/db/session.py",
          "line_number": 39,
          "description": "Database connection credentials stored in DATABASE_URL environment variable instead of secrets manager",
          "risk_level": "medium",
          "remediation_suggestion": "Store database credentials in secrets manager and retrieve connection details at runtime",
          "confidence": 0.85
        },
        {
          "file_path": "requirements.txt",
          "line_number": 1,
          "description": "No secrets management dependencies (HashiCorp Vault, AWS SDK, etc.) present in requirements",
          "risk_level": "critical",
          "remediation_suggestion": "Add dependencies for chosen secrets management solution (boto3 for AWS Secrets Manager, hvac for HashiCorp Vault, etc.)",
          "confidence": 0.99
        }
      ],
      "compliant_areas": [
        "API keys are hashed using SHA256 before storage (basic security)",
        "Environment variable abstraction through pydantic Settings",
        "Proper separation of configuration and secrets through SecretStr types"
      ],
      "recommendations": [
        "Implement the SecretsManagerClient abstract interface from ADR lines 104-116",
        "Create concrete implementations for development (local Vault) and production (AWS Secrets Manager/Azure Key Vault)",
        "Refactor API key storage to store only non-sensitive pointers in database",
        "Implement just-in-time secret retrieval pattern for all customer credentials",
        "Add comprehensive audit logging for all secret access operations",
        "Create abstraction layer allowing configurable secrets manager backends",
        "Implement proper secret lifecycle management (rotation, expiration)",
        "Add circuit breaker patterns for secrets manager communication failures"
      ],
      "analysis_timestamp": "2025-08-02T22:24:48.069768+00:00",
      "files_analyzed": [
        "docs/architecture/ADRs/ADR-F4-2_SecretManagement.md",
        "app/core/config.py",
        "app/models/api_key.py",
        "app/services/api_key_service.py",
        "app/main.py",
        "app/db/session.py",
        "pyproject.toml",
        "requirements.txt"
      ],
      "analysis_summary": "The codebase shows CRITICAL non-compliance with ADR-F4-2. While it implements basic API key management, it completely lacks the required dedicated secrets management architecture. All secrets are stored in the main application database or configuration, creating a single point of compromise that the ADR explicitly identifies as an anti-pattern. The SecretsManagerClient interface and just-in-time retrieval pattern are completely missing. This represents a fundamental architectural gap that requires immediate remediation to meet the ADR's security requirements."
    },
    "ADR-F3-2_ReportGeneration": {
      "adr_id": "ADR-F3-2_ReportGeneration",
      "compliance_score": 15.2,
      "violations": [
        {
          "file_path": "app/api/routes.py",
          "line_number": 21,
          "description": "Missing /reports API endpoints - ADR requires POST /api/v1/reports/generate endpoint but no report-related routes are registered",
          "risk_level": "critical",
          "remediation_suggestion": "Add report router to include_router() calls and create app/api/endpoints/reports.py with report generation endpoints",
          "confidence": 0.98
        },
        {
          "file_path": "requirements.txt",
          "line_number": 1,
          "description": "Missing Celery dependency - ADR specifies Celery for asynchronous task processing but celery is not in requirements",
          "risk_level": "critical",
          "remediation_suggestion": "Add celery>=5.3.0,<6.0.0 to requirements.txt for async task queue support",
          "confidence": 0.99
        },
        {
          "file_path": "requirements.txt",
          "line_number": 1,
          "description": "Missing Jinja2 dependency - ADR requires Jinja2 for HTML templating but jinja2 is not in requirements",
          "risk_level": "critical",
          "remediation_suggestion": "Add jinja2>=3.1.0,<4.0.0 to requirements.txt for template engine support",
          "confidence": 0.99
        },
        {
          "file_path": "requirements.txt",
          "line_number": 1,
          "description": "Missing Playwright dependency - ADR specifies Playwright for headless browser PDF generation but playwright is not in requirements",
          "risk_level": "critical",
          "remediation_suggestion": "Add playwright>=1.40.0,<2.0.0 to requirements.txt for PDF rendering support",
          "confidence": 0.99
        },
        {
          "file_path": "app/services/",
          "line_number": 0,
          "description": "Missing ReportService - No report generation service found in services directory",
          "risk_level": "critical",
          "remediation_suggestion": "Create app/services/report_service.py with ReportGenerationService class implementing PDF and JSON generation",
          "confidence": 0.97
        },
        {
          "file_path": "app/models/",
          "line_number": 0,
          "description": "Missing Report models - No Report or ReportConfiguration models found to support report generation workflow",
          "risk_level": "high",
          "remediation_suggestion": "Create app/models/report.py with Report, ReportConfiguration, and ReportBlock models",
          "confidence": 0.95
        },
        {
          "file_path": "app/core/config.py",
          "line_number": 1,
          "description": "Missing blob storage configuration - ADR requires blob storage for report artifacts but no storage config found",
          "risk_level": "high",
          "remediation_suggestion": "Add BLOB_STORAGE_URL, BLOB_STORAGE_CONTAINER configs to Settings class for report artifact storage",
          "confidence": 0.94
        },
        {
          "file_path": "app/",
          "line_number": 0,
          "description": "Missing workers directory - ADR requires dedicated reporting worker but no worker infrastructure found",
          "risk_level": "high",
          "remediation_suggestion": "Create app/workers/ directory with report_worker.py implementing Celery worker for report generation",
          "confidence": 0.93
        },
        {
          "file_path": "app/schemas/",
          "line_number": 0,
          "description": "Missing report schemas - No Pydantic schemas found for ReportConfiguration, ReportGenerationRequest, or ReportResponse",
          "risk_level": "medium",
          "remediation_suggestion": "Create app/schemas/report.py with comprehensive report-related Pydantic models",
          "confidence": 0.92
        },
        {
          "file_path": "app/",
          "line_number": 0,
          "description": "Missing templates directory - ADR requires HTML/CSS templates for PDF generation but no templates found",
          "risk_level": "medium",
          "remediation_suggestion": "Create app/templates/ directory with base templates and block-specific sub-templates",
          "confidence": 0.91
        }
      ],
      "compliant_areas": [
        "FastAPI framework provides foundation for async API endpoints",
        "SQLAlchemy 2.0+ supports async database operations for data aggregation",
        "Structured logging with structlog supports audit trail for report generation",
        "Pydantic validation framework can validate report configurations",
        "Authentication middleware supports securing report endpoints"
      ],
      "recommendations": [
        "CRITICAL: Implement complete report generation infrastructure - add Celery, Jinja2, Playwright dependencies and create report endpoints, services, models, and workers",
        "HIGH: Create blob storage integration for report artifact persistence with proper URL generation and access controls",
        "HIGH: Implement async task status tracking with 202 Accepted responses and task_id-based status endpoints",
        "MEDIUM: Create comprehensive HTML/CSS template system with modular block architecture as specified in ADR",
        "MEDIUM: Add data aggregation layer in services to query test results, findings, and taxonomy data for report composition",
        "LOW: Create monitoring and metrics for report generation performance and resource usage"
      ],
      "analysis_timestamp": "2025-08-02T23:14:57.286893+00:00",
      "files_analyzed": [
        "docs/architecture/ADRs/ADR-F3-2_ReportGeneration.md",
        "app/main.py",
        "app/api/routes.py",
        "docs/examples/endpoints/example_sql_safe.py",
        "app/core/config.py",
        "requirements.txt",
        "requirements-dev.txt",
        "app/services/ (directory listing)",
        "app/models/ (directory listing)",
        "app/schemas/ (directory listing)"
      ],
      "analysis_summary": "The ViolentUTF API codebase shows CRITICAL NON-COMPLIANCE with ADR-F3-2_ReportGeneration. While the application has a solid foundation with FastAPI, async support, and proper authentication, it completely lacks the server-side report generation engine specified in the ADR. Missing components include: Celery async task processing, Jinja2 templating, Playwright PDF rendering, report models/schemas/services, dedicated worker processes, blob storage integration, and the /reports API endpoints. The ADR-specified architecture for automated PDF and JSON report generation is entirely unimplemented. Implementation would require significant development effort across multiple layers of the application stack."
    }
  },
  "all_violations": [
    {
      "file_path": "tools/pre_audit/historical_analyzer.py",
      "line_number": 102,
      "description": "Type annotation unreachable warning with severity_weights validation - suggests defensive coding with unreachable branch after isinstance check",
      "risk_level": "low",
      "remediation_suggestion": "Remove the type: ignore[unreachable] comment or restructure the validation logic to avoid unreachable code",
      "confidence": 0.75
    },
    {
      "file_path": "tests/",
      "line_number": 0,
      "description": "Missing comprehensive unit tests for historical analyzer - No test files found for core implementation (ConventionalCommitParser, ADRPatternMatcher, ComplexityAnalyzer, HistoricalAnalyzer classes)",
      "risk_level": "high",
      "remediation_suggestion": "Implement test suite covering: test_conventional_commit_parser.py, test_adr_pattern_matcher.py, test_complexity_analyzer.py, test_historical_analyzer.py with edge cases and security validation",
      "confidence": 0.95
    },
    {
      "file_path": "tools/pre_audit/historical_analyzer.py",
      "line_number": 621,
      "description": "Path traversal protection logic is overly restrictive - rejects paths starting with '/' which are valid absolute paths",
      "risk_level": "medium",
      "remediation_suggestion": "Refine path validation logic to distinguish between malicious path traversal and legitimate absolute paths within repository bounds",
      "confidence": 0.85
    },
    {
      "file_path": "config/violation_patterns.yml",
      "line_number": 418,
      "description": "Configuration file ends abruptly without closing YAML structure - potential parsing issues",
      "risk_level": "medium",
      "remediation_suggestion": "Ensure YAML file has proper structure and validate with yaml.safe_load() test",
      "confidence": 0.8
    },
    {
      "file_path": "docs/architecture/ADRs/ADR-011_HistoricalCodeAnalysis.md",
      "line_number": 301,
      "description": "ADR specifies 'comprehensive unit test suite development' as short-term enhancement but tests are missing from current implementation",
      "risk_level": "medium",
      "remediation_suggestion": "Implement the promised comprehensive unit test suite as specified in the ADR to validate all architectural components",
      "confidence": 0.9
    },
    {
      "file_path": "requirements.txt",
      "line_number": 1,
      "description": "Missing task queue system dependencies: No Celery, RQ, or other task queue libraries found in requirements.txt. ADR mandates 'Task Queue system (e.g., Celery) with a message broker (e.g., Redis)'",
      "risk_level": "critical",
      "remediation_suggestion": "Add celery>=5.3.0 and celery[redis]>=5.3.0 to requirements.txt",
      "confidence": 0.98
    },
    {
      "file_path": "app/api/routes.py",
      "line_number": 21,
      "description": "No async task endpoints implemented: ADR requires '/api/v1/scans' endpoint that returns 202 Accepted with task_id and status_url, but no such endpoints exist",
      "risk_level": "critical",
      "remediation_suggestion": "Implement scan endpoints with 202 Accepted responses containing task_id and status_url fields",
      "confidence": 0.95
    },
    {
      "file_path": "app/models/",
      "line_number": 1,
      "description": "Missing Task model: No database model for tracking async tasks with PENDING/RUNNING/SUCCESS states as required by ADR implementation details",
      "risk_level": "high",
      "remediation_suggestion": "Create Task model with fields: task_id (UUID), status (PENDING/RUNNING/SUCCESS/FAILED), result_url, webhook_url, created_at, updated_at",
      "confidence": 0.92
    },
    {
      "file_path": "app/core/config.py",
      "line_number": 63,
      "description": "Incomplete task queue configuration: Redis URL is present but missing Celery broker configuration, worker settings, and task routing configuration",
      "risk_level": "high",
      "remediation_suggestion": "Add CELERY_BROKER_URL, CELERY_RESULT_BACKEND, task routing, and worker configuration settings",
      "confidence": 0.89
    },
    {
      "file_path": "app/api/endpoints/",
      "line_number": 1,
      "description": "Missing status polling endpoints: ADR requires 'GET /api/v1/tasks/{task_id}' endpoint for status checking, but no task status endpoints implemented",
      "risk_level": "high",
      "remediation_suggestion": "Implement GET /api/v1/tasks/{task_id} endpoint returning task status and result_url when complete",
      "confidence": 0.94
    },
    {
      "file_path": "app/services/",
      "line_number": 1,
      "description": "No worker processes implementation: ADR mandates 'separate processes that pull jobs from the queue, execute the long-running task', but no Celery workers or task services found",
      "risk_level": "critical",
      "remediation_suggestion": "Create Celery worker service with tasks for PyRIT orchestrator and Garak scan execution",
      "confidence": 0.96
    },
    {
      "file_path": "app/main.py",
      "line_number": 1,
      "description": "Missing webhook support: ADR requires webhook callback functionality with signature verification, but no webhook handling middleware or services implemented",
      "risk_level": "medium",
      "remediation_suggestion": "Add webhook service with HMAC signature verification and callback POST functionality",
      "confidence": 0.87
    },
    {
      "file_path": "alembic/versions/",
      "line_number": 1,
      "description": "No task-related database migrations: Database schema lacks tables for task tracking, status management, and result storage as specified in ADR",
      "risk_level": "high",
      "remediation_suggestion": "Create migration for tasks table with proper indexing on status and created_at fields",
      "confidence": 0.91
    },
    {
      "file_path": "app/main.py",
      "line_number": 216,
      "description": "Router is included with API_V1_STR prefix but there is no provision for multiple API versions or deprecation headers implementation",
      "risk_level": "medium",
      "remediation_suggestion": "Implement version-specific router organization with separate v1/ and v2/ directory structure and add deprecation header middleware",
      "confidence": 0.95
    },
    {
      "file_path": "app/core/config.py",
      "line_number": 31,
      "description": "API_V1_STR is hardcoded as static string '/api/v1' with no configuration for other versions or deprecation policies",
      "risk_level": "medium",
      "remediation_suggestion": "Add configuration settings for API_V2_STR, deprecation policy settings, and version management flags",
      "confidence": 0.9
    },
    {
      "file_path": "app/api/routes.py",
      "line_number": 21,
      "description": "Single api_router with no version-specific routing structure - all endpoints are mixed in one router without version separation",
      "risk_level": "high",
      "remediation_suggestion": "Refactor to use version-specific routers (e.g., v1_router, v2_router) and implement clean architecture separation",
      "confidence": 0.95
    },
    {
      "file_path": "app/main.py",
      "line_number": 146,
      "description": "OpenAPI documentation URL uses API_V1_STR but there's no provision for version-specific documentation generation",
      "risk_level": "medium",
      "remediation_suggestion": "Implement version-specific OpenAPI documentation generation with separate docs for each API version",
      "confidence": 0.85
    },
    {
      "file_path": "app/api/endpoints/",
      "line_number": 1,
      "description": "No implementation of deprecation headers (Deprecation, Warning) in endpoint responses as specified in the ADR",
      "risk_level": "high",
      "remediation_suggestion": "Add middleware to automatically inject Deprecation and Warning headers for deprecated API versions based on configuration",
      "confidence": 0.95
    },
    {
      "file_path": "app/main.py",
      "line_number": 1,
      "description": "Missing implementation of 6-month deprecation policy enforcement and sunset date tracking",
      "risk_level": "high",
      "remediation_suggestion": "Implement deprecation policy middleware with configurable sunset dates and automatic header injection",
      "confidence": 0.9
    },
    {
      "file_path": "N/A - Missing Implementation",
      "line_number": 0,
      "description": "Critical ADR Violation: ProviderPlugin abstract interface is completely missing. ADR requires 'A standardized ProviderPlugin abstract interface will be defined in the core application' with methods send_chat_completion, list_available_models, and validate_credentials.",
      "risk_level": "critical",
      "remediation_suggestion": "Create app/core/provider_plugin.py with the ProviderPlugin ABC class as specified in ADR lines 85-116",
      "confidence": 1.0
    },
    {
      "file_path": "N/A - Missing Implementation",
      "line_number": 0,
      "description": "Critical ADR Violation: Plugin directory violentutf_api/plugins/ does not exist. ADR specifies 'The application will discover plugins at startup by scanning a dedicated violentutf_api/plugins/ directory'",
      "risk_level": "critical",
      "remediation_suggestion": "Create violentutf_api/plugins/ directory structure and implement plugin discovery mechanism",
      "confidence": 1.0
    },
    {
      "file_path": "N/A - Missing Implementation",
      "line_number": 0,
      "description": "Critical ADR Violation: Generator database model is missing. ADR requires Generator schema with fields: name, plugin_name, model_id, credentials_id (lines 122-130)",
      "risk_level": "critical",
      "remediation_suggestion": "Create app/models/generator.py with required fields and add to database schema",
      "confidence": 1.0
    },
    {
      "file_path": "N/A - Missing Implementation",
      "line_number": 0,
      "description": "Critical ADR Violation: No plugin discovery and registration mechanism exists. ADR requires dynamic loading of plugins at startup",
      "risk_level": "critical",
      "remediation_suggestion": "Implement plugin discovery in app/core/startup.py to scan and register plugins automatically",
      "confidence": 1.0
    },
    {
      "file_path": "app/core/startup.py",
      "line_number": 13,
      "description": "High ADR Violation: Startup handler missing plugin initialization. ADR implementation requires plugin discovery during application startup",
      "risk_level": "high",
      "remediation_suggestion": "Add plugin discovery and registration logic to on_startup() function",
      "confidence": 0.9
    },
    {
      "file_path": "app/models/__init__.py",
      "line_number": 12,
      "description": "High ADR Violation: Generator model not imported/exported in models package",
      "risk_level": "high",
      "remediation_suggestion": "Add Generator to __all__ list after implementing the model",
      "confidence": 0.9
    },
    {
      "file_path": "app/core/external_services.py",
      "line_number": 38,
      "description": "Medium ADR Violation: AI_MODEL service type exists but is not integrated with ProviderPlugin architecture. This represents partial implementation without proper abstraction",
      "risk_level": "medium",
      "remediation_suggestion": "Integrate AI_MODEL service type with ProviderPlugin architecture when implementing the plugin system",
      "confidence": 0.8
    },
    {
      "file_path": "app/api/endpoints/users.py",
      "line_number": 53,
      "description": "Admin permission check uses only `is_superuser` flag instead of proper RBAC role-based checks. ADR-003 requires admin role validation, not just superuser flag.",
      "risk_level": "high",
      "remediation_suggestion": "Replace `is_superuser` check with proper RBAC role validation using `require_permissions(['admin'])` decorator",
      "confidence": 0.92
    },
    {
      "file_path": "app/models/user.py",
      "line_number": 90,
      "description": "User model stores roles as JSON array directly instead of using proper RBAC UserRole relationship. This bypasses the formal role management system.",
      "risk_level": "high",
      "remediation_suggestion": "Remove direct `roles` field and use only the UserRole relationship table for proper RBAC implementation",
      "confidence": 0.95
    },
    {
      "file_path": "app/middleware/permissions.py",
      "line_number": 63,
      "description": "Permission middleware attempts to extract user roles from token but doesn't enforce organization_id filtering for ABAC. Missing the critical ABAC layer.",
      "risk_level": "critical",
      "remediation_suggestion": "Add organization_id filtering to all data access queries as specified in ADR-003 lines 113-126",
      "confidence": 0.98
    },
    {
      "file_path": "app/repositories/base.py",
      "line_number": 56,
      "description": "Base repository lacks organization_id filtering in queries. ADR-003 requires all tenant-owned resources to be filtered by organization_id automatically.",
      "risk_level": "critical",
      "remediation_suggestion": "Implement automatic organization_id filtering in base repository get/list methods as shown in ADR-003 pseudocode",
      "confidence": 0.96
    },
    {
      "file_path": "app/core/permissions.py",
      "line_number": 17,
      "description": "Permission decorators implement RBAC but lack ABAC integration. No automatic organization_id checks are performed on resources.",
      "risk_level": "high",
      "remediation_suggestion": "Enhance permission decorators to include ABAC checks by validating resource ownership via organization_id",
      "confidence": 0.91
    },
    {
      "file_path": "app/api/endpoints/users.py",
      "line_number": 129,
      "description": "List users endpoint lacks organization_id filtering, allowing users to see other organizations' data.",
      "risk_level": "critical",
      "remediation_suggestion": "Add organization_id filtering to user listing queries to enforce multi-tenant data isolation",
      "confidence": 0.97
    },
    {
      "file_path": "app/models/__init__.py",
      "line_number": 13,
      "description": "Missing VulnerabilityTaxonomy and TaxonomyMapping models in the models package. ADR requires two database tables: vulnerability_taxonomies and taxonomy_mappings, but no corresponding SQLAlchemy models exist.",
      "risk_level": "critical",
      "remediation_suggestion": "Create VulnerabilityTaxonomy and TaxonomyMapping SQLAlchemy models with the schema specified in ADR lines 70-83",
      "confidence": 0.98
    },
    {
      "file_path": "app/db/base.py",
      "line_number": 11,
      "description": "No import statements for vulnerability taxonomy models. The base.py file imports all models for Alembic discovery but is missing the required taxonomy models.",
      "risk_level": "critical",
      "remediation_suggestion": "Add imports for VulnerabilityTaxonomy and TaxonomyMapping models once they are created",
      "confidence": 0.97
    },
    {
      "file_path": "alembic/versions/",
      "line_number": 1,
      "description": "No database migration files exist for vulnerability_taxonomies and taxonomy_mappings tables. ADR requires specific database schema with UUID primary keys, hierarchical parent_id relationships, and framework mapping tables.",
      "risk_level": "critical",
      "remediation_suggestion": "Create Alembic migration to add vulnerability_taxonomies table with columns: id (UUID), name (String), description (Text), remediation_advice (Text), parent_id (UUID FK), default_severity (Enum), and taxonomy_mappings table with framework mapping fields",
      "confidence": 0.99
    },
    {
      "file_path": "app/api/routes.py",
      "line_number": 120,
      "description": "No API endpoints for vulnerability taxonomy management. ADR implies need for CRUD operations on taxonomy data, but no endpoints exist in the API router.",
      "risk_level": "high",
      "remediation_suggestion": "Create API endpoints for vulnerability taxonomy management including GET /taxonomies, POST /taxonomies, PUT /taxonomies/{id}, DELETE /taxonomies/{id}",
      "confidence": 0.85
    },
    {
      "file_path": "app/schemas/",
      "line_number": 1,
      "description": "Missing Pydantic schemas for vulnerability taxonomy data validation. No schemas exist for VulnerabilityTaxonomy or TaxonomyMapping request/response models.",
      "risk_level": "high",
      "remediation_suggestion": "Create Pydantic schemas: VulnerabilityTaxonomyCreate, VulnerabilityTaxonomyUpdate, VulnerabilityTaxonomyResponse, TaxonomyMappingCreate, TaxonomyMappingResponse",
      "confidence": 0.92
    },
    {
      "file_path": "app/services/",
      "line_number": 1,
      "description": "No service layer implementation for vulnerability taxonomy business logic. No service exists to handle taxonomy operations, hierarchy management, or framework mapping.",
      "risk_level": "high",
      "remediation_suggestion": "Create VulnerabilityTaxonomyService with methods for: creating taxonomies, managing hierarchical relationships, mapping to external frameworks (OWASP, MITRE), and validating taxonomy data",
      "confidence": 0.88
    },
    {
      "file_path": "app/repositories/",
      "line_number": 1,
      "description": "Missing repository layer for vulnerability taxonomy data access. No repository pattern implementation for database operations on taxonomy data.",
      "risk_level": "medium",
      "remediation_suggestion": "Create VulnerabilityTaxonomyRepository and TaxonomyMappingRepository classes with methods for CRUD operations, hierarchy queries, and framework mapping lookups",
      "confidence": 0.85
    },
    {
      "file_path": "docs/architecture/ADRs/ADR-F2-2_DataStorage.md",
      "line_number": 89,
      "description": "ADR-F2-2 references vulnerability_taxonomies table in PostgreSQL implementation but table doesn't exist. This creates inconsistency between related ADRs.",
      "risk_level": "medium",
      "remediation_suggestion": "Ensure vulnerability_taxonomies table implementation aligns with both ADR-F2-1 and ADR-F2-2 requirements",
      "confidence": 0.9
    },
    {
      "file_path": "app/",
      "line_number": 1,
      "description": "No initial data seeding implementation for OWASP LLM Top 10. ADR line 85-86 requires seeding the vulnerability_taxonomies table with OWASP definitions upon deployment.",
      "risk_level": "medium",
      "remediation_suggestion": "Create data seeding script or migration to populate vulnerability_taxonomies with OWASP LLM Top 10 classifications including hierarchy and framework mappings",
      "confidence": 0.87
    },
    {
      "file_path": "app/core/errors.py",
      "line_number": 15,
      "description": "ErrorDetail model does not follow RFC 7807 standard - missing required fields: type, title, status, detail, instance. Current implementation uses non-standard fields: error, message, request_id, path, timestamp",
      "risk_level": "critical",
      "remediation_suggestion": "Replace ErrorDetail model with RFC 7807 compliant ProblemDetail model containing type, title, status, detail, instance fields",
      "confidence": 0.95
    },
    {
      "file_path": "app/core/errors.py",
      "line_number": 132,
      "description": "api_error_handler returns non-standard error format instead of RFC 7807 application/problem+json format",
      "risk_level": "critical",
      "remediation_suggestion": "Update handler to return Content-Type: application/problem+json with RFC 7807 compliant structure",
      "confidence": 0.95
    },
    {
      "file_path": "app/core/errors.py",
      "line_number": 160,
      "description": "validation_error_handler does not conform to RFC 7807 - missing type URI, status, title fields and uses non-standard structure",
      "risk_level": "critical",
      "remediation_suggestion": "Implement RFC 7807 validation error format with type URI pointing to validation error documentation",
      "confidence": 0.95
    },
    {
      "file_path": "app/core/errors.py",
      "line_number": 199,
      "description": "generic_error_handler lacks RFC 7807 compliance - missing type URI, proper status field, and application/problem+json content type",
      "risk_level": "critical",
      "remediation_suggestion": "Implement RFC 7807 compliant generic error handler with proper content type and structure",
      "confidence": 0.95
    },
    {
      "file_path": "app/schemas/base.py",
      "line_number": 182,
      "description": "APIErrorResponse schema exists but is not used in actual error handlers. It follows RFC 7807 but lacks correlation_id and error_code as required by ADR",
      "risk_level": "high",
      "remediation_suggestion": "Update APIErrorResponse to include correlation_id and error_code fields, then integrate with error handlers",
      "confidence": 0.9
    },
    {
      "file_path": "app/schemas/common.py",
      "line_number": 11,
      "description": "ErrorResponse schema uses non-standard format (error, detail, request_id, timestamp) instead of RFC 7807 fields",
      "risk_level": "high",
      "remediation_suggestion": "Replace with RFC 7807 compliant schema or deprecate in favor of APIErrorResponse",
      "confidence": 0.9
    },
    {
      "file_path": "app/main.py",
      "line_number": 40,
      "description": "rate_limit_handler returns non-RFC 7807 compliant error format with type field but missing other required RFC 7807 fields",
      "risk_level": "medium",
      "remediation_suggestion": "Update rate limit handler to use centralized RFC 7807 error response format",
      "confidence": 0.85
    },
    {
      "file_path": "Missing Implementation",
      "line_number": 0,
      "description": "No centralized Error Dictionary found as specified in ADR - should map error codes to RFC 7807 type URIs, titles, and status codes",
      "risk_level": "critical",
      "remediation_suggestion": "Create centralized error dictionary mapping error codes (VUTF-XXXX) to RFC 7807 compliant error definitions",
      "confidence": 0.95
    },
    {
      "file_path": "Missing Implementation",
      "line_number": 0,
      "description": "No correlation_id implementation found - ADR requires linking errors to structured logs via correlation_id from ADR-008",
      "risk_level": "high",
      "remediation_suggestion": "Implement correlation_id extraction from request state and include in all error responses",
      "confidence": 0.9
    },
    {
      "file_path": "Missing Implementation",
      "line_number": 0,
      "description": "No error_code field implementation found - ADR requires stable error codes like VUTF-1001 for programmatic error handling",
      "risk_level": "high",
      "remediation_suggestion": "Add error_code field to all error responses using VUTF-XXXX format",
      "confidence": 0.9
    },
    {
      "file_path": "app/api/endpoints/audit_logs.py",
      "line_number": 159,
      "description": "Export endpoint supports CSV format (text/csv) in addition to JSON, violating the 'exclusive JSON' requirement. The endpoint allows users to export audit logs in CSV format which is not the mandated application/json media type.",
      "risk_level": "medium",
      "remediation_suggestion": "Remove CSV export functionality or document this as an approved exception for data export purposes. Consider implementing JSON-only export with CSV generation on the client side.",
      "confidence": 0.95
    },
    {
      "file_path": "tests/integration/test_security_middleware_chain.py",
      "line_number": 45,
      "description": "Test cases include XML content types (application/xml, text/xml) which suggests the API may accept non-JSON formats during testing, potentially indicating insufficient content-type validation.",
      "risk_level": "low",
      "remediation_suggestion": "Ensure these test cases are specifically for rejection scenarios and that the middleware properly rejects non-JSON content types.",
      "confidence": 0.8
    },
    {
      "file_path": ".github/workflows/pr-validation.yml",
      "line_number": 62,
      "description": "pip-audit is missing from CI/CD pipeline as a blocking step. ADR requires pip-audit to block PR merges on CRITICAL/HIGH vulnerabilities, but workflow only uses 'safety check' which doesn't match ADR specifications",
      "risk_level": "critical",
      "remediation_suggestion": "Add pip-audit as a mandatory blocking step in PR validation with --fail-on-high flag",
      "confidence": 0.95
    },
    {
      "file_path": ".github/workflows/ci.yml",
      "line_number": null,
      "description": "CI pipeline lacks pip-audit integration completely. ADR mandates pip-audit as blocking CI step but it's absent from quick CI checks",
      "risk_level": "high",
      "remediation_suggestion": "Add pip-audit step to ci.yml workflow with appropriate failure conditions",
      "confidence": 0.9
    },
    {
      "file_path": "security/pip-audit-report.json",
      "line_number": 1,
      "description": "Current pip-audit scan shows 15 HIGH/CRITICAL vulnerabilities (aiohttp, mcp, pillow, protobuf, requests, starlette, torch, tornado, transformers, urllib3) but no blocking mechanism prevents deployment",
      "risk_level": "critical",
      "remediation_suggestion": "Fix identified vulnerabilities and implement automated blocking for CRITICAL/HIGH severity issues",
      "confidence": 0.98
    },
    {
      "file_path": "scripts/security-scan.sh",
      "line_number": 17,
      "description": "Safety check allows failures with '|| true' pattern, violating ADR's requirement for blocking security scans",
      "risk_level": "medium",
      "remediation_suggestion": "Remove '|| true' pattern and implement proper failure handling for safety check",
      "confidence": 0.85
    },
    {
      "file_path": ".github/workflows/security.yml",
      "line_number": 40,
      "description": "Security workflow uses 'safety check' instead of pip-audit for dependency scanning, not matching ADR tooling requirements",
      "risk_level": "medium",
      "remediation_suggestion": "Replace or supplement safety with pip-audit in security workflow",
      "confidence": 0.8
    },
    {
      "file_path": "/Users/tamnguyen/Documents/GitHub/violentutf-api/requirements.txt",
      "line_number": 1,
      "description": "Critical violation: Jinja2 dependency is completely missing from requirements.txt. ADR mandates Jinja2 as the chosen templating engine with specific version pinning for security.",
      "risk_level": "critical",
      "remediation_suggestion": "Add 'jinja2>=3.1.0,<4.0.0' to requirements.txt with proper version constraints for security",
      "confidence": 1.0
    },
    {
      "file_path": "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/api/routes.py",
      "line_number": 1,
      "description": "Critical violation: No templating endpoints exist. ADR requires API endpoints for template rendering (e.g., POST /templates/render) with sandboxed Jinja2 environment implementation.",
      "risk_level": "critical",
      "remediation_suggestion": "Create template rendering endpoints with SandboxedEnvironment implementation, input validation, and proper error handling",
      "confidence": 1.0
    },
    {
      "file_path": "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/services",
      "line_number": 1,
      "description": "Critical violation: No TemplatingService implementation found. ADR requires a secure service layer for rendering sandboxed templates with resource limiting and custom filters.",
      "risk_level": "critical",
      "remediation_suggestion": "Implement TemplateService class using jinja2.SandboxedEnvironment with disabled dangerous methods, custom filters, and resource limiting",
      "confidence": 1.0
    },
    {
      "file_path": "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/core/config.py",
      "line_number": 524,
      "description": "High violation: No template rendering configuration found in Settings class. ADR requires CPU time and memory limits for template execution to prevent DoS attacks.",
      "risk_level": "high",
      "remediation_suggestion": "Add template engine configuration fields: TEMPLATE_CPU_TIME_LIMIT, TEMPLATE_MEMORY_LIMIT, MAX_TEMPLATE_SIZE, TEMPLATE_TIMEOUT",
      "confidence": 0.95
    },
    {
      "file_path": "/Users/tamnguyen/Documents/GitHub/violentutf-api/app",
      "line_number": 1,
      "description": "Critical violation: No custom filter implementation found. ADR mandates specific filters: base64encode, base64decode, urlencode, leetspeak, reverse, json_escape for secure template transformations.",
      "risk_level": "critical",
      "remediation_suggestion": "Implement custom filter library in app/utils/template_filters.py with security-reviewed transformation functions and proper error handling",
      "confidence": 1.0
    },
    {
      "file_path": "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/utils/validation.py",
      "line_number": 402,
      "description": "Medium violation: Template injection validation missing. While prompt injection validation exists (line 199), no specific Jinja2 template injection protection is implemented for additional security layers.",
      "risk_level": "medium",
      "remediation_suggestion": "Extend validation.py to include template injection pattern detection ({{ }}, {% %}, {# #}) for additional security layers beyond sandboxing",
      "confidence": 0.85
    },
    {
      "file_path": "/Users/tamnguyen/Documents/GitHub/violentutf-api/app/main.py",
      "line_number": 254,
      "description": "High violation: No template service initialization in application startup. ADR requires proper initialization of sandboxed environment during app startup.",
      "risk_level": "high",
      "remediation_suggestion": "Add template service initialization to the lifespan context manager or startup handlers",
      "confidence": 0.9
    },
    {
      "file_path": "app/core/rate_limiting.py",
      "line_number": 103,
      "description": "Rate limiter does not explicitly implement Token Bucket algorithm as required by ADR. Uses SlowAPI default algorithm which may not be Token Bucket.",
      "risk_level": "high",
      "remediation_suggestion": "Verify SlowAPI uses Token Bucket algorithm or implement custom Token Bucket rate limiter with explicit bucket size and refill rate",
      "confidence": 0.85
    },
    {
      "file_path": "app/core/rate_limiting.py",
      "line_number": 105,
      "description": "Redis storage configuration uses conditional fallback to memory:// which violates ADR requirement for centralized Redis state management",
      "risk_level": "critical",
      "remediation_suggestion": "Remove memory:// fallback and enforce Redis requirement. Add proper Redis connection validation before enabling rate limiting",
      "confidence": 0.95
    },
    {
      "file_path": "app/core/rate_limiting.py",
      "line_number": 43,
      "description": "Missing rate limit configuration for scan_create (10/minute) as specified in ADR implementation details",
      "risk_level": "high",
      "remediation_suggestion": "Add rate limit configuration: 'scan_create': '10/minute' and implement POST /api/v1/scans endpoint",
      "confidence": 0.9
    },
    {
      "file_path": "app/core/rate_limiting.py",
      "line_number": 44,
      "description": "Missing rate limit configuration for report_generate (20/minute) as specified in ADR implementation details",
      "risk_level": "high",
      "remediation_suggestion": "Add rate limit configuration: 'report_generate': '20/minute' and implement POST /api/v1/reports/generate endpoint",
      "confidence": 0.9
    },
    {
      "file_path": "app/api/endpoints",
      "line_number": 0,
      "description": "Critical business endpoints POST /api/v1/scans and POST /api/v1/reports/generate are completely missing from implementation",
      "risk_level": "critical",
      "remediation_suggestion": "Implement missing resource-intensive endpoints with proper rate limiting decorators applied",
      "confidence": 1.0
    },
    {
      "file_path": "app/middleware/rate_limiting.py",
      "line_number": 146,
      "description": "Rate limiting enforcement is disabled in middleware with comment 'Skip actual rate limiting in test/development mode'",
      "risk_level": "critical",
      "remediation_suggestion": "Implement proper rate limiting logic in production mode and remove test mode bypasses",
      "confidence": 0.95
    },
    {
      "file_path": "app/core/rate_limiting.py",
      "line_number": 81,
      "description": "Rate limit principal uses API key truncation ([:8]) which may not provide sufficient uniqueness for organization-based limiting",
      "risk_level": "medium",
      "remediation_suggestion": "Use proper API key hashing or full organization_id extraction from API key metadata",
      "confidence": 0.75
    },
    {
      "file_path": "app/middleware/rate_limiting.py",
      "line_number": 206,
      "description": "HTTP headers implementation is incomplete - hardcoded values instead of actual rate limit state",
      "risk_level": "medium",
      "remediation_suggestion": "Integrate with SlowAPI internals to provide accurate X-RateLimit-Remaining and X-RateLimit-Reset headers",
      "confidence": 0.8
    },
    {
      "file_path": "app/core/cache.py",
      "line_number": 19,
      "description": "Missing Redis Sentinel support - ADR requires Redis Sentinel for high availability but CacheManager only implements basic redis connection without sentinel configuration",
      "risk_level": "high",
      "remediation_suggestion": "Implement Redis Sentinel support in CacheManager constructor and connection logic to enable automatic failover between Redis instances",
      "confidence": 0.92
    },
    {
      "file_path": "app/core/cache.py",
      "line_number": 162,
      "description": "Missing write-through caching implementation - ADR requires write-through caching for consistency but current implementation only provides write-behind pattern",
      "risk_level": "medium",
      "remediation_suggestion": "Implement write-through caching by ensuring database writes occur before cache updates in set() method",
      "confidence": 0.88
    },
    {
      "file_path": "app/core/auth_failover.py",
      "line_number": 344,
      "description": "Circuit breaker integration incomplete - get_circuit_breaker function calls may fail if circuit breakers are not properly initialized",
      "risk_level": "medium",
      "remediation_suggestion": "Add null checks and proper error handling for circuit breaker retrieval in is_service_degraded method",
      "confidence": 0.85
    },
    {
      "file_path": "app/services/health_service.py",
      "line_number": 313,
      "description": "Missing RBAC model import - Line references 'app.models.rbac' which does not exist in the codebase",
      "risk_level": "high",
      "remediation_suggestion": "Fix import to use correct model path 'app.models.role' or create the missing rbac model module",
      "confidence": 0.95
    },
    {
      "file_path": "app/core/session.py",
      "line_number": 26,
      "description": "Cache dependency mismatch - Uses get_cache_client() instead of get_cache() from core.cache module, creating inconsistent cache management",
      "risk_level": "medium",
      "remediation_suggestion": "Update import to use get_cache() from app.core.cache for consistent cache management across the application",
      "confidence": 0.9
    },
    {
      "file_path": "app/core/auth_failover.py",
      "line_number": 117,
      "description": "Insecure password hashing fallback - Uses SHA256 as fallback when bcrypt is unavailable, which violates security requirements",
      "risk_level": "high",
      "remediation_suggestion": "Remove SHA256 fallback and make bcrypt mandatory, or implement proper key derivation function like PBKDF2",
      "confidence": 0.93
    },
    {
      "file_path": "app/core/logging.py",
      "line_number": 108,
      "description": "Missing required organization_id and correlation_id context binding. log_request_context function only binds request_id, method, path, client_ip, and user_id but fails to include organization_id which is mandated by ADR-008 for multi-tenant identity tracking.",
      "risk_level": "high",
      "remediation_suggestion": "Add organization_id parameter to log_request_context function and bind it using bind_contextvars. Extract organization_id from JWT token claims or request headers.",
      "confidence": 0.95
    },
    {
      "file_path": "app/core/logging.py",
      "line_number": 88,
      "description": "Log level configuration does not enforce ADR-008 production policy. LOG_LEVEL is read from settings but there's no validation to prevent DEBUG level in production as required by the ADR.",
      "risk_level": "medium",
      "remediation_suggestion": "Add validation in setup_logging() to enforce LOG_LEVEL != 'DEBUG' when ENVIRONMENT == 'production'",
      "confidence": 0.9
    },
    {
      "file_path": "app/middleware/request_id.py",
      "line_number": 39,
      "description": "Uses request_id instead of correlation_id as specified in ADR-008. The ADR explicitly requires correlation_id for end-to-end tracing through asynchronous workers.",
      "risk_level": "medium",
      "remediation_suggestion": "Rename request_id to correlation_id throughout the codebase to align with ADR-008 terminology and ensure consistency with async task processing requirements.",
      "confidence": 0.85
    },
    {
      "file_path": "app/core/logging.py",
      "line_number": 25,
      "description": "Data redaction policy incomplete. Missing required PII fields from ADR-008: firstName, lastName, email are not included in sensitive_keys set as mandated by the specification.",
      "risk_level": "high",
      "remediation_suggestion": "Add 'firstname', 'lastname', 'email', 'first_name', 'last_name' to sensitive_keys set in sanitize_sensitive_data function.",
      "confidence": 0.92
    },
    {
      "file_path": "app/middleware/logging.py",
      "line_number": 30,
      "description": "Log entries do not follow ADR-008 schema. Missing required fields: service_name, auth_context with organization_id/user_id, http_context structured object. Current logs only include basic request information.",
      "risk_level": "high",
      "remediation_suggestion": "Restructure log entries to include complete ADR-008 schema: timestamp (ISO 8601), level, message, correlation_id, service_name, auth_context, http_context, extra_data objects.",
      "confidence": 0.88
    },
    {
      "file_path": "app/middleware/audit.py",
      "line_number": 234,
      "description": "Audit logging writes to database instead of stdout as mandated by ADR-008. The ADR explicitly requires 'log to standard output (stdout) as a stream of JSON objects' for containerization best practices.",
      "risk_level": "medium",
      "remediation_suggestion": "Modify audit middleware to emit structured JSON logs to stdout in addition to database storage. Use logger.info() with complete ADR-008 schema for audit events.",
      "confidence": 0.9
    },
    {
      "file_path": "app/models/session.py",
      "line_number": 1,
      "description": "Session model exists but lacks scoring-specific fields like 'analysis_status' column required by ADR. The model tracks user authentication sessions but not red-teaming test session evidence with scoring metadata.",
      "risk_level": "critical",
      "remediation_suggestion": "Add analysis_status column to session model or create separate TestSession model for red-teaming sessions with scoring lifecycle tracking",
      "confidence": 0.95
    },
    {
      "file_path": "app/services/session_service.py",
      "line_number": 1,
      "description": "SessionService exists but is focused on authentication session management, not orchestration of red-teaming sessions. Missing triage scoring integration and deep analysis job triggering as required by ADR.",
      "risk_level": "critical",
      "remediation_suggestion": "Create OrchestrationService that implements real-time triage scoring during test execution and triggers batch deep analysis jobs",
      "confidence": 0.98
    },
    {
      "file_path": "Missing implementation",
      "line_number": 0,
      "description": "ScorerPlugin abstract base class is completely missing. ADR requires extensible scorer plugin architecture with SCORER_TYPE (real-time/batch) and SCORER_NAME attributes.",
      "risk_level": "critical",
      "remediation_suggestion": "Implement ScorerPlugin ABC as shown in ADR with score() method, SCORER_TYPE literal, and plugin registration system",
      "confidence": 1.0
    },
    {
      "file_path": "Missing implementation",
      "line_number": 0,
      "description": "No real-time triage scorers implemented. ADR requires lightweight scorers (regex, keyword matching) to run synchronously during test execution for immediate feedback.",
      "risk_level": "high",
      "remediation_suggestion": "Implement triage scorer plugins like RefusalDetectionScorer, ToxicityKeywordScorer using regex/keyword patterns",
      "confidence": 1.0
    },
    {
      "file_path": "Missing implementation",
      "line_number": 0,
      "description": "No batch deep analysis scorers implemented. ADR requires computationally expensive scorers (LLM-as-judge, semantic analysis) to run asynchronously after test completion.",
      "risk_level": "high",
      "remediation_suggestion": "Implement batch scorer plugins like LLMJudgeScorer, BiasAnalysisScorer, SemanticSimilarityScorer",
      "confidence": 1.0
    },
    {
      "file_path": "app/core/config.py",
      "line_number": 70,
      "description": "Task queue infrastructure referenced but no actual task queue implementation found. ADR requires task queue for triggering deep analysis jobs after test completion.",
      "risk_level": "high",
      "remediation_suggestion": "Implement Celery/Redis task queue or FastAPI BackgroundTasks for deep analysis job processing",
      "confidence": 0.9
    },
    {
      "file_path": "Missing implementation",
      "line_number": 0,
      "description": "Evidence document storage not implemented. ADR requires document database (MongoDB/DynamoDB) to store prompt/response pairs with triage and deep analysis scores.",
      "risk_level": "critical",
      "remediation_suggestion": "Implement evidence document storage using MongoDB or similar document database as defined in ADR-F2-2",
      "confidence": 1.0
    },
    {
      "file_path": "Missing implementation",
      "line_number": 0,
      "description": "No session_summary table with analysis_status column. ADR requires tracking completion state of deep analysis phase in relational database.",
      "risk_level": "high",
      "remediation_suggestion": "Add session_summary table with analysis_status enum ('pending', 'in_progress', 'completed') and deep analysis job tracking",
      "confidence": 0.95
    },
    {
      "file_path": "Missing implementation",
      "line_number": 0,
      "description": "Two-phase scoring lifecycle not implemented. ADR requires Phase 1 (real-time triage) during execution and Phase 2 (async deep analysis) after completion.",
      "risk_level": "critical",
      "remediation_suggestion": "Implement orchestration flow that runs triage scorers synchronously and enqueues deep analysis jobs to task queue upon test completion",
      "confidence": 1.0
    },
    {
      "file_path": "app/main.py",
      "line_number": 146,
      "description": "OpenAPI documentation URL uses API_V1_STR prefix but should follow pure REST versioning pattern. Current: '/api/v1/openapi.json' suggests correct versioning, but production disabling reduces discoverability.",
      "risk_level": "low",
      "remediation_suggestion": "Consider exposing OpenAPI schema at '/api/v1/schema' even in production for better API discoverability while maintaining security",
      "confidence": 0.85
    },
    {
      "file_path": "app/api/routes.py",
      "line_number": 94,
      "description": "OAuth2 endpoints included without clear REST resource mapping. OAuth2 follows its own spec which may not align perfectly with REST principles for token endpoints.",
      "risk_level": "medium",
      "remediation_suggestion": "Document OAuth2 endpoints as exception to pure REST in ADR, or restructure as '/api/v1/tokens' resource with appropriate verbs",
      "confidence": 0.75
    },
    {
      "file_path": "app/middleware/authentication.py",
      "line_number": 18,
      "description": "Hardcoded protected paths list couples middleware to specific API versions. This creates maintenance burden when adding new API versions.",
      "risk_level": "medium",
      "remediation_suggestion": "Implement dynamic path protection based on route metadata or use pattern matching for '/api/v*/protected-resource-types'",
      "confidence": 0.9
    },
    {
      "file_path": "app/core/config.py",
      "line_number": 31,
      "description": "API versioning is configured properly ('/api/v1') but lacks strategy for handling multiple concurrent versions as mentioned in ADR.",
      "risk_level": "low",
      "remediation_suggestion": "Add configuration support for multiple API versions and implement version deprecation strategy per ADR-004 reference",
      "confidence": 0.8
    },
    {
      "file_path": "app/api/routes.py",
      "line_number": 216,
      "description": "Missing orchestrator endpoints - no '/api/v1/orchestrators/execute' endpoint exists in the API routes. ADR requires 'POST /api/v1/orchestrators/execute' for workflow submission.",
      "risk_level": "critical",
      "remediation_suggestion": "Create orchestrator endpoints module and add to routes.py to handle workflow execution requests",
      "confidence": 0.95
    },
    {
      "file_path": "app/models/__init__.py",
      "line_number": 12,
      "description": "Missing orchestration database models - no Task, Orchestration, or Job models exist to store workflow definitions, execution state, and results as required by ADR.",
      "risk_level": "critical",
      "remediation_suggestion": "Create database models for orchestration tasks, workflow definitions, and execution state management",
      "confidence": 0.95
    },
    {
      "file_path": "requirements.txt",
      "line_number": 1,
      "description": "Missing Celery task queue dependency - ADR specifies backend task queue system (Celery) with message broker (Redis) for long-running orchestration execution.",
      "risk_level": "critical",
      "remediation_suggestion": "Add celery>=5.3.0 to requirements.txt and implement worker processes for orchestration execution",
      "confidence": 0.9
    },
    {
      "file_path": "app/main.py",
      "line_number": 238,
      "description": "Missing state machine execution engine - no implementation for parsing YAML/JSON workflow definitions and executing multi-turn conversations as specified in ADR.",
      "risk_level": "critical",
      "remediation_suggestion": "Implement state machine engine with YAML parser, prompt rendering, and transition logic evaluation",
      "confidence": 0.9
    },
    {
      "file_path": "app/api/routes.py",
      "line_number": 21,
      "description": "Missing task status polling endpoints - no '/api/v1/tasks/{task_id}' endpoint for clients to poll orchestration status as required by ADR-007 integration.",
      "risk_level": "high",
      "remediation_suggestion": "Implement task status endpoints returning task status, progress, and result URLs",
      "confidence": 0.85
    },
    {
      "file_path": "app/schemas/__init__.py",
      "line_number": 12,
      "description": "Missing orchestration schemas - no Pydantic models for workflow definitions, task status responses, or orchestration results validation.",
      "risk_level": "high",
      "remediation_suggestion": "Create schema models for workflow validation, task responses, and orchestration result structures",
      "confidence": 0.85
    },
    {
      "file_path": "app/core/config.py",
      "line_number": 50,
      "description": "Missing configuration for templating engine integration - ADR specifies dependency on ADR-F1.1 templating engine for prompt rendering during orchestration.",
      "risk_level": "medium",
      "remediation_suggestion": "Add Jinja2 or similar templating configuration and integrate with orchestration engine for prompt template rendering",
      "confidence": 0.8
    },
    {
      "file_path": "app/core/external_services.py",
      "line_number": 38,
      "description": "External service configuration includes AI_MODEL service type but no container-based sandboxing implementation exists. The ADR requires mandatory container-based sandboxing for all untrusted model interactions.",
      "risk_level": "critical",
      "remediation_suggestion": "Implement container-based sandboxing infrastructure with Docker SDK for Python, ephemeral container provisioning, and secure container profiles as specified in ADR requirements.",
      "confidence": 0.98
    },
    {
      "file_path": "/",
      "line_number": 0,
      "description": "No container management SDK implementation found. ADR requires Docker SDK for Python to launch sandboxed containers for untrusted model execution.",
      "risk_level": "critical",
      "remediation_suggestion": "Add Docker SDK for Python dependency and implement container orchestration worker as specified in ADR execution flow steps 1-6.",
      "confidence": 1.0
    },
    {
      "file_path": "/",
      "line_number": 0,
      "description": "No secure container profile implementation found. ADR mandates containers with --user=non-root, --read-only, --cap-drop=ALL, --network=none, and resource limits.",
      "risk_level": "critical",
      "remediation_suggestion": "Implement secure container profile configuration with all security restrictions specified in ADR section 'Secure Container Profile'.",
      "confidence": 1.0
    },
    {
      "file_path": "/",
      "line_number": 0,
      "description": "No ephemeral container lifecycle management found. ADR requires containers to be created on-demand and destroyed immediately after execution with no state reuse.",
      "risk_level": "critical",
      "remediation_suggestion": "Implement ephemeral container lifecycle management that creates new containers per execution and irrevocably destroys them upon completion.",
      "confidence": 1.0
    },
    {
      "file_path": "/",
      "line_number": 0,
      "description": "No orchestration worker implementation for untrusted model execution. ADR specifies detailed execution flow with worker receiving jobs and managing container lifecycle.",
      "risk_level": "critical",
      "remediation_suggestion": "Implement orchestration worker service that handles untrusted model execution jobs through the specified 6-step execution flow.",
      "confidence": 1.0
    },
    {
      "file_path": "Dockerfile",
      "line_number": 22,
      "description": "Application Dockerfile creates non-root user but does not implement sandboxing infrastructure for untrusted model execution. This is the application container, not the sandbox containers required by ADR.",
      "risk_level": "high",
      "remediation_suggestion": "Create separate minimal base container image for untrusted model sandboxing as specified in ADR technical impact section.",
      "confidence": 0.92
    },
    {
      "file_path": "app/core/config.py",
      "line_number": 42,
      "description": "Algorithm set to HS256 (symmetric) instead of RS256 (asymmetric) as required by ADR-002. ADR specifies 'RS256 will be used, as asymmetric keys allow the signing key to be kept private while the public key for verification can be widely distributed.'",
      "risk_level": "high",
      "remediation_suggestion": "Change ALGORITHM default from 'HS256' to 'RS256' and implement RSA key pair generation and management for JWT signing",
      "confidence": 0.95
    },
    {
      "file_path": "app/core/security.py",
      "line_number": 51,
      "description": "JWT tokens are signed with symmetric key (HS256) using SECRET_KEY instead of RSA private key. This violates ADR-002 requirement for asymmetric signing.",
      "risk_level": "high",
      "remediation_suggestion": "Implement RSA private/public key pair for JWT signing and verification, replace SECRET_KEY usage with RSA private key",
      "confidence": 0.95
    },
    {
      "file_path": "app/models/api_key.py",
      "line_number": 100,
      "description": "API keys stored with SHA-256 hashing but no evidence of strong hashing algorithm as required by ADR-002. ADR states 'Keys will be stored in the database using a strong hashing algorithm (e.g., SHA-256)'",
      "risk_level": "medium",
      "remediation_suggestion": "Consider using more secure hashing like bcrypt or Argon2 for API key storage, similar to password hashing",
      "confidence": 0.8
    },
    {
      "file_path": "app/middleware/authentication.py",
      "line_number": 96,
      "description": "No token blocklist implementation found for immediate JWT revocation. ADR-002 requires 'A token blocklist will be implemented using a distributed cache (e.g., Redis) to enable immediate revocation of specific tokens or all tokens for a user.'",
      "risk_level": "high",
      "remediation_suggestion": "Implement Redis-based token blocklist system with token JTI (JWT ID) tracking for immediate revocation capabilities",
      "confidence": 0.9
    },
    {
      "file_path": "app/core/security.py",
      "line_number": 48,
      "description": "JWT tokens missing JTI (JWT ID) claim as required by ADR-002. ADR specifies tokens should include 'jti' claim for revocation tracking.",
      "risk_level": "medium",
      "remediation_suggestion": "Add 'jti' (JWT ID) claim to token creation functions using unique identifiers for revocation tracking",
      "confidence": 0.85
    },
    {
      "file_path": "app/api/endpoints/api_keys.py",
      "line_number": 218,
      "description": "API key format uses 'vutf_' prefix but ADR-002 requires 'vutf-api_...' prefix format. ADR states 'Keys will be generated with a prefix (e.g., vutf-api_...) for identifiability'",
      "risk_level": "low",
      "remediation_suggestion": "Change API key prefix from 'vutf_' to 'vutf-api_' to match ADR specification",
      "confidence": 0.9
    },
    {
      "file_path": "app/core/config.py",
      "line_number": 59,
      "description": "Only PostgreSQL/SQLite database configuration found - missing MongoDB/DynamoDB configuration for document database as required by ADR polyglot persistence strategy",
      "risk_level": "critical",
      "remediation_suggestion": "Add configuration fields for MongoDB/DynamoDB connection string and credentials (MONGODB_URL, DYNAMODB_REGION, etc.)",
      "confidence": 0.95
    },
    {
      "file_path": "app/core/config.py",
      "line_number": 64,
      "description": "No blob storage configuration (S3, Google Cloud Storage) found in settings - ADR requires archival storage tier",
      "risk_level": "critical",
      "remediation_suggestion": "Add blob storage configuration fields (S3_BUCKET, S3_REGION, GCS_BUCKET, etc.) with lifecycle policies",
      "confidence": 0.95
    },
    {
      "file_path": "app/models/session.py",
      "line_number": 1,
      "description": "Session model stored only in relational database - violates ADR requirement for storing session evidence in document database",
      "risk_level": "high",
      "remediation_suggestion": "Create separate SessionEvidence model for document database storage with session_id, prompt, response, scores, vulnerability_ids fields",
      "confidence": 0.9
    },
    {
      "file_path": "app/db/session.py",
      "line_number": 36,
      "description": "Database session management only supports single relational database - missing document database and blob storage connections",
      "risk_level": "high",
      "remediation_suggestion": "Implement separate database connection managers for MongoDB and S3/blob storage with connection pooling",
      "confidence": 0.9
    },
    {
      "file_path": "requirements.txt",
      "line_number": 10,
      "description": "Missing document database dependencies - no PyMongo, aioboto3, boto3, or other polyglot storage libraries",
      "risk_level": "high",
      "remediation_suggestion": "Add PyMongo>=4.6.0, aioboto3>=12.0.0, motor>=3.3.0 for MongoDB and S3 support",
      "confidence": 0.95
    },
    {
      "file_path": "app/models/audit_log.py",
      "line_number": 60,
      "description": "Audit logs stored in relational DB with JSON fields - should follow ADR pattern with structured metadata in PostgreSQL and evidence details in document DB",
      "risk_level": "medium",
      "remediation_suggestion": "Split audit functionality: keep high-level summaries in PostgreSQL, move detailed evidence/logs to document database",
      "confidence": 0.8
    },
    {
      "file_path": "app/repositories/session.py",
      "line_number": 1,
      "description": "Session repository only implements relational database access patterns - missing document database and blob storage repository patterns",
      "risk_level": "high",
      "remediation_suggestion": "Create separate EvidenceRepository for document database operations and ArchiveRepository for blob storage lifecycle management",
      "confidence": 0.85
    },
    {
      "file_path": "app/models/api_key.py",
      "line_number": 27,
      "description": "API keys are stored as SHA256 hashes directly in the main application database instead of using a dedicated secrets manager. This violates ADR requirement for externalized storage.",
      "risk_level": "critical",
      "remediation_suggestion": "Implement SecretsManagerClient interface from ADR and store only non-sensitive pointers to secrets in external secrets manager",
      "confidence": 0.98
    },
    {
      "file_path": "app/services/api_key_service.py",
      "line_number": 141,
      "description": "API key validation retrieves secrets directly from database via hash lookup instead of using just-in-time retrieval from dedicated secrets manager",
      "risk_level": "high",
      "remediation_suggestion": "Refactor to retrieve secrets from external secrets manager using stored pointer/reference",
      "confidence": 0.95
    },
    {
      "file_path": "app/core/config.py",
      "line_number": 39,
      "description": "SECRET_KEY stored as SecretStr in application configuration instead of being retrieved from dedicated secrets manager",
      "risk_level": "high",
      "remediation_suggestion": "Implement secrets manager client to retrieve SECRET_KEY at runtime using JIT pattern",
      "confidence": 0.92
    },
    {
      "file_path": "app/db/session.py",
      "line_number": 39,
      "description": "Database connection credentials stored in DATABASE_URL environment variable instead of secrets manager",
      "risk_level": "medium",
      "remediation_suggestion": "Store database credentials in secrets manager and retrieve connection details at runtime",
      "confidence": 0.85
    },
    {
      "file_path": "requirements.txt",
      "line_number": 1,
      "description": "No secrets management dependencies (HashiCorp Vault, AWS SDK, etc.) present in requirements",
      "risk_level": "critical",
      "remediation_suggestion": "Add dependencies for chosen secrets management solution (boto3 for AWS Secrets Manager, hvac for HashiCorp Vault, etc.)",
      "confidence": 0.99
    },
    {
      "file_path": "app/api/routes.py",
      "line_number": 21,
      "description": "Missing /reports API endpoints - ADR requires POST /api/v1/reports/generate endpoint but no report-related routes are registered",
      "risk_level": "critical",
      "remediation_suggestion": "Add report router to include_router() calls and create app/api/endpoints/reports.py with report generation endpoints",
      "confidence": 0.98
    },
    {
      "file_path": "requirements.txt",
      "line_number": 1,
      "description": "Missing Celery dependency - ADR specifies Celery for asynchronous task processing but celery is not in requirements",
      "risk_level": "critical",
      "remediation_suggestion": "Add celery>=5.3.0,<6.0.0 to requirements.txt for async task queue support",
      "confidence": 0.99
    },
    {
      "file_path": "requirements.txt",
      "line_number": 1,
      "description": "Missing Jinja2 dependency - ADR requires Jinja2 for HTML templating but jinja2 is not in requirements",
      "risk_level": "critical",
      "remediation_suggestion": "Add jinja2>=3.1.0,<4.0.0 to requirements.txt for template engine support",
      "confidence": 0.99
    },
    {
      "file_path": "requirements.txt",
      "line_number": 1,
      "description": "Missing Playwright dependency - ADR specifies Playwright for headless browser PDF generation but playwright is not in requirements",
      "risk_level": "critical",
      "remediation_suggestion": "Add playwright>=1.40.0,<2.0.0 to requirements.txt for PDF rendering support",
      "confidence": 0.99
    },
    {
      "file_path": "app/services/",
      "line_number": 0,
      "description": "Missing ReportService - No report generation service found in services directory",
      "risk_level": "critical",
      "remediation_suggestion": "Create app/services/report_service.py with ReportGenerationService class implementing PDF and JSON generation",
      "confidence": 0.97
    },
    {
      "file_path": "app/models/",
      "line_number": 0,
      "description": "Missing Report models - No Report or ReportConfiguration models found to support report generation workflow",
      "risk_level": "high",
      "remediation_suggestion": "Create app/models/report.py with Report, ReportConfiguration, and ReportBlock models",
      "confidence": 0.95
    },
    {
      "file_path": "app/core/config.py",
      "line_number": 1,
      "description": "Missing blob storage configuration - ADR requires blob storage for report artifacts but no storage config found",
      "risk_level": "high",
      "remediation_suggestion": "Add BLOB_STORAGE_URL, BLOB_STORAGE_CONTAINER configs to Settings class for report artifact storage",
      "confidence": 0.94
    },
    {
      "file_path": "app/",
      "line_number": 0,
      "description": "Missing workers directory - ADR requires dedicated reporting worker but no worker infrastructure found",
      "risk_level": "high",
      "remediation_suggestion": "Create app/workers/ directory with report_worker.py implementing Celery worker for report generation",
      "confidence": 0.93
    },
    {
      "file_path": "app/schemas/",
      "line_number": 0,
      "description": "Missing report schemas - No Pydantic schemas found for ReportConfiguration, ReportGenerationRequest, or ReportResponse",
      "risk_level": "medium",
      "remediation_suggestion": "Create app/schemas/report.py with comprehensive report-related Pydantic models",
      "confidence": 0.92
    },
    {
      "file_path": "app/",
      "line_number": 0,
      "description": "Missing templates directory - ADR requires HTML/CSS templates for PDF generation but no templates found",
      "risk_level": "medium",
      "remediation_suggestion": "Create app/templates/ directory with base templates and block-specific sub-templates",
      "confidence": 0.91
    }
  ],
  "violation_summary": {
    "total_violations": 139,
    "by_risk_level": {
      "low": 5,
      "high": 51,
      "medium": 33,
      "critical": 50
    },
    "by_adr": {
      "unknown": 139
    },
    "top_violated_files": [
      {
        "file": "app/core/config.py",
        "violation_count": 10
      },
      {
        "file": "requirements.txt",
        "violation_count": 7
      },
      {
        "file": "app/api/routes.py",
        "violation_count": 7
      },
      {
        "file": "app/main.py",
        "violation_count": 7
      },
      {
        "file": "Missing implementation",
        "violation_count": 6
      },
      {
        "file": "app/core/rate_limiting.py",
        "violation_count": 5
      },
      {
        "file": "N/A - Missing Implementation",
        "violation_count": 4
      },
      {
        "file": "app/core/errors.py",
        "violation_count": 4
      },
      {
        "file": "/",
        "violation_count": 4
      },
      {
        "file": "app/services/",
        "violation_count": 3
      }
    ]
  },
  "architectural_hotspots": [],
  "recommendations": [
    "Address 50 critical violations immediately"
  ]
}
