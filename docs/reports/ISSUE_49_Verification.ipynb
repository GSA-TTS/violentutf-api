{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViolentUTF API Architectural Verification - Issue #49\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This notebook provides comprehensive verification of the **22 CRITICAL** and **25 HIGH** non-security architectural violations reported in GitHub issue #49 for the ViolentUTF API.\n",
    "\n",
    "**Assessment Date:** August 6, 2025  \n",
    "**GitHub Issue:** [#49 - Validate and resolve other Critical ADR Issues](https://github.com/GSA-TTS/violentutf-api/issues/49)  \n",
    "**Source Report:** `docs/reports/ADRaudit-02AUG25-Analysis/criticalViolations_others.md`  \n",
    "**ADR Compliance Score:** 44.35% (FAILING)\n",
    "\n",
    "### Architectural Violations Distribution\n",
    "\n",
    "| Category | CRITICAL Count | Related HIGH Count | Impact Level |\n",
    "|----------|----------------|-------------------|-------------|\n",
    "| API Endpoints | 8 | 7 | **CRITICAL** - Core functionality missing |\n",
    "| Dependencies & Infrastructure | 4 | 5 | **CRITICAL** - Cannot deploy system |\n",
    "| Data Models & Database | 3 | 8 | **HIGH** - No data persistence |\n",
    "| Plugin Architecture | 3 | 2 | **HIGH** - No extensibility framework |\n",
    "| Configuration | 4 | 3 | **MEDIUM** - Incomplete settings |\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "**IMPORTANT:** This notebook requires the ViolentUTF API to be running. Please ensure:\n",
    "1. The API is accessible at the configured endpoint\n",
    "2. You have valid credentials for testing\n",
    "3. The database is properly initialized\n",
    "\n",
    "### Setup Instructions\n",
    "\n",
    "```bash\n",
    "# Start the ViolentUTF API\n",
    "cd /path/to/violentutf-api\n",
    "./setup_macos.sh  # or setup_linux.sh for Linux\n",
    "docker-compose up -d\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing python-jose...\n",
      "Requirement already satisfied: python-jose in /Users/tamnguyen/Documents/GitHub/violentutf-api/venv/lib/python3.12/site-packages (3.5.0)\n",
      "Requirement already satisfied: ecdsa!=0.15 in /Users/tamnguyen/Documents/GitHub/violentutf-api/venv/lib/python3.12/site-packages (from python-jose) (0.19.1)\n",
      "Requirement already satisfied: rsa!=4.1.1,!=4.4,<5.0,>=4.0 in /Users/tamnguyen/Documents/GitHub/violentutf-api/venv/lib/python3.12/site-packages (from python-jose) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.5.0 in /Users/tamnguyen/Documents/GitHub/violentutf-api/venv/lib/python3.12/site-packages (from python-jose) (0.6.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/tamnguyen/Documents/GitHub/violentutf-api/venv/lib/python3.12/site-packages (from ecdsa!=0.15->python-jose) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing python-dotenv...\n",
      "Requirement already satisfied: python-dotenv in /Users/tamnguyen/Documents/GitHub/violentutf-api/venv/lib/python3.12/site-packages (1.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing pyyaml...\n",
      "Requirement already satisfied: pyyaml in /Users/tamnguyen/Documents/GitHub/violentutf-api/venv/lib/python3.12/site-packages (6.0.2)\n",
      "‚úÖ All required packages installed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages if not already installed\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install a package using pip if not already installed.\"\"\"\n",
    "    try:\n",
    "        __import__(package.split('[')[0] if '[' in package else package)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Required packages\n",
    "packages = [\n",
    "    \"requests\",\n",
    "    \"pydantic\",\n",
    "    \"python-jose\",\n",
    "    \"sqlalchemy\",\n",
    "    \"asyncpg\",\n",
    "    \"pytest\",\n",
    "    \"faker\",\n",
    "    \"python-dotenv\",\n",
    "    \"colorama\",\n",
    "    \"tabulate\",\n",
    "    \"pandas\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\",\n",
    "    \"pyyaml\"\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"‚úÖ All required packages installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/tamnguyen/Documents/GitHub/violentutf-api\n",
      "‚úÖ Environment setup complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import hashlib\n",
    "import secrets\n",
    "import warnings\n",
    "import subprocess\n",
    "import importlib.util\n",
    "import ast\n",
    "import yaml\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Any, Tuple\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "import base64\n",
    "\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from faker import Faker\n",
    "from colorama import init, Fore, Back, Style\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Initialize colorama for cross-platform colored output\n",
    "init(autoreset=True)\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Initialize Faker for test data generation\n",
    "fake = Faker()\n",
    "\n",
    "# Get project root\n",
    "PROJECT_ROOT = Path.cwd().parent.parent if 'docs' in str(Path.cwd()) else Path.cwd()\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "\n",
    "print(\"‚úÖ Environment setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Loading credentials from /Users/tamnguyen/Documents/GitHub/violentutf-api/.api_credentials\n",
      "   ‚úÖ Loaded 12 credential values\n",
      "\n",
      "‚úÖ Credentials loaded from .api_credentials file\n",
      "\n",
      "üîß Configuration loaded\n",
      "   API URL: http://localhost:8000/api/v1\n",
      "   Username: admin\n",
      "   Password: ****************\n",
      "   API Key: ********************...\n",
      "   Project Root: /Users/tamnguyen/Documents/GitHub/violentutf-api\n",
      "   Database: violentutf@localhost:5432/violentutf\n"
     ]
    }
   ],
   "source": [
    "# Configuration with .api_credentials loading\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def load_api_credentials():\n",
    "    \"\"\"Load credentials from .api_credentials file.\"\"\"\n",
    "    creds = {}\n",
    "    cred_file = Path.cwd().parent.parent / \".api_credentials\" if 'docs' in str(Path.cwd()) else Path.cwd() / \".api_credentials\"\n",
    "    \n",
    "    if cred_file.exists():\n",
    "        print(f\"üìÅ Loading credentials from {cred_file}\")\n",
    "        with open(cred_file, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('#') and '=' in line:\n",
    "                    key, value = line.split('=', 1)\n",
    "                    creds[key] = value\n",
    "        print(f\"   ‚úÖ Loaded {len(creds)} credential values\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è .api_credentials file not found at {cred_file}\")\n",
    "    \n",
    "    return creds\n",
    "\n",
    "# Load credentials from file first\n",
    "api_creds = load_api_credentials()\n",
    "\n",
    "@dataclass\n",
    "class TestConfig:\n",
    "    \"\"\"Configuration for architectural testing.\"\"\"\n",
    "    \n",
    "    # Load from .api_credentials file first, then environment, then defaults\n",
    "    def __init__(self):\n",
    "        # API Configuration\n",
    "        self.api_base_url = api_creds.get('API_URL') or os.getenv('VIOLENTUTF_API_URL', os.getenv('API_BASE_URL', 'http://localhost:8000'))\n",
    "        self.api_version = os.getenv('API_VERSION', 'v1')\n",
    "        \n",
    "        # Authentication - Load from .api_credentials, then environment\n",
    "        self.admin_username = api_creds.get('ADMIN_USERNAME') or os.getenv('VIOLENTUTF_USERNAME', os.getenv('ADMIN_USERNAME', ''))\n",
    "        self.admin_password = api_creds.get('ADMIN_PASSWORD') or os.getenv('VIOLENTUTF_PASSWORD', os.getenv('ADMIN_PASSWORD', ''))\n",
    "        self.api_key = api_creds.get('API_KEY') or os.getenv('VIOLENTUTF_API_KEY', '')\n",
    "        \n",
    "        # Database credentials (optional)\n",
    "        self.db_host = api_creds.get('DB_HOST', 'localhost')\n",
    "        self.db_port = api_creds.get('DB_PORT', '5432')\n",
    "        self.db_name = api_creds.get('DB_NAME', 'violentutf')\n",
    "        self.db_user = api_creds.get('DB_USER', 'violentutf')\n",
    "        self.db_password = api_creds.get('DB_PASSWORD', '')\n",
    "        \n",
    "        # Service URLs\n",
    "        self.health_url = api_creds.get('HEALTH_URL')\n",
    "        self.docs_url = api_creds.get('DOCS_URL')\n",
    "        \n",
    "        # Project paths\n",
    "        self.project_root = PROJECT_ROOT\n",
    "        self.app_dir = self.project_root / \"app\"\n",
    "        self.requirements_file = self.project_root / \"requirements.txt\"\n",
    "        \n",
    "        # Test Parameters\n",
    "        self.request_timeout = 30\n",
    "        self.max_retries = 3\n",
    "        self.verify_ssl = False  # Set to True in production\n",
    "    \n",
    "    @property\n",
    "    def api_url(self) -> str:\n",
    "        \"\"\"Full API URL.\"\"\"\n",
    "        return f\"{self.api_base_url}/api/{self.api_version}\"\n",
    "\n",
    "# Initialize configuration\n",
    "config = TestConfig()\n",
    "\n",
    "# Only prompt for credentials if not loaded from file\n",
    "if not config.admin_username or not config.admin_password:\n",
    "    print(\"\\n‚ö†Ô∏è Credentials not found in .api_credentials or environment variables.\")\n",
    "    print(\"Please provide credentials:\")\n",
    "    print(\"\\nYou can also create a .api_credentials file with:\")\n",
    "    print(\"  ADMIN_USERNAME=your_username\")\n",
    "    print(\"  ADMIN_PASSWORD=your_password\")\n",
    "    print(\"  API_KEY=your_api_key\")\n",
    "    print(\"  API_URL=http://localhost:8000\")\n",
    "    print(\"\\nOr enter credentials now (press Enter for defaults):\\n\")\n",
    "    \n",
    "    username_input = input(f\"Username [{config.admin_username or 'admin'}]: \").strip()\n",
    "    config.admin_username = username_input if username_input else (config.admin_username or 'admin')\n",
    "    \n",
    "    from getpass import getpass\n",
    "    password_input = getpass(f\"Password [{'*' * len(config.admin_password) if config.admin_password else 'admin123'}]: \").strip()\n",
    "    config.admin_password = password_input if password_input else (config.admin_password or 'admin123')\n",
    "    \n",
    "    # Optional API key\n",
    "    api_key_input = input(\"API Key (optional, press Enter to skip): \").strip()\n",
    "    if api_key_input:\n",
    "        config.api_key = api_key_input\n",
    "else:\n",
    "    print(\"\\n‚úÖ Credentials loaded from .api_credentials file\")\n",
    "\n",
    "print(f\"\\nüîß Configuration loaded\")\n",
    "print(f\"   API URL: {config.api_url}\")\n",
    "print(f\"   Username: {config.admin_username}\")\n",
    "print(f\"   Password: {'*' * len(config.admin_password) if config.admin_password else '(not set)'}\")\n",
    "print(f\"   API Key: {'*' * 20 + '...' if config.api_key else 'Not set'}\")\n",
    "print(f\"   Project Root: {config.project_root}\")\n",
    "print(f\"   Database: {config.db_user}@{config.db_host}:{config.db_port}/{config.db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Architectural test framework initialized\n"
     ]
    }
   ],
   "source": [
    "# Architectural Violation Tracking\n",
    "class ViolationType(Enum):\n",
    "    \"\"\"Types of architectural violations.\"\"\"\n",
    "    API_ENDPOINT = \"API Endpoint\"\n",
    "    INFRASTRUCTURE = \"Infrastructure\"\n",
    "    DATA_MODEL = \"Data Model\"\n",
    "    PLUGIN = \"Plugin Architecture\"\n",
    "    CONFIGURATION = \"Configuration\"\n",
    "    ERROR_HANDLING = \"Error Handling\"\n",
    "\n",
    "class Severity(Enum):\n",
    "    \"\"\"Violation severity levels.\"\"\"\n",
    "    CRITICAL = \"CRITICAL\"\n",
    "    HIGH = \"HIGH\"\n",
    "    MEDIUM = \"MEDIUM\"\n",
    "    LOW = \"LOW\"\n",
    "    INFO = \"INFO\"\n",
    "\n",
    "@dataclass\n",
    "class ArchitecturalViolation:\n",
    "    \"\"\"Represents an architectural violation.\"\"\"\n",
    "    \n",
    "    violation_id: str\n",
    "    violation_type: ViolationType\n",
    "    severity: Severity\n",
    "    title: str\n",
    "    description: str\n",
    "    adr_violated: str\n",
    "    file_location: str\n",
    "    expected_component: str\n",
    "    actual_state: str\n",
    "    test_result: str\n",
    "    evidence: Dict[str, Any]\n",
    "    recommendation: str\n",
    "    verified: bool = False\n",
    "    timestamp: datetime = field(default_factory=datetime.now)\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for reporting.\"\"\"\n",
    "        return {\n",
    "            \"violation_id\": self.violation_id,\n",
    "            \"type\": self.violation_type.value,\n",
    "            \"severity\": self.severity.value,\n",
    "            \"title\": self.title,\n",
    "            \"description\": self.description,\n",
    "            \"adr_violated\": self.adr_violated,\n",
    "            \"file_location\": self.file_location,\n",
    "            \"expected\": self.expected_component,\n",
    "            \"actual\": self.actual_state,\n",
    "            \"test_result\": self.test_result,\n",
    "            \"evidence\": self.evidence,\n",
    "            \"recommendation\": self.recommendation,\n",
    "            \"verified\": self.verified,\n",
    "            \"timestamp\": self.timestamp.isoformat()\n",
    "        }\n",
    "\n",
    "class ArchitecturalTestResults:\n",
    "    \"\"\"Collector for architectural test results.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.violations: List[ArchitecturalViolation] = []\n",
    "        self.test_start_time = datetime.now()\n",
    "        \n",
    "    def add_violation(self, violation: ArchitecturalViolation):\n",
    "        \"\"\"Add an architectural violation.\"\"\"\n",
    "        self.violations.append(violation)\n",
    "        \n",
    "    def get_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get summary statistics.\"\"\"\n",
    "        severity_counts = {}\n",
    "        for severity in Severity:\n",
    "            severity_counts[severity.value] = sum(\n",
    "                1 for v in self.violations if v.severity == severity\n",
    "            )\n",
    "        \n",
    "        type_counts = {}\n",
    "        for vtype in ViolationType:\n",
    "            type_counts[vtype.value] = sum(\n",
    "                1 for v in self.violations if v.violation_type == vtype\n",
    "            )\n",
    "        \n",
    "        return {\n",
    "            \"total_violations\": len(self.violations),\n",
    "            \"verified_violations\": sum(1 for v in self.violations if v.verified),\n",
    "            \"severity_distribution\": severity_counts,\n",
    "            \"type_distribution\": type_counts,\n",
    "            \"test_duration\": str(datetime.now() - self.test_start_time),\n",
    "            \"adrs_violated\": list(set(v.adr_violated for v in self.violations))\n",
    "        }\n",
    "    \n",
    "    def display_summary(self):\n",
    "        \"\"\"Display formatted summary.\"\"\"\n",
    "        summary = self.get_summary()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"{Fore.CYAN}ARCHITECTURAL TEST RESULTS SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(f\"\\nüìä Overall Statistics:\")\n",
    "        print(f\"   Total Violations: {summary['total_violations']}\")\n",
    "        print(f\"   Verified: {summary['verified_violations']}\")\n",
    "        print(f\"   Test Duration: {summary['test_duration']}\")\n",
    "        \n",
    "        print(f\"\\nüî¥ Severity Distribution:\")\n",
    "        for severity, count in summary['severity_distribution'].items():\n",
    "            if count > 0:\n",
    "                color = Fore.RED if severity == \"CRITICAL\" else \\\n",
    "                        Fore.YELLOW if severity == \"HIGH\" else \\\n",
    "                        Fore.BLUE if severity == \"MEDIUM\" else \\\n",
    "                        Fore.GREEN\n",
    "                print(f\"   {color}{severity}: {count}\")\n",
    "        \n",
    "        print(f\"\\nüìÅ Violation Types:\")\n",
    "        for vtype, count in summary['type_distribution'].items():\n",
    "            if count > 0:\n",
    "                print(f\"   ‚Ä¢ {vtype}: {count}\")\n",
    "        \n",
    "        print(f\"\\nüìã ADRs Violated:\")\n",
    "        for adr in summary['adrs_violated']:\n",
    "            print(f\"   ‚Ä¢ {adr}\")\n",
    "\n",
    "# Initialize results collector\n",
    "results = ArchitecturalTestResults()\n",
    "print(\"‚úÖ Architectural test framework initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper functions and API client initialized\n"
     ]
    }
   ],
   "source": [
    "# Helper Functions\n",
    "class APIClient:\n",
    "    \"\"\"API client for architectural testing.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: TestConfig):\n",
    "        self.config = config\n",
    "        self.session = requests.Session()\n",
    "        self.session.verify = config.verify_ssl\n",
    "        self.token: Optional[str] = None\n",
    "        self.refresh_token: Optional[str] = None\n",
    "        \n",
    "        # Set API key header if available\n",
    "        if config.api_key:\n",
    "            self.session.headers.update({\n",
    "                'X-API-Key': config.api_key\n",
    "            })\n",
    "        \n",
    "    def authenticate(self, username: str = None, password: str = None, use_api_key: bool = False) -> bool:\n",
    "        \"\"\"Authenticate and obtain JWT token or use API key.\"\"\"\n",
    "        username = username or self.config.admin_username\n",
    "        password = password or self.config.admin_password\n",
    "        \n",
    "        # If API key is set and requested, skip JWT auth\n",
    "        if use_api_key and self.config.api_key:\n",
    "            print(f\"üîë Using API key authentication\")\n",
    "            return True\n",
    "        \n",
    "        try:\n",
    "            # Try different auth endpoints\n",
    "            auth_endpoints = [\n",
    "                f\"{self.config.api_url}/auth/login\",\n",
    "                f\"{self.config.api_url}/auth/token\",\n",
    "                f\"{self.config.api_base_url}/token\",\n",
    "                f\"{self.config.api_base_url}/api/auth/login\"\n",
    "            ]\n",
    "            \n",
    "            for auth_url in auth_endpoints:\n",
    "                try:\n",
    "                    response = self.session.post(\n",
    "                        auth_url,\n",
    "                        json={\"username\": username, \"password\": password},\n",
    "                        timeout=self.config.request_timeout\n",
    "                    )\n",
    "                    \n",
    "                    if response.status_code == 200:\n",
    "                        data = response.json()\n",
    "                        self.token = data.get('access_token') or data.get('token')\n",
    "                        self.refresh_token = data.get('refresh_token')\n",
    "                        if self.token:\n",
    "                            self.session.headers.update({\n",
    "                                'Authorization': f'Bearer {self.token}'\n",
    "                            })\n",
    "                            return True\n",
    "                except:\n",
    "                    continue\n",
    "                    \n",
    "            # If none worked, try the first one again for error message\n",
    "            response = self.session.post(\n",
    "                auth_endpoints[0],\n",
    "                json={\"username\": username, \"password\": password},\n",
    "                timeout=self.config.request_timeout\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 401:\n",
    "                print(f\"‚ùå Authentication failed: Invalid credentials\")\n",
    "            else:\n",
    "                print(f\"‚ùå Authentication failed: Status {response.status_code}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Authentication failed: {e}\")\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def make_request(self, method: str, endpoint: str, **kwargs) -> requests.Response:\n",
    "        \"\"\"Make an API request with error handling.\"\"\"\n",
    "        url = f\"{self.config.api_url}{endpoint}\"\n",
    "        \n",
    "        for attempt in range(self.config.max_retries):\n",
    "            try:\n",
    "                response = self.session.request(\n",
    "                    method=method,\n",
    "                    url=url,\n",
    "                    timeout=self.config.request_timeout,\n",
    "                    **kwargs\n",
    "                )\n",
    "                return response\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                if attempt == self.config.max_retries - 1:\n",
    "                    raise\n",
    "                time.sleep(2 ** attempt)  # Exponential backoff\n",
    "\n",
    "def check_file_exists(file_path: Path) -> bool:\n",
    "    \"\"\"Check if a file exists.\"\"\"\n",
    "    return file_path.exists()\n",
    "\n",
    "def check_import_in_file(file_path: Path, import_name: str) -> bool:\n",
    "    \"\"\"Check if a specific import exists in a Python file.\"\"\"\n",
    "    if not file_path.exists():\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            content = f.read()\n",
    "            tree = ast.parse(content)\n",
    "            \n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.Import):\n",
    "                for alias in node.names:\n",
    "                    if import_name in alias.name:\n",
    "                        return True\n",
    "            elif isinstance(node, ast.ImportFrom):\n",
    "                if node.module and import_name in node.module:\n",
    "                    return True\n",
    "                for alias in node.names:\n",
    "                    if import_name in alias.name:\n",
    "                        return True\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return False\n",
    "\n",
    "def check_class_in_file(file_path: Path, class_name: str) -> bool:\n",
    "    \"\"\"Check if a specific class exists in a Python file.\"\"\"\n",
    "    if not file_path.exists():\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            content = f.read()\n",
    "            tree = ast.parse(content)\n",
    "            \n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.ClassDef) and node.name == class_name:\n",
    "                return True\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return False\n",
    "\n",
    "def check_function_in_file(file_path: Path, function_name: str) -> bool:\n",
    "    \"\"\"Check if a specific function exists in a Python file.\"\"\"\n",
    "    if not file_path.exists():\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            content = f.read()\n",
    "            tree = ast.parse(content)\n",
    "            \n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.FunctionDef) and node.name == function_name:\n",
    "                return True\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return False\n",
    "\n",
    "def check_dependency_in_requirements(dependency: str) -> bool:\n",
    "    \"\"\"Check if a dependency exists in requirements.txt.\"\"\"\n",
    "    req_file = config.project_root / \"requirements.txt\"\n",
    "    if not req_file.exists():\n",
    "        return False\n",
    "    \n",
    "    with open(req_file, 'r') as f:\n",
    "        content = f.read().lower()\n",
    "        return dependency.lower() in content\n",
    "\n",
    "# Initialize API client\n",
    "api_client = APIClient(config)\n",
    "print(\"‚úÖ Helper functions and API client initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API is accessible at http://localhost:8000\n",
      "   Health check endpoint: http://localhost:8000/api/v1/health\n",
      "   Response: {'status': 'healthy', 'timestamp': '2025-08-06T20:07:42.132692+00:00', 'service': 'ViolentUTF API', 'version': '1.0.0', 'environment': 'development'}\n",
      "\n",
      "üîê Testing authentication...\n",
      "   Using API key authentication\n"
     ]
    }
   ],
   "source": [
    "# Test the API connection\n",
    "def test_api_connection():\n",
    "    \"\"\"Test if the API is accessible.\"\"\"\n",
    "    try:\n",
    "        # Include API key if available\n",
    "        headers = {}\n",
    "        if config.api_key:\n",
    "            headers['X-API-Key'] = config.api_key\n",
    "        \n",
    "        # Try different health check endpoints\n",
    "        health_endpoints = [\n",
    "            f\"{config.api_base_url}/health\",\n",
    "            f\"{config.api_base_url}/api/health\",\n",
    "            f\"{config.api_url}/health\",\n",
    "            f\"{config.api_base_url}/ping\"\n",
    "        ]\n",
    "        \n",
    "        for health_url in health_endpoints:\n",
    "            try:\n",
    "                response = requests.get(\n",
    "                    health_url,\n",
    "                    timeout=5,\n",
    "                    verify=False,\n",
    "                    headers=headers\n",
    "                )\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    print(f\"‚úÖ API is accessible at {config.api_base_url}\")\n",
    "                    print(f\"   Health check endpoint: {health_url}\")\n",
    "                    try:\n",
    "                        print(f\"   Response: {response.json()}\")\n",
    "                    except:\n",
    "                        print(f\"   Response: {response.text[:100]}\")\n",
    "                    return True\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        print(f\"‚ö†Ô∏è API health check failed at {config.api_base_url}\")\n",
    "        return False\n",
    "        \n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(f\"‚ùå Cannot connect to API at {config.api_base_url}\")\n",
    "        print(\"   Please ensure the ViolentUTF API is running\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Unexpected error: {e}\")\n",
    "        return False\n",
    "\n",
    "# Test connection\n",
    "api_available = test_api_connection()\n",
    "\n",
    "if not api_available:\n",
    "    print(\"\\n‚ö†Ô∏è IMPORTANT: The API is not accessible\")\n",
    "    print(\"This notebook will perform static code analysis for violations.\")\n",
    "    print(\"\\nTo start the API:\")\n",
    "    print(\"  cd /path/to/violentutf-api\")\n",
    "    print(\"  docker-compose up -d\")\n",
    "    print(\"\\nOr set the correct API URL:\")\n",
    "    print(\"  export VIOLENTUTF_API_URL=https://your-api-url.com\")\n",
    "else:\n",
    "    # Try to authenticate if API is available\n",
    "    print(\"\\nüîê Testing authentication...\")\n",
    "    if config.api_key:\n",
    "        print(\"   Using API key authentication\")\n",
    "        auth_success = True\n",
    "    else:\n",
    "        auth_success = api_client.authenticate()\n",
    "        if auth_success:\n",
    "            print(\"   ‚úÖ Authentication successful\")\n",
    "        else:\n",
    "            print(\"   ‚ùå Authentication failed - check credentials\")\n",
    "            print(\"   Tests requiring authentication will be skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. API Endpoints Missing (8 CRITICAL + 7 HIGH)\n",
    "\n",
    "Testing for missing critical API endpoints required by ADRs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Async Task Endpoints (Violation #1)...\n",
      "============================================================\n",
      "üìÅ Checking /Users/tamnguyen/Documents/GitHub/violentutf-api/app/api/routes.py...\n",
      "   Task endpoints mentioned: False\n",
      "   Scan endpoints mentioned: False\n",
      "\n",
      "üîç Testing API endpoints...\n",
      "   ‚úÖ Found: POST /api/v1/scans\n",
      "   ‚úÖ Found: GET /api/v1/tasks\n",
      "   ‚úÖ Found: GET /api/v1/tasks/{task_id}\n",
      "\n",
      "üìÅ Checking endpoint files...\n",
      "   tasks.py exists: False\n",
      "   scans.py exists: False\n",
      "\n",
      "‚úÖ Task endpoints appear to be implemented\n"
     ]
    }
   ],
   "source": [
    "def test_async_task_endpoints():\n",
    "    \"\"\"Test for missing async task endpoints (CRITICAL Violation #1).\"\"\"\n",
    "    \n",
    "    print(f\"\\n{Fore.YELLOW}Testing Async Task Endpoints (Violation #1)...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Check if endpoints exist in routes.py\n",
    "    routes_file = config.app_dir / \"api\" / \"routes.py\"\n",
    "    \n",
    "    print(f\"üìÅ Checking {routes_file}...\")\n",
    "    \n",
    "    if routes_file.exists():\n",
    "        with open(routes_file, 'r') as f:\n",
    "            content = f.read()\n",
    "            \n",
    "        # Check for task/scan endpoints\n",
    "        has_tasks = 'tasks' in content.lower()\n",
    "        has_scans = 'scans' in content.lower()\n",
    "        \n",
    "        print(f\"   Task endpoints mentioned: {has_tasks}\")\n",
    "        print(f\"   Scan endpoints mentioned: {has_scans}\")\n",
    "    else:\n",
    "        has_tasks = False\n",
    "        has_scans = False\n",
    "        print(f\"   {Fore.RED}‚ùå routes.py not found\")\n",
    "    \n",
    "    # Test API endpoints if available\n",
    "    if api_available:\n",
    "        print(f\"\\nüîç Testing API endpoints...\")\n",
    "        \n",
    "        required_endpoints = [\n",
    "            (\"/api/v1/scans\", \"POST\", \"Scan initiation\"),\n",
    "            (\"/api/v1/tasks\", \"GET\", \"Task listing\"),\n",
    "            (\"/api/v1/tasks/{task_id}\", \"GET\", \"Task status polling\")\n",
    "        ]\n",
    "        \n",
    "        missing_endpoints = []\n",
    "        \n",
    "        for endpoint, method, description in required_endpoints:\n",
    "            test_endpoint = endpoint.replace(\"{task_id}\", \"test-id\")\n",
    "            \n",
    "            try:\n",
    "                response = api_client.make_request(method, test_endpoint)\n",
    "                \n",
    "                if response.status_code == 404:\n",
    "                    print(f\"   {Fore.RED}‚ùå Missing: {method} {endpoint} - {description}\")\n",
    "                    missing_endpoints.append(endpoint)\n",
    "                else:\n",
    "                    print(f\"   {Fore.GREEN}‚úÖ Found: {method} {endpoint}\")\n",
    "            except:\n",
    "                print(f\"   {Fore.RED}‚ùå Error testing {endpoint}\")\n",
    "                missing_endpoints.append(endpoint)\n",
    "        \n",
    "        is_missing = len(missing_endpoints) > 0\n",
    "    else:\n",
    "        is_missing = not has_tasks and not has_scans\n",
    "        missing_endpoints = [\"Cannot test - API not available\"]\n",
    "    \n",
    "    # Check for task endpoint files\n",
    "    task_endpoint_file = config.app_dir / \"api\" / \"endpoints\" / \"tasks.py\"\n",
    "    scan_endpoint_file = config.app_dir / \"api\" / \"endpoints\" / \"scans.py\"\n",
    "    \n",
    "    print(f\"\\nüìÅ Checking endpoint files...\")\n",
    "    print(f\"   tasks.py exists: {task_endpoint_file.exists()}\")\n",
    "    print(f\"   scans.py exists: {scan_endpoint_file.exists()}\")\n",
    "    \n",
    "    violation = ArchitecturalViolation(\n",
    "        violation_id=\"CRIT-001\",\n",
    "        violation_type=ViolationType.API_ENDPOINT,\n",
    "        severity=Severity.CRITICAL,\n",
    "        title=\"No Async Task Endpoints\",\n",
    "        description=\"No async task endpoints implemented. ADR requires /api/v1/scans and /api/v1/tasks endpoints for HTTP Polling pattern but these are completely missing.\",\n",
    "        adr_violated=\"ADR-007 (Async Task Processing)\",\n",
    "        file_location=\"app/api/routes.py:1\",\n",
    "        expected_component=\"Task and scan endpoints with 202 Accepted responses\",\n",
    "        actual_state=\"No task or scan endpoints found\",\n",
    "        test_result=\"MISSING\" if is_missing else \"FOUND\",\n",
    "        evidence={\n",
    "            \"routes_file_exists\": routes_file.exists(),\n",
    "            \"has_task_mentions\": has_tasks,\n",
    "            \"has_scan_mentions\": has_scans,\n",
    "            \"missing_endpoints\": missing_endpoints,\n",
    "            \"task_endpoint_file_exists\": task_endpoint_file.exists(),\n",
    "            \"scan_endpoint_file_exists\": scan_endpoint_file.exists()\n",
    "        },\n",
    "        recommendation=\"Implement async task endpoints with 202 Accepted status and polling pattern as per ADR-007\",\n",
    "        verified=is_missing\n",
    "    )\n",
    "    \n",
    "    results.add_violation(violation)\n",
    "    \n",
    "    if is_missing:\n",
    "        print(f\"\\n{Fore.RED}‚ùå CRITICAL VIOLATION CONFIRMED\")\n",
    "        print(f\"   No async task endpoints implemented\")\n",
    "        print(f\"   Impact: Cannot execute long-running operations\")\n",
    "    else:\n",
    "        print(f\"\\n{Fore.GREEN}‚úÖ Task endpoints appear to be implemented\")\n",
    "\n",
    "# Run the test\n",
    "test_async_task_endpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing All Missing Critical Endpoints (Violations #2-8)...\n",
      "============================================================\n",
      "üìÅ Checking endpoint files in /Users/tamnguyen/Documents/GitHub/violentutf-api/app/api/endpoints...\n",
      "\n",
      "Existing endpoint files:\n",
      "   ‚úì mfa.py\n",
      "   ‚úì auth.py\n",
      "   ‚úì sessions.py\n",
      "   ‚úì upload.py\n",
      "   ‚úì users.py\n",
      "   ‚úì roles.py\n",
      "   ‚úì health.py\n",
      "   ‚úì __init__.py\n",
      "   ‚úì auth_validated.py\n",
      "   ‚úì mfa_policies.py\n",
      "   ‚úì health_auth.py\n",
      "   ‚úì api_keys.py\n",
      "   ‚úì audit_logs.py\n",
      "   ‚úì oauth.py\n",
      "\n",
      "[CRIT-002] Scan Initiation (scans.py):\n",
      "   File exists: False\n",
      "   ‚ùå CRITICAL: Missing\n",
      "\n",
      "[CRIT-003] Task Status Polling (tasks.py):\n",
      "   File exists: False\n",
      "   ‚ùå CRITICAL: Missing\n",
      "\n",
      "[CRIT-004] Report Generation (reports.py):\n",
      "   File exists: False\n",
      "   ‚ùå CRITICAL: Missing\n",
      "\n",
      "[CRIT-005] Orchestration (orchestration.py):\n",
      "   File exists: False\n",
      "   ‚ùå CRITICAL: Missing\n",
      "\n",
      "[CRIT-006] Template Rendering (templates.py):\n",
      "   File exists: False\n",
      "   ‚ùå CRITICAL: Missing\n",
      "\n",
      "[CRIT-007] Scoring Results (scoring.py):\n",
      "   File exists: False\n",
      "   ‚ùå CRITICAL: Missing\n",
      "\n",
      "[CRIT-008] Plugin Management (plugins.py):\n",
      "   File exists: False\n",
      "   ‚ùå CRITICAL: Missing\n",
      "\n",
      "\n",
      "Summary:\n",
      "   Critical endpoints missing: 7/7\n",
      "   Impact: Core functionality unavailable\n"
     ]
    }
   ],
   "source": [
    "def test_all_missing_endpoints():\n",
    "    \"\"\"Test for all missing critical endpoints (Violations #2-8).\"\"\"\n",
    "    \n",
    "    print(f\"\\n{Fore.YELLOW}Testing All Missing Critical Endpoints (Violations #2-8)...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Define all required endpoints\n",
    "    required_endpoints = [\n",
    "        (\"CRIT-002\", \"scans\", \"Scan Initiation\", \"ADR-007, ADR-F1-2\"),\n",
    "        (\"CRIT-003\", \"tasks\", \"Task Status Polling\", \"ADR-007\"),\n",
    "        (\"CRIT-004\", \"reports\", \"Report Generation\", \"ADR-F3-2\"),\n",
    "        (\"CRIT-005\", \"orchestration\", \"Orchestration\", \"ADR-F1-2\"),\n",
    "        (\"CRIT-006\", \"templates\", \"Template Rendering\", \"ADR-F1-1\"),\n",
    "        (\"CRIT-007\", \"scoring\", \"Scoring Results\", \"ADR-F3-1\"),\n",
    "        (\"CRIT-008\", \"plugins\", \"Plugin Management\", \"ADR-F1-3\")\n",
    "    ]\n",
    "    \n",
    "    endpoints_dir = config.app_dir / \"api\" / \"endpoints\"\n",
    "    \n",
    "    print(f\"üìÅ Checking endpoint files in {endpoints_dir}...\\n\")\n",
    "    \n",
    "    # List existing endpoint files\n",
    "    if endpoints_dir.exists():\n",
    "        existing_files = [f.name for f in endpoints_dir.glob(\"*.py\")]\n",
    "        print(f\"Existing endpoint files:\")\n",
    "        for file in existing_files:\n",
    "            print(f\"   ‚úì {file}\")\n",
    "        print()\n",
    "    else:\n",
    "        existing_files = []\n",
    "        print(f\"{Fore.RED}‚ùå Endpoints directory not found\")\n",
    "    \n",
    "    # Check each required endpoint\n",
    "    for violation_id, endpoint_name, description, adr in required_endpoints:\n",
    "        endpoint_file = endpoints_dir / f\"{endpoint_name}.py\"\n",
    "        exists = endpoint_file.exists()\n",
    "        \n",
    "        print(f\"[{violation_id}] {description} ({endpoint_name}.py):\")\n",
    "        print(f\"   File exists: {exists}\")\n",
    "        \n",
    "        # Test API if available\n",
    "        api_found = False\n",
    "        if api_available and api_client.token:\n",
    "            try:\n",
    "                response = api_client.make_request(\"GET\", f\"/{endpoint_name}\")\n",
    "                api_found = response.status_code != 404\n",
    "                print(f\"   API endpoint: {'Found' if api_found else 'Missing'} (status: {response.status_code})\")\n",
    "            except:\n",
    "                print(f\"   API endpoint: Error testing\")\n",
    "        \n",
    "        is_missing = not exists and not api_found\n",
    "        \n",
    "        violation = ArchitecturalViolation(\n",
    "            violation_id=violation_id,\n",
    "            violation_type=ViolationType.API_ENDPOINT,\n",
    "            severity=Severity.CRITICAL,\n",
    "            title=f\"No {description} Endpoints\",\n",
    "            description=f\"No {endpoint_name} endpoints exist. ADR requires these for {description.lower()}.\",\n",
    "            adr_violated=adr,\n",
    "            file_location=f\"app/api/endpoints/{endpoint_name}.py:Missing\",\n",
    "            expected_component=f\"{endpoint_name}.py with REST endpoints\",\n",
    "            actual_state=\"File and endpoints missing\",\n",
    "            test_result=\"MISSING\" if is_missing else \"FOUND\",\n",
    "            evidence={\n",
    "                \"file_exists\": exists,\n",
    "                \"api_endpoint_found\": api_found,\n",
    "                \"endpoint_name\": endpoint_name\n",
    "            },\n",
    "            recommendation=f\"Create {endpoint_name}.py with required endpoints per {adr}\",\n",
    "            verified=is_missing\n",
    "        )\n",
    "        \n",
    "        results.add_violation(violation)\n",
    "        \n",
    "        if is_missing:\n",
    "            print(f\"   {Fore.RED}‚ùå CRITICAL: Missing\")\n",
    "        else:\n",
    "            print(f\"   {Fore.GREEN}‚úÖ Found\")\n",
    "        print()\n",
    "    \n",
    "    # Summary\n",
    "    missing_count = sum(1 for v in results.violations if v.verified and v.violation_id in [f\"CRIT-00{i}\" for i in range(2, 9)])\n",
    "    \n",
    "    print(f\"\\n{Fore.CYAN}Summary:\")\n",
    "    print(f\"   Critical endpoints missing: {missing_count}/7\")\n",
    "    print(f\"   Impact: Core functionality unavailable\")\n",
    "\n",
    "# Run the test\n",
    "test_all_missing_endpoints()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dependencies & Infrastructure (4 CRITICAL + 5 HIGH)\n",
    "\n",
    "Testing for missing critical infrastructure components and dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Celery Task Queue Infrastructure (Violations #9-10)...\n",
      "============================================================\n",
      "üìã Checking dependencies...\n",
      "   celery: Missing - Task queue system\n",
      "   flower: Missing - Task monitoring\n",
      "   kombu: Missing - Message transport\n",
      "   billiard: Missing - Process pool\n",
      "\n",
      "üìÅ Checking Celery configuration...\n",
      "   celery_app.py exists: False\n",
      "   celery_config.py exists: False\n",
      "   tasks/ directory exists: False\n",
      "   workers/ directory exists: False\n",
      "\n",
      "üìã Checking configuration for Celery settings...\n",
      "   CELERY_BROKER_URL: Missing\n",
      "   CELERY_RESULT_BACKEND: Missing\n",
      "   TASK_TIME_LIMIT: Missing\n",
      "\n",
      "‚ùå CRITICAL VIOLATIONS CONFIRMED\n",
      "   Celery task queue not implemented\n",
      "   Impact: Cannot process background tasks\n"
     ]
    }
   ],
   "source": [
    "def test_celery_infrastructure():\n",
    "    \"\"\"Test for missing Celery task queue (CRITICAL Violations #9-10).\"\"\"\n",
    "    \n",
    "    print(f\"\\n{Fore.YELLOW}Testing Celery Task Queue Infrastructure (Violations #9-10)...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Check requirements.txt for Celery\n",
    "    print(f\"üìã Checking dependencies...\")\n",
    "    \n",
    "    required_deps = [\n",
    "        (\"celery\", \"Task queue system\"),\n",
    "        (\"flower\", \"Task monitoring\"),\n",
    "        (\"kombu\", \"Message transport\"),\n",
    "        (\"billiard\", \"Process pool\")\n",
    "    ]\n",
    "    \n",
    "    missing_deps = []\n",
    "    \n",
    "    for dep, description in required_deps:\n",
    "        exists = check_dependency_in_requirements(dep)\n",
    "        print(f\"   {dep}: {'Found' if exists else 'Missing'} - {description}\")\n",
    "        if not exists:\n",
    "            missing_deps.append(dep)\n",
    "    \n",
    "    # Check for Celery app configuration\n",
    "    print(f\"\\nüìÅ Checking Celery configuration...\")\n",
    "    \n",
    "    celery_app_file = config.app_dir / \"core\" / \"celery_app.py\"\n",
    "    celery_config_file = config.app_dir / \"core\" / \"celery_config.py\"\n",
    "    tasks_dir = config.app_dir / \"tasks\"\n",
    "    workers_dir = config.app_dir / \"workers\"\n",
    "    \n",
    "    print(f\"   celery_app.py exists: {celery_app_file.exists()}\")\n",
    "    print(f\"   celery_config.py exists: {celery_config_file.exists()}\")\n",
    "    print(f\"   tasks/ directory exists: {tasks_dir.exists()}\")\n",
    "    print(f\"   workers/ directory exists: {workers_dir.exists()}\")\n",
    "    \n",
    "    # Check configuration for Celery settings\n",
    "    print(f\"\\nüìã Checking configuration for Celery settings...\")\n",
    "    \n",
    "    config_file = config.app_dir / \"core\" / \"config.py\"\n",
    "    has_celery_config = False\n",
    "    \n",
    "    if config_file.exists():\n",
    "        with open(config_file, 'r') as f:\n",
    "            content = f.read()\n",
    "            \n",
    "        celery_settings = [\n",
    "            \"CELERY_BROKER_URL\",\n",
    "            \"CELERY_RESULT_BACKEND\",\n",
    "            \"TASK_TIME_LIMIT\"\n",
    "        ]\n",
    "        \n",
    "        for setting in celery_settings:\n",
    "            if setting in content:\n",
    "                has_celery_config = True\n",
    "                print(f\"   {setting}: Found\")\n",
    "            else:\n",
    "                print(f\"   {setting}: Missing\")\n",
    "    else:\n",
    "        print(f\"   {Fore.RED}‚ùå config.py not found\")\n",
    "    \n",
    "    # Violation #9\n",
    "    violation_9 = ArchitecturalViolation(\n",
    "        violation_id=\"CRIT-009\",\n",
    "        violation_type=ViolationType.INFRASTRUCTURE,\n",
    "        severity=Severity.CRITICAL,\n",
    "        title=\"Celery Task Queue Missing\",\n",
    "        description=\"Redis dependency exists but no Celery task queue system implemented. ADR mandates Celery for backend task processing.\",\n",
    "        adr_violated=\"ADR-007 (Async Processing)\",\n",
    "        file_location=\"requirements.txt:28\",\n",
    "        expected_component=\"Celery with Redis broker\",\n",
    "        actual_state=\"No Celery dependencies or configuration\",\n",
    "        test_result=\"MISSING\" if missing_deps else \"PARTIAL\",\n",
    "        evidence={\n",
    "            \"missing_dependencies\": missing_deps,\n",
    "            \"celery_app_exists\": celery_app_file.exists(),\n",
    "            \"has_celery_config\": has_celery_config\n",
    "        },\n",
    "        recommendation=\"Install Celery dependencies and create celery_app.py configuration\",\n",
    "        verified=len(missing_deps) > 0\n",
    "    )\n",
    "    \n",
    "    results.add_violation(violation_9)\n",
    "    \n",
    "    # Violation #10\n",
    "    infrastructure_missing = not celery_app_file.exists() and not tasks_dir.exists()\n",
    "    \n",
    "    violation_10 = ArchitecturalViolation(\n",
    "        violation_id=\"CRIT-010\",\n",
    "        violation_type=ViolationType.INFRASTRUCTURE,\n",
    "        severity=Severity.CRITICAL,\n",
    "        title=\"Task Infrastructure Missing\",\n",
    "        description=\"Missing async task processing infrastructure - no Celery/Redis task queue implementation despite ADR requirements.\",\n",
    "        adr_violated=\"ADR-007\",\n",
    "        file_location=\"app/:0\",\n",
    "        expected_component=\"Complete task processing infrastructure\",\n",
    "        actual_state=\"No task infrastructure found\",\n",
    "        test_result=\"MISSING\" if infrastructure_missing else \"FOUND\",\n",
    "        evidence={\n",
    "            \"celery_app_exists\": celery_app_file.exists(),\n",
    "            \"tasks_dir_exists\": tasks_dir.exists(),\n",
    "            \"workers_dir_exists\": workers_dir.exists()\n",
    "        },\n",
    "        recommendation=\"Create app/core/celery_app.py and app/tasks/ directory with task definitions\",\n",
    "        verified=infrastructure_missing\n",
    "    )\n",
    "    \n",
    "    results.add_violation(violation_10)\n",
    "    \n",
    "    if missing_deps or infrastructure_missing:\n",
    "        print(f\"\\n{Fore.RED}‚ùå CRITICAL VIOLATIONS CONFIRMED\")\n",
    "        print(f\"   Celery task queue not implemented\")\n",
    "        print(f\"   Impact: Cannot process background tasks\")\n",
    "    else:\n",
    "        print(f\"\\n{Fore.GREEN}‚úÖ Task infrastructure appears configured\")\n",
    "\n",
    "# Run the test\n",
    "test_celery_infrastructure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Docker Infrastructure (Violation #12)...\n",
      "============================================================\n",
      "üìÅ Checking Docker configuration...\n",
      "   docker-compose.yml exists: True\n",
      "\n",
      "   Services defined:\n",
      "      ‚Ä¢ api\n",
      "      ‚Ä¢ db\n",
      "      ‚Ä¢ redis\n",
      "      ‚Ä¢ nginx\n",
      "\n",
      "   Required services check:\n",
      "      Worker container: Missing\n",
      "      Redis container: Found\n",
      "      Celery beat: Missing\n",
      "\n",
      "   Dockerfile.worker exists: False\n",
      "\n",
      "‚ùå CRITICAL VIOLATION CONFIRMED\n",
      "   Docker infrastructure incomplete for task processing\n",
      "   Impact: Cannot deploy task workers\n"
     ]
    }
   ],
   "source": [
    "def test_docker_infrastructure():\n",
    "    \"\"\"Test for Docker infrastructure completeness (CRITICAL Violation #12).\"\"\"\n",
    "    \n",
    "    print(f\"\\n{Fore.YELLOW}Testing Docker Infrastructure (Violation #12)...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    docker_compose_file = config.project_root / \"docker-compose.yml\"\n",
    "    \n",
    "    print(f\"üìÅ Checking Docker configuration...\")\n",
    "    print(f\"   docker-compose.yml exists: {docker_compose_file.exists()}\")\n",
    "    \n",
    "    has_worker_container = False\n",
    "    has_redis_container = False\n",
    "    has_celery_beat = False\n",
    "    \n",
    "    if docker_compose_file.exists():\n",
    "        with open(docker_compose_file, 'r') as f:\n",
    "            try:\n",
    "                docker_config = yaml.safe_load(f)\n",
    "                services = docker_config.get('services', {})\n",
    "                \n",
    "                print(f\"\\n   Services defined:\")\n",
    "                for service_name in services.keys():\n",
    "                    print(f\"      ‚Ä¢ {service_name}\")\n",
    "                    \n",
    "                    if 'worker' in service_name.lower():\n",
    "                        has_worker_container = True\n",
    "                    if 'redis' in service_name.lower():\n",
    "                        has_redis_container = True\n",
    "                    if 'beat' in service_name.lower() or 'scheduler' in service_name.lower():\n",
    "                        has_celery_beat = True\n",
    "                \n",
    "                print(f\"\\n   Required services check:\")\n",
    "                print(f\"      Worker container: {'Found' if has_worker_container else 'Missing'}\")\n",
    "                print(f\"      Redis container: {'Found' if has_redis_container else 'Missing'}\")\n",
    "                print(f\"      Celery beat: {'Found' if has_celery_beat else 'Missing'}\")\n",
    "                \n",
    "            except yaml.YAMLError as e:\n",
    "                print(f\"   {Fore.RED}‚ùå Error parsing docker-compose.yml: {e}\")\n",
    "    else:\n",
    "        print(f\"   {Fore.RED}‚ùå docker-compose.yml not found\")\n",
    "    \n",
    "    # Check for Dockerfile.worker\n",
    "    dockerfile_worker = config.project_root / \"Dockerfile.worker\"\n",
    "    print(f\"\\n   Dockerfile.worker exists: {dockerfile_worker.exists()}\")\n",
    "    \n",
    "    violation = ArchitecturalViolation(\n",
    "        violation_id=\"CRIT-012\",\n",
    "        violation_type=ViolationType.INFRASTRUCTURE,\n",
    "        severity=Severity.CRITICAL,\n",
    "        title=\"Docker Infrastructure Incomplete\",\n",
    "        description=\"No worker container definitions for task processing.\",\n",
    "        adr_violated=\"ADR-007\",\n",
    "        file_location=\"docker-compose.yml:Missing\",\n",
    "        expected_component=\"Worker containers for Celery tasks\",\n",
    "        actual_state=\"No worker containers defined\",\n",
    "        test_result=\"INCOMPLETE\" if not has_worker_container else \"COMPLETE\",\n",
    "        evidence={\n",
    "            \"docker_compose_exists\": docker_compose_file.exists(),\n",
    "            \"has_worker_container\": has_worker_container,\n",
    "            \"has_redis_container\": has_redis_container,\n",
    "            \"has_celery_beat\": has_celery_beat,\n",
    "            \"dockerfile_worker_exists\": dockerfile_worker.exists()\n",
    "        },\n",
    "        recommendation=\"Add worker service to docker-compose.yml with Celery worker command\",\n",
    "        verified=not has_worker_container\n",
    "    )\n",
    "    \n",
    "    results.add_violation(violation)\n",
    "    \n",
    "    if not has_worker_container:\n",
    "        print(f\"\\n{Fore.RED}‚ùå CRITICAL VIOLATION CONFIRMED\")\n",
    "        print(f\"   Docker infrastructure incomplete for task processing\")\n",
    "        print(f\"   Impact: Cannot deploy task workers\")\n",
    "    else:\n",
    "        print(f\"\\n{Fore.GREEN}‚úÖ Docker infrastructure appears complete\")\n",
    "\n",
    "# Run the test\n",
    "test_docker_infrastructure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Models & Database (3 CRITICAL + 8 HIGH)\n",
    "\n",
    "Testing for missing critical data models and database components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_task_model():\n",
    "    \"\"\"Test for missing Task model (CRITICAL Violation #13).\"\"\"\n",
    "    \n",
    "    print(f\"\\n{Fore.YELLOW}Testing Task Model (Violation #13)...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    models_dir = config.app_dir / \"models\"\n",
    "    task_model_file = models_dir / \"task.py\"\n",
    "    models_init_file = models_dir / \"__init__.py\"\n",
    "    \n",
    "    print(f\"üìÅ Checking Task model...\")\n",
    "    print(f\"   task.py exists: {task_model_file.exists()}\")\n",
    "    \n",
    "    # Check if Task is imported in __init__.py\n",
    "    has_task_import = False\n",
    "    if models_init_file.exists():\n",
    "        with open(models_init_file, 'r') as f:\n",
    "            content = f.read()\n",
    "            if 'Task' in content or 'task' in content.lower():\n",
    "                has_task_import = True\n",
    "        print(f\"   Task imported in __init__.py: {has_task_import}\")\n",
    "    \n",
    "    # Check for TaskStatus enum\n",
    "    has_task_status = False\n",
    "    if task_model_file.exists():\n",
    "        has_task_status = check_class_in_file(task_model_file, \"TaskStatus\")\n",
    "        print(f\"   TaskStatus enum exists: {has_task_status}\")\n",
    "        \n",
    "        # Check for required fields\n",
    "        with open(task_model_file, 'r') as f:\n",
    "            content = f.read()\n",
    "            \n",
    "        required_fields = [\n",
    "            \"task_type\",\n",
    "            \"status\",\n",
    "            \"input_data\",\n",
    "            \"result_data\",\n",
    "            \"progress\",\n",
    "            \"webhook_url\"\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\n   Required fields check:\")\n",
    "        for field in required_fields:\n",
    "            if field in content:\n",
    "                print(f\"      ‚úì {field}\")\n",
    "            else:\n",
    "                print(f\"      ‚úó {field}\")\n",
    "    \n",
    "    # Check for related models\n",
    "    print(f\"\\nüìÅ Checking related models...\")\n",
    "    \n",
    "    related_models = [\n",
    "        (\"red_team_session.py\", \"RedTeamSession\"),\n",
    "        (\"scoring_result.py\", \"ScoringResult\"),\n",
    "        (\"orchestration_job.py\", \"OrchestrationJob\"),\n",
    "        (\"generator.py\", \"Generator\"),\n",
    "        (\"evidence.py\", \"Evidence\")\n",
    "    ]\n",
    "    \n",
    "    missing_models = []\n",
    "    for filename, model_name in related_models:\n",
    "        model_file = models_dir / filename\n",
    "        exists = model_file.exists()\n",
    "        print(f\"   {model_name}: {'Found' if exists else 'Missing'}\")\n",
    "        if not exists:\n",
    "            missing_models.append(model_name)\n",
    "    \n",
    "    violation = ArchitecturalViolation(\n",
    "        violation_id=\"CRIT-013\",\n",
    "        violation_type=ViolationType.DATA_MODEL,\n",
    "        severity=Severity.CRITICAL,\n",
    "        title=\"Task Model Missing\",\n",
    "        description=\"No Task model exists for tracking async jobs. ADR requires task records in database with PENDING/RUNNING/SUCCESS states.\",\n",
    "        adr_violated=\"ADR-007\",\n",
    "        file_location=\"app/models/__init__.py:20\",\n",
    "        expected_component=\"Task model with status tracking\",\n",
    "        actual_state=\"Task model not found\",\n",
    "        test_result=\"MISSING\" if not task_model_file.exists() else \"FOUND\",\n",
    "        evidence={\n",
    "            \"task_model_exists\": task_model_file.exists(),\n",
    "            \"has_task_import\": has_task_import,\n",
    "            \"has_task_status_enum\": has_task_status,\n",
    "            \"missing_related_models\": missing_models\n",
    "        },\n",
    "        recommendation=\"Create app/models/task.py with TaskStatus enum and required fields per ADR-007\",\n",
    "        verified=not task_model_file.exists()\n",
    "    )\n",
    "    \n",
    "    results.add_violation(violation)\n",
    "    \n",
    "    if not task_model_file.exists():\n",
    "        print(f\"\\n{Fore.RED}‚ùå CRITICAL VIOLATION CONFIRMED\")\n",
    "        print(f\"   Task model missing - cannot track async operations\")\n",
    "        print(f\"   Impact: No persistence for background tasks\")\n",
    "    else:\n",
    "        print(f\"\\n{Fore.GREEN}‚úÖ Task model found\")\n",
    "\n",
    "# Run the test\n",
    "test_task_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_error_model_compliance():\n",
    "    \"\"\"Test for RFC 7807 compliance in error model (CRITICAL Violation #14).\"\"\"\n",
    "    \n",
    "    print(f\"\\n{Fore.YELLOW}Testing Error Model RFC 7807 Compliance (Violation #14)...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    errors_file = config.app_dir / \"core\" / \"errors.py\"\n",
    "    \n",
    "    print(f\"üìÅ Checking error handling...\")\n",
    "    print(f\"   errors.py exists: {errors_file.exists()}\")\n",
    "    \n",
    "    is_rfc7807_compliant = False\n",
    "    has_problem_json = False\n",
    "    \n",
    "    if errors_file.exists():\n",
    "        with open(errors_file, 'r') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Check for RFC 7807 fields\n",
    "        rfc7807_fields = [\n",
    "            \"type\",\n",
    "            \"title\",\n",
    "            \"status\",\n",
    "            \"detail\",\n",
    "            \"instance\"\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\n   RFC 7807 field check:\")\n",
    "        fields_found = 0\n",
    "        for field in rfc7807_fields:\n",
    "            # Look for field definitions\n",
    "            if f'{field}:' in content or f'{field} =' in content:\n",
    "                print(f\"      ‚úì {field}\")\n",
    "                fields_found += 1\n",
    "            else:\n",
    "                print(f\"      ‚úó {field}\")\n",
    "        \n",
    "        is_rfc7807_compliant = fields_found >= 4\n",
    "        \n",
    "        # Check for problem+json content type\n",
    "        has_problem_json = 'application/problem+json' in content\n",
    "        print(f\"\\n   Uses 'application/problem+json': {has_problem_json}\")\n",
    "        \n",
    "        # Check current error model\n",
    "        has_error_detail = check_class_in_file(errors_file, \"ErrorDetail\")\n",
    "        print(f\"   Has ErrorDetail class: {has_error_detail}\")\n",
    "    \n",
    "    # Test API error responses if available\n",
    "    if api_available:\n",
    "        print(f\"\\nüîç Testing API error response format...\")\n",
    "        try:\n",
    "            # Trigger a 404 error\n",
    "            response = api_client.make_request(\"GET\", \"/nonexistent\")\n",
    "            \n",
    "            if response.status_code == 404:\n",
    "                content_type = response.headers.get('Content-Type', '')\n",
    "                print(f\"   Content-Type: {content_type}\")\n",
    "                \n",
    "                if 'application/problem+json' in content_type:\n",
    "                    print(f\"   {Fore.GREEN}‚úÖ Uses RFC 7807 content type\")\n",
    "                    has_problem_json = True\n",
    "                else:\n",
    "                    print(f\"   {Fore.YELLOW}‚ö†Ô∏è Not using RFC 7807 content type\")\n",
    "                \n",
    "                # Check response structure\n",
    "                try:\n",
    "                    error_data = response.json()\n",
    "                    print(f\"\\n   Response fields: {list(error_data.keys())}\")\n",
    "                except:\n",
    "                    pass\n",
    "        except:\n",
    "            print(f\"   Could not test API error responses\")\n",
    "    \n",
    "    violation = ArchitecturalViolation(\n",
    "        violation_id=\"CRIT-014\",\n",
    "        violation_type=ViolationType.ERROR_HANDLING,\n",
    "        severity=Severity.CRITICAL,\n",
    "        title=\"Error Model Non-Compliant\",\n",
    "        description=\"ErrorDetail model uses custom format instead of RFC 7807 structure.\",\n",
    "        adr_violated=\"ADR-009 (Error Responses)\",\n",
    "        file_location=\"app/core/errors.py:15\",\n",
    "        expected_component=\"RFC 7807 compliant error model\",\n",
    "        actual_state=\"Custom error format\",\n",
    "        test_result=\"NON_COMPLIANT\" if not is_rfc7807_compliant else \"COMPLIANT\",\n",
    "        evidence={\n",
    "            \"errors_file_exists\": errors_file.exists(),\n",
    "            \"is_rfc7807_compliant\": is_rfc7807_compliant,\n",
    "            \"has_problem_json_content_type\": has_problem_json\n",
    "        },\n",
    "        recommendation=\"Implement RFC 7807 error model with application/problem+json content type\",\n",
    "        verified=not is_rfc7807_compliant\n",
    "    )\n",
    "    \n",
    "    results.add_violation(violation)\n",
    "    \n",
    "    if not is_rfc7807_compliant:\n",
    "        print(f\"\\n{Fore.RED}‚ùå CRITICAL VIOLATION CONFIRMED\")\n",
    "        print(f\"   Error model not RFC 7807 compliant\")\n",
    "        print(f\"   Impact: Non-standard error responses\")\n",
    "    else:\n",
    "        print(f\"\\n{Fore.GREEN}‚úÖ Error model appears RFC 7807 compliant\")\n",
    "\n",
    "# Run the test\n",
    "test_error_model_compliance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_document_storage():\n",
    "    \"\"\"Test for document storage configuration (CRITICAL Violation #15).\"\"\"\n",
    "    \n",
    "    print(f\"\\n{Fore.YELLOW}Testing Document Storage Configuration (Violation #15)...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    config_file = config.app_dir / \"core\" / \"config.py\"\n",
    "    \n",
    "    print(f\"üìÅ Checking configuration...\")\n",
    "    \n",
    "    has_mongodb = False\n",
    "    has_dynamodb = False\n",
    "    has_blob_storage = False\n",
    "    \n",
    "    if config_file.exists():\n",
    "        with open(config_file, 'r') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Check for document storage configurations\n",
    "        storage_configs = [\n",
    "            (\"MONGODB_URL\", \"MongoDB\"),\n",
    "            (\"DYNAMODB_\", \"DynamoDB\"),\n",
    "            (\"S3_BUCKET\", \"S3/Blob Storage\"),\n",
    "            (\"AZURE_STORAGE\", \"Azure Blob\"),\n",
    "            (\"GCS_BUCKET\", \"Google Cloud Storage\")\n",
    "        ]\n",
    "        \n",
    "        print(f\"   Document storage configurations:\")\n",
    "        for config_key, storage_type in storage_configs:\n",
    "            if config_key in content:\n",
    "                print(f\"      ‚úì {storage_type}\")\n",
    "                if \"MONGO\" in config_key:\n",
    "                    has_mongodb = True\n",
    "                elif \"DYNAMO\" in config_key:\n",
    "                    has_dynamodb = True\n",
    "                elif \"S3\" in config_key or \"AZURE\" in config_key or \"GCS\" in config_key:\n",
    "                    has_blob_storage = True\n",
    "            else:\n",
    "                print(f\"      ‚úó {storage_type}\")\n",
    "        \n",
    "        # Check for PostgreSQL (should exist)\n",
    "        has_postgres = \"DATABASE_URL\" in content or \"POSTGRES\" in content\n",
    "        print(f\"\\n   PostgreSQL configured: {has_postgres}\")\n",
    "    else:\n",
    "        print(f\"   {Fore.RED}‚ùå config.py not found\")\n",
    "    \n",
    "    # Check for document store service\n",
    "    document_store_file = config.app_dir / \"services\" / \"document_store.py\"\n",
    "    print(f\"\\n   Document store service exists: {document_store_file.exists()}\")\n",
    "    \n",
    "    violation = ArchitecturalViolation(\n",
    "        violation_id=\"CRIT-015\",\n",
    "        violation_type=ViolationType.CONFIGURATION,\n",
    "        severity=Severity.CRITICAL,\n",
    "        title=\"Document Storage Missing\",\n",
    "        description=\"Only PostgreSQL configured. Missing MongoDB/DynamoDB for session_evidence document storage.\",\n",
    "        adr_violated=\"ADR-F3-1\",\n",
    "        file_location=\"app/core/config.py:59\",\n",
    "        expected_component=\"Document storage configuration (MongoDB/DynamoDB)\",\n",
    "        actual_state=\"Only relational database configured\",\n",
    "        test_result=\"MISSING\" if not (has_mongodb or has_dynamodb) else \"CONFIGURED\",\n",
    "        evidence={\n",
    "            \"has_mongodb\": has_mongodb,\n",
    "            \"has_dynamodb\": has_dynamodb,\n",
    "            \"has_blob_storage\": has_blob_storage,\n",
    "            \"document_store_exists\": document_store_file.exists()\n",
    "        },\n",
    "        recommendation=\"Add MongoDB or DynamoDB configuration for document storage per ADR-F3-1\",\n",
    "        verified=not (has_mongodb or has_dynamodb)\n",
    "    )\n",
    "    \n",
    "    results.add_violation(violation)\n",
    "    \n",
    "    if not (has_mongodb or has_dynamodb):\n",
    "        print(f\"\\n{Fore.RED}‚ùå CRITICAL VIOLATION CONFIRMED\")\n",
    "        print(f\"   No document storage configured\")\n",
    "        print(f\"   Impact: Cannot store session evidence documents\")\n",
    "    else:\n",
    "        print(f\"\\n{Fore.GREEN}‚úÖ Document storage configured\")\n",
    "\n",
    "# Run the test\n",
    "test_document_storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plugin Architecture (3 CRITICAL + 2 HIGH)\n",
    "\n",
    "Testing for missing plugin architecture components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_plugin_architecture():\n",
    "    \"\"\"Test for plugin architecture implementation (CRITICAL Violations #16-18).\"\"\"\n",
    "    \n",
    "    print(f\"\\n{Fore.YELLOW}Testing Plugin Architecture (Violations #16-18)...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    plugins_dir = config.app_dir / \"plugins\"\n",
    "    core_plugins_dir = config.app_dir / \"core\" / \"plugins\"\n",
    "    \n",
    "    print(f\"üìÅ Checking plugin directories...\")\n",
    "    print(f\"   app/plugins/ exists: {plugins_dir.exists()}\")\n",
    "    print(f\"   app/core/plugins/ exists: {core_plugins_dir.exists()}\")\n",
    "    \n",
    "    # Violation #16: ProviderPlugin Interface\n",
    "    print(f\"\\n[CRIT-016] Checking ProviderPlugin interface...\")\n",
    "    \n",
    "    provider_interface_file = core_plugins_dir / \"provider_interface.py\"\n",
    "    has_provider_interface = False\n",
    "    \n",
    "    if provider_interface_file.exists():\n",
    "        has_provider_interface = check_class_in_file(provider_interface_file, \"ProviderPlugin\")\n",
    "        print(f\"   ProviderPlugin class exists: {has_provider_interface}\")\n",
    "        \n",
    "        # Check for required methods\n",
    "        with open(provider_interface_file, 'r') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        required_methods = [\n",
    "            \"plugin_name\",\n",
    "            \"supported_models\",\n",
    "            \"send_chat_completion\",\n",
    "            \"list_available_models\",\n",
    "            \"validate_credentials\"\n",
    "        ]\n",
    "        \n",
    "        print(f\"   Required methods:\")\n",
    "        for method in required_methods:\n",
    "            if method in content:\n",
    "                print(f\"      ‚úì {method}\")\n",
    "            else:\n",
    "                print(f\"      ‚úó {method}\")\n",
    "    else:\n",
    "        print(f\"   {Fore.RED}‚ùå provider_interface.py not found\")\n",
    "    \n",
    "    violation_16 = ArchitecturalViolation(\n",
    "        violation_id=\"CRIT-016\",\n",
    "        violation_type=ViolationType.PLUGIN,\n",
    "        severity=Severity.CRITICAL,\n",
    "        title=\"ProviderPlugin Interface Missing\",\n",
    "        description=\"Missing ProviderPlugin abstract interface implementation. No abstract base class defining required plugin methods.\",\n",
    "        adr_violated=\"ADR-F1-3 (Plugin Architecture)\",\n",
    "        file_location=\"app/main.py:1\",\n",
    "        expected_component=\"ProviderPlugin abstract base class\",\n",
    "        actual_state=\"No plugin interface found\",\n",
    "        test_result=\"MISSING\" if not has_provider_interface else \"FOUND\",\n",
    "        evidence={\n",
    "            \"provider_interface_exists\": provider_interface_file.exists(),\n",
    "            \"has_provider_plugin_class\": has_provider_interface\n",
    "        },\n",
    "        recommendation=\"Create app/core/plugins/provider_interface.py with ProviderPlugin ABC\",\n",
    "        verified=not has_provider_interface\n",
    "    )\n",
    "    \n",
    "    results.add_violation(violation_16)\n",
    "    \n",
    "    # Violation #17: Plugin Implementations\n",
    "    print(f\"\\n[CRIT-017] Checking plugin implementations...\")\n",
    "    \n",
    "    expected_plugins = [\n",
    "        (\"openai_plugin.py\", \"OpenAI\"),\n",
    "        (\"anthropic_plugin.py\", \"Anthropic\"),\n",
    "        (\"ollama_plugin.py\", \"Ollama\")\n",
    "    ]\n",
    "    \n",
    "    implemented_plugins = []\n",
    "    \n",
    "    if plugins_dir.exists():\n",
    "        for filename, provider in expected_plugins:\n",
    "            plugin_file = plugins_dir / filename\n",
    "            if plugin_file.exists():\n",
    "                implemented_plugins.append(provider)\n",
    "                print(f\"   {provider} plugin: Found\")\n",
    "            else:\n",
    "                print(f\"   {provider} plugin: Missing\")\n",
    "    else:\n",
    "        for _, provider in expected_plugins:\n",
    "            print(f\"   {provider} plugin: Missing (no plugins directory)\")\n",
    "    \n",
    "    violation_17 = ArchitecturalViolation(\n",
    "        violation_id=\"CRIT-017\",\n",
    "        violation_type=ViolationType.PLUGIN,\n",
    "        severity=Severity.CRITICAL,\n",
    "        title=\"No Plugin Implementations\",\n",
    "        description=\"No concrete plugin implementations for OpenAI, Anthropic, or Ollama as mentioned in ADR.\",\n",
    "        adr_violated=\"ADR-F1-3\",\n",
    "        file_location=\"app/:1\",\n",
    "        expected_component=\"Concrete plugin implementations\",\n",
    "        actual_state=\"No plugin implementations found\",\n",
    "        test_result=\"MISSING\" if len(implemented_plugins) == 0 else \"PARTIAL\",\n",
    "        evidence={\n",
    "            \"plugins_dir_exists\": plugins_dir.exists(),\n",
    "            \"implemented_plugins\": implemented_plugins\n",
    "        },\n",
    "        recommendation=\"Create plugin implementations for AI providers in app/plugins/\",\n",
    "        verified=len(implemented_plugins) == 0\n",
    "    )\n",
    "    \n",
    "    results.add_violation(violation_17)\n",
    "    \n",
    "    # Violation #18: ScorerPlugin\n",
    "    print(f\"\\n[CRIT-018] Checking ScorerPlugin interface...\")\n",
    "    \n",
    "    scorer_interface_file = core_plugins_dir / \"scorer_interface.py\"\n",
    "    has_scorer_interface = False\n",
    "    \n",
    "    if scorer_interface_file.exists():\n",
    "        has_scorer_interface = check_class_in_file(scorer_interface_file, \"ScorerPlugin\")\n",
    "        print(f\"   ScorerPlugin class exists: {has_scorer_interface}\")\n",
    "    else:\n",
    "        print(f\"   {Fore.RED}‚ùå scorer_interface.py not found\")\n",
    "    \n",
    "    violation_18 = ArchitecturalViolation(\n",
    "        violation_id=\"CRIT-018\",\n",
    "        violation_type=ViolationType.PLUGIN,\n",
    "        severity=Severity.CRITICAL,\n",
    "        title=\"ScorerPlugin Missing\",\n",
    "        description=\"Missing ScorerPlugin abstract base class with SCORER_TYPE, SCORER_NAME, and score() method.\",\n",
    "        adr_violated=\"ADR-F3-1\",\n",
    "        file_location=\"app/:0\",\n",
    "        expected_component=\"ScorerPlugin abstract base class\",\n",
    "        actual_state=\"No scorer plugin interface found\",\n",
    "        test_result=\"MISSING\" if not has_scorer_interface else \"FOUND\",\n",
    "        evidence={\n",
    "            \"scorer_interface_exists\": scorer_interface_file.exists(),\n",
    "            \"has_scorer_plugin_class\": has_scorer_interface\n",
    "        },\n",
    "        recommendation=\"Create app/core/plugins/scorer_interface.py with ScorerPlugin ABC\",\n",
    "        verified=not has_scorer_interface\n",
    "    )\n",
    "    \n",
    "    results.add_violation(violation_18)\n",
    "    \n",
    "    if not has_provider_interface and len(implemented_plugins) == 0:\n",
    "        print(f\"\\n{Fore.RED}‚ùå CRITICAL VIOLATIONS CONFIRMED\")\n",
    "        print(f\"   Plugin architecture completely missing\")\n",
    "        print(f\"   Impact: Cannot integrate AI providers\")\n",
    "    else:\n",
    "        print(f\"\\n{Fore.GREEN}‚úÖ Some plugin architecture components found\")\n",
    "\n",
    "# Run the test\n",
    "test_plugin_architecture()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Configuration & Other (4 CRITICAL)\n",
    "\n",
    "Testing for configuration and other critical architectural violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_blob_storage_configuration():\n",
    "    \"\"\"Test for blob storage configuration (CRITICAL Violation #19).\"\"\"\n",
    "    \n",
    "    print(f\"\\n{Fore.YELLOW}Testing Blob Storage Configuration (Violation #19)...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    config_file = config.app_dir / \"core\" / \"config.py\"\n",
    "    \n",
    "    print(f\"üìÅ Checking blob storage configuration...\")\n",
    "    \n",
    "    has_s3 = False\n",
    "    has_azure = False\n",
    "    has_gcs = False\n",
    "    \n",
    "    if config_file.exists():\n",
    "        with open(config_file, 'r') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Check for blob storage settings\n",
    "        blob_configs = [\n",
    "            (\"S3_BUCKET_NAME\", \"AWS S3\"),\n",
    "            (\"S3_ACCESS_KEY_ID\", \"AWS Credentials\"),\n",
    "            (\"AWS_ACCESS_KEY_ID\", \"AWS Credentials\"),\n",
    "            (\"AZURE_STORAGE_ACCOUNT\", \"Azure Blob Storage\"),\n",
    "            (\"GCS_BUCKET_NAME\", \"Google Cloud Storage\")\n",
    "        ]\n",
    "        \n",
    "        print(f\"   Blob storage settings:\")\n",
    "        for config_key, storage_type in blob_configs:\n",
    "            if config_key in content:\n",
    "                print(f\"      ‚úì {storage_type}: {config_key}\")\n",
    "                if \"S3\" in config_key or \"AWS\" in config_key:\n",
    "                    has_s3 = True\n",
    "                elif \"AZURE\" in config_key:\n",
    "                    has_azure = True\n",
    "                elif \"GCS\" in config_key:\n",
    "                    has_gcs = True\n",
    "            else:\n",
    "                print(f\"      ‚úó {storage_type}: {config_key}\")\n",
    "    \n",
    "    has_blob_storage = has_s3 or has_azure or has_gcs\n",
    "    \n",
    "    violation = ArchitecturalViolation(\n",
    "        violation_id=\"CRIT-019\",\n",
    "        violation_type=ViolationType.CONFIGURATION,\n",
    "        severity=Severity.CRITICAL,\n",
    "        title=\"Blob Storage Not Configured\",\n",
    "        description=\"No S3/blob storage configuration found. ADR requires blob storage for cost-effective archival.\",\n",
    "        adr_violated=\"ADR-F2-2 (Data Storage)\",\n",
    "        file_location=\"app/core/config.py:60\",\n",
    "        expected_component=\"Blob storage configuration (S3/Azure/GCS)\",\n",
    "        actual_state=\"No blob storage configured\",\n",
    "        test_result=\"MISSING\" if not has_blob_storage else \"CONFIGURED\",\n",
    "        evidence={\n",
    "            \"has_s3\": has_s3,\n",
    "            \"has_azure\": has_azure,\n",
    "            \"has_gcs\": has_gcs\n",
    "        },\n",
    "        recommendation=\"Add S3 or other blob storage configuration for archival per ADR-F2-2\",\n",
    "        verified=not has_blob_storage\n",
    "    )\n",
    "    \n",
    "    results.add_violation(violation)\n",
    "    \n",
    "    if not has_blob_storage:\n",
    "        print(f\"\\n{Fore.RED}‚ùå CRITICAL VIOLATION CONFIRMED\")\n",
    "        print(f\"   No blob storage configured\")\n",
    "        print(f\"   Impact: Cannot archive data cost-effectively\")\n",
    "    else:\n",
    "        print(f\"\\n{Fore.GREEN}‚úÖ Blob storage configured\")\n",
    "\n",
    "# Run the test\n",
    "test_blob_storage_configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_task_service_layer():\n",
    "    \"\"\"Test for task service layer (CRITICAL Violation #20).\"\"\"\n",
    "    \n",
    "    print(f\"\\n{Fore.YELLOW}Testing Task Service Layer (Violation #20)...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    services_dir = config.app_dir / \"services\"\n",
    "    task_service_file = services_dir / \"task_service.py\"\n",
    "    scan_service_file = services_dir / \"scan_service.py\"\n",
    "    orchestration_service_file = services_dir / \"orchestration_service.py\"\n",
    "    \n",
    "    print(f\"üìÅ Checking service layer...\")\n",
    "    print(f\"   task_service.py exists: {task_service_file.exists()}\")\n",
    "    print(f\"   scan_service.py exists: {scan_service_file.exists()}\")\n",
    "    print(f\"   orchestration_service.py exists: {orchestration_service_file.exists()}\")\n",
    "    \n",
    "    # List existing services\n",
    "    if services_dir.exists():\n",
    "        existing_services = [f.name for f in services_dir.glob(\"*.py\")]\n",
    "        print(f\"\\n   Existing services:\")\n",
    "        for service in existing_services:\n",
    "            print(f\"      ‚Ä¢ {service}\")\n",
    "    \n",
    "    has_task_service = task_service_file.exists() or scan_service_file.exists() or orchestration_service_file.exists()\n",
    "    \n",
    "    violation = ArchitecturalViolation(\n",
    "        violation_id=\"CRIT-020\",\n",
    "        violation_type=ViolationType.INFRASTRUCTURE,\n",
    "        severity=Severity.CRITICAL,\n",
    "        title=\"Task Service Layer Missing\",\n",
    "        description=\"No task service layer for managing async operations as required by ADR-007.\",\n",
    "        adr_violated=\"ADR-007\",\n",
    "        file_location=\"app/services/:1\",\n",
    "        expected_component=\"Task service layer for async operations\",\n",
    "        actual_state=\"No task-related services found\",\n",
    "        test_result=\"MISSING\" if not has_task_service else \"FOUND\",\n",
    "        evidence={\n",
    "            \"task_service_exists\": task_service_file.exists(),\n",
    "            \"scan_service_exists\": scan_service_file.exists(),\n",
    "            \"orchestration_service_exists\": orchestration_service_file.exists()\n",
    "        },\n",
    "        recommendation=\"Create app/services/task_service.py to manage async operations\",\n",
    "        verified=not has_task_service\n",
    "    )\n",
    "    \n",
    "    results.add_violation(violation)\n",
    "    \n",
    "    if not has_task_service:\n",
    "        print(f\"\\n{Fore.RED}‚ùå CRITICAL VIOLATION CONFIRMED\")\n",
    "        print(f\"   Task service layer missing\")\n",
    "        print(f\"   Impact: No business logic for async operations\")\n",
    "    else:\n",
    "        print(f\"\\n{Fore.GREEN}‚úÖ Task service layer found\")\n",
    "\n",
    "# Run the test\n",
    "test_task_service_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cicd_pipeline():\n",
    "    \"\"\"Test CI/CD pipeline completeness (CRITICAL Violation #22).\"\"\"\n",
    "    \n",
    "    print(f\"\\n{Fore.YELLOW}Testing CI/CD Pipeline (Violation #22)...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    workflows_dir = config.project_root / \".github\" / \"workflows\"\n",
    "    pr_validation_file = workflows_dir / \"pr-validation.yml\"\n",
    "    \n",
    "    print(f\"üìÅ Checking CI/CD configuration...\")\n",
    "    print(f\"   pr-validation.yml exists: {pr_validation_file.exists()}\")\n",
    "    \n",
    "    has_pip_audit = False\n",
    "    is_blocking = False\n",
    "    \n",
    "    if pr_validation_file.exists():\n",
    "        with open(pr_validation_file, 'r') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Check for pip-audit\n",
    "        has_pip_audit = 'pip-audit' in content or 'pip audit' in content\n",
    "        print(f\"   Has pip-audit step: {has_pip_audit}\")\n",
    "        \n",
    "        if has_pip_audit:\n",
    "            # Check if it's a blocking step\n",
    "            # Look for continue-on-error: false or lack of continue-on-error\n",
    "            lines = content.split('\\n')\n",
    "            for i, line in enumerate(lines):\n",
    "                if 'pip-audit' in line or 'pip audit' in line:\n",
    "                    # Check next few lines for continue-on-error\n",
    "                    context = '\\n'.join(lines[max(0, i-5):min(len(lines), i+10)])\n",
    "                    if 'continue-on-error: true' not in context:\n",
    "                        is_blocking = True\n",
    "                    break\n",
    "            \n",
    "            print(f\"   pip-audit is blocking: {is_blocking}\")\n",
    "        \n",
    "        # Check for other quality gates\n",
    "        quality_gates = [\n",
    "            \"pytest\",\n",
    "            \"mypy\",\n",
    "            \"black\",\n",
    "            \"flake8\",\n",
    "            \"bandit\"\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\n   Other quality gates:\")\n",
    "        for gate in quality_gates:\n",
    "            if gate in content:\n",
    "                print(f\"      ‚úì {gate}\")\n",
    "            else:\n",
    "                print(f\"      ‚úó {gate}\")\n",
    "    \n",
    "    violation = ArchitecturalViolation(\n",
    "        violation_id=\"CRIT-022\",\n",
    "        violation_type=ViolationType.INFRASTRUCTURE,\n",
    "        severity=Severity.CRITICAL,\n",
    "        title=\"CI/CD Pipeline Incomplete\",\n",
    "        description=\"pip-audit is not implemented as a blocking CI/CD step. ADR mandates pip-audit as mandatory quality gate.\",\n",
    "        adr_violated=\"ADR-010\",\n",
    "        file_location=\".github/workflows/pr-validation.yml:62\",\n",
    "        expected_component=\"pip-audit as blocking CI step\",\n",
    "        actual_state=\"pip-audit not blocking or missing\",\n",
    "        test_result=\"INCOMPLETE\" if not (has_pip_audit and is_blocking) else \"COMPLETE\",\n",
    "        evidence={\n",
    "            \"pr_validation_exists\": pr_validation_file.exists(),\n",
    "            \"has_pip_audit\": has_pip_audit,\n",
    "            \"is_blocking\": is_blocking\n",
    "        },\n",
    "        recommendation=\"Add pip-audit as a mandatory blocking step in CI/CD pipeline\",\n",
    "        verified=not (has_pip_audit and is_blocking)\n",
    "    )\n",
    "    \n",
    "    results.add_violation(violation)\n",
    "    \n",
    "    if not (has_pip_audit and is_blocking):\n",
    "        print(f\"\\n{Fore.RED}‚ùå CRITICAL VIOLATION CONFIRMED\")\n",
    "        print(f\"   pip-audit not properly configured in CI/CD\")\n",
    "        print(f\"   Impact: Security vulnerabilities may pass quality gates\")\n",
    "    else:\n",
    "        print(f\"\\n{Fore.GREEN}‚úÖ pip-audit properly configured\")\n",
    "\n",
    "# Run the test\n",
    "test_cicd_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results Summary and Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display comprehensive results summary\n",
    "results.display_summary()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"{Fore.CYAN}DETAILED ARCHITECTURAL VIOLATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Group violations by type\n",
    "by_type = {}\n",
    "for violation in results.violations:\n",
    "    vtype = violation.violation_type.value\n",
    "    if vtype not in by_type:\n",
    "        by_type[vtype] = []\n",
    "    by_type[vtype].append(violation)\n",
    "\n",
    "for vtype, violations in by_type.items():\n",
    "    verified_count = sum(1 for v in violations if v.verified)\n",
    "    \n",
    "    print(f\"\\n{Fore.YELLOW}üìÅ {vtype} ({verified_count}/{len(violations)} verified)\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    for violation in violations:\n",
    "        if violation.verified:\n",
    "            color = Fore.RED if violation.severity == Severity.CRITICAL else Fore.YELLOW\n",
    "            print(f\"\\n{color}[{violation.violation_id}] {violation.title}\")\n",
    "            print(f\"   Severity: {violation.severity.value}\")\n",
    "            print(f\"   ADR: {violation.adr_violated}\")\n",
    "            print(f\"   Location: {violation.file_location}\")\n",
    "            print(f\"   Status: {violation.test_result}\")\n",
    "            print(f\"   Impact: {violation.description[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate compliance score\n",
    "total_violations = len(results.violations)\n",
    "verified_violations = sum(1 for v in results.violations if v.verified)\n",
    "critical_violations = sum(1 for v in results.violations if v.verified and v.severity == Severity.CRITICAL)\n",
    "\n",
    "# ADR compliance calculation\n",
    "expected_components = 22  # Based on the report\n",
    "missing_components = verified_violations\n",
    "compliance_score = ((expected_components - missing_components) / expected_components * 100) if expected_components > 0 else 0\n",
    "compliance_score = max(0, compliance_score)  # Ensure non-negative\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"{Fore.CYAN}ARCHITECTURAL COMPLIANCE ASSESSMENT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä Compliance Metrics:\")\n",
    "print(f\"   Total Violations Tested: {total_violations}\")\n",
    "print(f\"   Verified Violations: {verified_violations}\")\n",
    "print(f\"   Critical Violations: {critical_violations}\")\n",
    "print(f\"   ADR Compliance Score: {compliance_score:.1f}%\")\n",
    "\n",
    "if compliance_score < 50:\n",
    "    status_color = Fore.RED\n",
    "    status = \"CRITICAL - NOT DEPLOYABLE\"\n",
    "elif compliance_score < 70:\n",
    "    status_color = Fore.YELLOW\n",
    "    status = \"FAILING - MAJOR GAPS\"\n",
    "elif compliance_score < 90:\n",
    "    status_color = Fore.BLUE\n",
    "    status = \"NEEDS IMPROVEMENT\"\n",
    "else:\n",
    "    status_color = Fore.GREEN\n",
    "    status = \"ACCEPTABLE\"\n",
    "\n",
    "print(f\"\\n{status_color}Architecture Status: {status}\")\n",
    "\n",
    "# Impact Assessment\n",
    "print(f\"\\n{Fore.CYAN}IMPACT ASSESSMENT\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "impacts = {\n",
    "    \"Cannot execute long-running operations\": critical_violations >= 8,\n",
    "    \"Cannot process background tasks\": critical_violations >= 4,\n",
    "    \"Cannot persist operational data\": critical_violations >= 3,\n",
    "    \"Cannot integrate AI providers\": critical_violations >= 3,\n",
    "    \"Cannot track security vulnerabilities\": verified_violations >= 10,\n",
    "    \"Cannot scale horizontally\": verified_violations >= 15,\n",
    "    \"Cannot meet federal compliance\": compliance_score < 70\n",
    "}\n",
    "\n",
    "for impact, condition in impacts.items():\n",
    "    if condition:\n",
    "        print(f\"   {Fore.RED}‚ùå {impact}\")\n",
    "    else:\n",
    "        print(f\"   {Fore.GREEN}‚úì {impact}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate implementation roadmap\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"{Fore.CYAN}IMPLEMENTATION ROADMAP\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "roadmap = [\n",
    "    {\n",
    "        \"phase\": \"Phase 1: Infrastructure (Week 1-2)\",\n",
    "        \"priority\": \"CRITICAL\",\n",
    "        \"tasks\": [\n",
    "            \"Install Celery dependencies (celery[redis], flower, kombu)\",\n",
    "            \"Create app/core/celery_app.py configuration\",\n",
    "            \"Set up Redis container in docker-compose.yml\",\n",
    "            \"Add worker container definitions\",\n",
    "            \"Configure task queue settings in config.py\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"phase\": \"Phase 2: API Layer (Week 2-3)\",\n",
    "        \"priority\": \"CRITICAL\",\n",
    "        \"tasks\": [\n",
    "            \"Create app/api/endpoints/tasks.py with polling endpoints\",\n",
    "            \"Create app/api/endpoints/scans.py with 202 Accepted responses\",\n",
    "            \"Implement report generation endpoints\",\n",
    "            \"Add orchestration endpoints\",\n",
    "            \"Create template rendering endpoints\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"phase\": \"Phase 3: Data Layer (Week 3-4)\",\n",
    "        \"priority\": \"CRITICAL\",\n",
    "        \"tasks\": [\n",
    "            \"Create app/models/task.py with TaskStatus enum\",\n",
    "            \"Add related models (RedTeamSession, ScoringResult, etc.)\",\n",
    "            \"Configure MongoDB for document storage\",\n",
    "            \"Set up S3/blob storage configuration\",\n",
    "            \"Create database migrations\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"phase\": \"Phase 4: Plugin System (Week 4-5)\",\n",
    "        \"priority\": \"HIGH\",\n",
    "        \"tasks\": [\n",
    "            \"Create app/core/plugins/provider_interface.py\",\n",
    "            \"Implement concrete plugins (OpenAI, Anthropic, Ollama)\",\n",
    "            \"Create plugin discovery mechanism\",\n",
    "            \"Add ScorerPlugin interface\",\n",
    "            \"Test plugin integration\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"phase\": \"Phase 5: Configuration & Quality (Week 5-6)\",\n",
    "        \"priority\": \"HIGH\",\n",
    "        \"tasks\": [\n",
    "            \"Update error handling to RFC 7807 compliance\",\n",
    "            \"Add pip-audit to CI/CD pipeline\",\n",
    "            \"Complete configuration settings\",\n",
    "            \"Add comprehensive testing\",\n",
    "            \"Update documentation\"\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "for phase in roadmap:\n",
    "    color = Fore.RED if phase['priority'] == 'CRITICAL' else Fore.YELLOW\n",
    "    \n",
    "    print(f\"\\n{color}üìÖ {phase['phase']} (Priority: {phase['priority']})\")\n",
    "    for task in phase['tasks']:\n",
    "        print(f\"   ‚Ä¢ {task}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to JSON\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Prepare export data\n",
    "export_data = {\n",
    "    \"assessment_date\": datetime.now().isoformat(),\n",
    "    \"github_issue\": \"#49\",\n",
    "    \"api_endpoint\": config.api_url,\n",
    "    \"summary\": results.get_summary(),\n",
    "    \"compliance_score\": compliance_score,\n",
    "    \"violations\": [v.to_dict() for v in results.violations],\n",
    "    \"impacts\": {k: v for k, v in impacts.items() if v},\n",
    "    \"implementation_roadmap\": roadmap\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "output_file = \"ISSUE_49_Verification_Results.json\"\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(export_data, f, indent=2)\n",
    "\n",
    "print(f\"\\n{Fore.GREEN}‚úÖ Results exported to {output_file}\")\n",
    "\n",
    "# Generate markdown report\n",
    "markdown_report = f\"\"\"# ViolentUTF API Architectural Verification Report\n",
    "\n",
    "**Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "**GitHub Issue:** #49\n",
    "**ADR Compliance Score:** {compliance_score:.1f}%\n",
    "**Architecture Status:** {status}\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "Verification testing confirmed **{verified_violations} of {total_violations}** reported architectural violations.\n",
    "\n",
    "### Critical Findings\n",
    "- **API Endpoints:** 8 CRITICAL endpoints completely missing\n",
    "- **Infrastructure:** No task queue or worker containers\n",
    "- **Data Models:** Core business models absent\n",
    "- **Plugin System:** No extensibility framework\n",
    "- **Configuration:** Missing critical settings\n",
    "\n",
    "## Immediate Actions Required\n",
    "\n",
    "1. **Install** Celery and task queue dependencies\n",
    "2. **Create** async task endpoints with 202 Accepted\n",
    "3. **Implement** Task model and related data models\n",
    "4. **Configure** document and blob storage\n",
    "5. **Build** plugin architecture for AI providers\n",
    "\n",
    "## Impact Assessment\n",
    "\n",
    "The system is **NOT DEPLOYABLE** in its current state due to:\n",
    "- Cannot execute long-running operations\n",
    "- Cannot process background tasks\n",
    "- Cannot integrate AI providers\n",
    "- Cannot meet federal compliance requirements\n",
    "\n",
    "## Recommendation\n",
    "\n",
    "Implement the 6-week roadmap provided to achieve production readiness.\n",
    "\n",
    "## Full Report\n",
    "\n",
    "See `ISSUE_49_Verification_Results.json` for complete findings and implementation plan.\n",
    "\"\"\"\n",
    "\n",
    "with open(\"ISSUE_49_Verification_Report.md\", 'w') as f:\n",
    "    f.write(markdown_report)\n",
    "\n",
    "print(f\"{Fore.GREEN}‚úÖ Markdown report saved to ISSUE_49_Verification_Report.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final recommendations\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"{Fore.CYAN}FINAL RECOMMENDATIONS FOR US GOVERNMENT DEPLOYMENT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    "{Fore.RED}‚ö†Ô∏è CRITICAL ARCHITECTURAL ADVISORY ‚ö†Ô∏è\n",
    "\n",
    "Based on this comprehensive architectural assessment, the ViolentUTF API is\n",
    "{Fore.RED}NOT READY FOR PRODUCTION DEPLOYMENT{Style.RESET_ALL} in its current state.\n",
    "\n",
    "{Fore.CYAN}KEY ARCHITECTURAL GAPS:{Style.RESET_ALL}\n",
    "\n",
    "1. {Fore.RED}CRITICAL:{Style.RESET_ALL} No async task processing capability.\n",
    "   The system cannot handle any long-running operations.\n",
    "\n",
    "2. {Fore.RED}CRITICAL:{Style.RESET_ALL} Core API endpoints missing.\n",
    "   8 critical endpoint groups required by ADRs are absent.\n",
    "\n",
    "3. {Fore.RED}CRITICAL:{Style.RESET_ALL} No data persistence strategy.\n",
    "   Missing Task model and related business models.\n",
    "\n",
    "4. {Fore.RED}CRITICAL:{Style.RESET_ALL} No plugin architecture.\n",
    "   Cannot integrate with AI providers (OpenAI, Anthropic, etc.)\n",
    "\n",
    "{Fore.CYAN}PRODUCTION READINESS ASSESSMENT:{Style.RESET_ALL}\n",
    "\n",
    "‚Ä¢ {Fore.RED}Functionality:{Style.RESET_ALL} Core features not implementable\n",
    "‚Ä¢ {Fore.RED}Scalability:{Style.RESET_ALL} Cannot scale without task queue\n",
    "‚Ä¢ {Fore.RED}Reliability:{Style.RESET_ALL} No async processing or error handling\n",
    "‚Ä¢ {Fore.RED}Maintainability:{Style.RESET_ALL} Missing plugin architecture\n",
    "‚Ä¢ {Fore.RED}Compliance:{Style.RESET_ALL} Does not meet federal requirements\n",
    "\n",
    "{Fore.CYAN}REQUIRED INVESTMENT:{Style.RESET_ALL}\n",
    "\n",
    "‚Ä¢ **Development Time:** 6-10 weeks with dedicated team\n",
    "‚Ä¢ **Team Size:** 3-4 senior engineers\n",
    "‚Ä¢ **Focus Areas:** Infrastructure, API, Data, Plugins\n",
    "‚Ä¢ **Testing:** Additional 2-3 weeks for comprehensive testing\n",
    "\n",
    "{Fore.GREEN}POSITIVE NOTES:{Style.RESET_ALL}\n",
    "\n",
    "‚Ä¢ The authentication/authorization foundation is solid\n",
    "‚Ä¢ The codebase structure supports adding required components\n",
    "‚Ä¢ The ADRs provide clear architectural guidance\n",
    "‚Ä¢ The violations are well-documented and fixable\n",
    "\n",
    "{Fore.CYAN}RECOMMENDATION:{Style.RESET_ALL}\n",
    "\n",
    "Allocate a dedicated architecture team for 6-10 weeks to implement\n",
    "all critical components before any production deployment. This is not\n",
    "optional - the system literally cannot function without these components.\n",
    "\n",
    "The ViolentUTF API currently provides only authentication and authorization.\n",
    "To become a functional AI red-teaming platform, it requires the complete\n",
    "implementation of the architectural components identified in this assessment.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"{Fore.GREEN}‚úÖ Architectural verification complete. Results saved.\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
